{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras后端\n",
    "## 什么是“后端”\n",
    "\n",
    "Keras是一个模型级的库，提供了快速构建深度学习网络的模块。Keras并不处理如张量乘法、卷积等底层操作。这些操作依赖于某种特定的、优化良好的张量操作库。Keras依赖于处理张量的库就称为“后端引擎”。Keras提供了两种后端引擎Theano/Tensorflow，并将其函数统一封装，使得用户可以以同一个接口调用不同后端引擎的函数\n",
    "\n",
    "* Theano是一个开源的符号主义张量操作框架，由蒙特利尔大学LISA/MILA实验室开发\n",
    "* TensorFlow是一个符号主义的张量操作框架，由Google开发\n",
    "\n",
    "在未来，我们有可能要添加更多的后端选项，如果你有兴趣开发后端，请与我联系~\n",
    "\n",
    "## 切换后端\n",
    "\n",
    "如果你至少运行过一次Keras，你将在下面的目录下找到Keras的配置文件：\n",
    "\n",
    "  ~/.keras/keras.json\n",
    "\n",
    "如果该目录下没有该文件，你可以手动创建一个\n",
    "\n",
    "文件的默认配置如下：\n",
    "\n",
    "{\n",
    "\"image_dim_ordering\":\"tf\",\n",
    "\"epsilon\":1e-07,\n",
    "\"floatx\":\"float32\",\n",
    "\"backend\":\"tensorflow\"\n",
    "}\n",
    "\n",
    "将backend字段的值改写为你需要使用的后端：theano或tensorflow，即可完成后端的切换\n",
    "\n",
    "我们也可以通过定义环境变量KERAS_BACKEND来覆盖上面配置文件中定义的后端：\n",
    "\n",
    "KERAS_BACKEND=tensorflow python -c \"from keras import backend;\"\n",
    "Using TensorFlow backend.\n",
    "\n",
    "## keras.json 细节\n",
    "\n",
    "{\n",
    "    \"image_dim_ordering\": \"tf\",\n",
    "    \"epsilon\": 1e-07,\n",
    "    \"floatx\": \"float32\",\n",
    "    \"backend\": \"tensorflow\"\n",
    "}\n",
    "\n",
    "你可以更改以上~/.keras/keras.json中的配置\n",
    "* image_dim_ordering：字符串，\"tf\"或\"th\"，该选项指定了Keras将要使用的维度顺序，可通过keras.backend.image_dim_ordering()来获取当前的维度顺序。对2D数据来说，tf假定维度顺序为(rows,cols,channels)而th假定维度顺序为(channels, rows, cols)。对3D数据而言，tf假定(conv_dim1, conv_dim2, conv_dim3, channels)，th则是(channels, conv_dim1, conv_dim2, conv_dim3)\n",
    "* epsilon：浮点数，防止除0错误的小数字\n",
    "* floatx：字符串，\"float16\", \"float32\", \"float64\"之一，为浮点数精度\n",
    "* backend：字符串，所使用的后端，为\"tensorflow\"或\"theano\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用抽象的Keras后端来编写代码\n",
    "\n",
    "如果你希望你编写的Keras模块能够同时在Theano和TensorFlow两个后端上使用，你可以通过Keras后端接口来编写代码，这里是一个简介："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下面的代码实例化了一个输入占位符，等价于tf.placeholder() ，T.matrix()，T.tensor3()等\n",
    "\n",
    "input = K.placeholder(shape=(2, 4, 5))\n",
    "# also works:\n",
    "input = K.placeholder(shape=(None, 4, 5))\n",
    "# also works:\n",
    "input = K.placeholder(ndim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val: [[[0.79496233 0.54872479 0.08859713 0.35435715 0.03394271]\n",
      "  [0.50680406 0.32313895 0.87309698 0.89853147 0.93612113]\n",
      "  [0.31808792 0.24273923 0.27757798 0.93155299 0.4561912 ]\n",
      "  [0.6233277  0.77349137 0.00133366 0.01985535 0.43858308]]\n",
      "\n",
      " [[0.19338747 0.49391168 0.6575116  0.28903274 0.06796342]\n",
      "  [0.24399184 0.43370948 0.09434266 0.6000801  0.87372022]\n",
      "  [0.48281087 0.14385422 0.5573031  0.49824132 0.56656246]\n",
      "  [0.15673988 0.35300013 0.2813824  0.80561722 0.4395718 ]]\n",
      "\n",
      " [[0.58334764 0.22605754 0.30405116 0.11582888 0.45504755]\n",
      "  [0.46195351 0.92311736 0.44215206 0.4578755  0.98691677]\n",
      "  [0.1913837  0.15435109 0.8365811  0.52367146 0.85430744]\n",
      "  [0.51205048 0.76778    0.75212    0.00719794 0.66528514]]]\n",
      "var: <tf.Variable 'Variable:0' shape=(3, 4, 5) dtype=float32_ref>\n",
      "var.eval(): [[[0.79496235 0.5487248  0.08859713 0.35435715 0.03394271]\n",
      "  [0.50680405 0.32313895 0.873097   0.8985315  0.9361211 ]\n",
      "  [0.31808794 0.24273923 0.27757797 0.931553   0.45619118]\n",
      "  [0.62332773 0.7734914  0.00133366 0.01985535 0.43858308]]\n",
      "\n",
      " [[0.19338746 0.49391168 0.6575116  0.28903273 0.06796342]\n",
      "  [0.24399184 0.43370947 0.09434266 0.60008013 0.8737202 ]\n",
      "  [0.48281088 0.14385422 0.5573031  0.4982413  0.5665625 ]\n",
      "  [0.15673988 0.35300013 0.28138238 0.8056172  0.4395718 ]]\n",
      "\n",
      " [[0.5833476  0.22605753 0.30405116 0.11582889 0.45504755]\n",
      "  [0.46195352 0.92311734 0.44215205 0.4578755  0.9869168 ]\n",
      "  [0.19138369 0.15435109 0.8365811  0.52367145 0.8543074 ]\n",
      "  [0.51205045 0.76778    0.75212    0.00719794 0.6652851 ]]]\n",
      "type(scalar): <class 'tensorflow.python.ops.variables.Variable'>\n",
      "scalar.shape: ()\n",
      "scalar.eval(): 1.0\n",
      "type(vec): <class 'tensorflow.python.ops.variables.Variable'>\n",
      "vec.shape: (3,)\n",
      "vec.eval(): [1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "#下面的代码实例化了一个共享变量（shared），等价于tf.variable()或 theano.shared()\n",
    "\n",
    "val = np.random.random((3, 4, 5))\n",
    "var = K.variable(value=val)\n",
    "print('val:',val)\n",
    "print('var:',var)\n",
    "print('var.eval():',K.eval(var))\n",
    "# all-zeros variable:\n",
    "var = K.zeros(shape=(3, 4, 5))\n",
    "# all-ones:\n",
    "var = K.ones(shape=(3, 4, 5))\n",
    "\n",
    "scalar=K.variable(value=1)   #标量\n",
    "print('type(scalar):',type(scalar))\n",
    "print('scalar.shape:',scalar.shape)\n",
    "print('scalar.eval():',K.eval(scalar))\n",
    "\n",
    "vec=K.variable(value=[1,2,3])#向量\n",
    "print('type(vec):',type(vec))\n",
    "print('vec.shape:',vec.shape)\n",
    "print('vec.eval():',K.eval(vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.eval(): [[1.]]\n",
      "b.eval(): [[1.]]\n",
      "c.eval(): [[1.]]\n",
      "d.eval(): [[1.]]\n"
     ]
    }
   ],
   "source": [
    "a=K.variable(value=[[1]])\n",
    "b=K.variable(value=[[1]])\n",
    "c=K.transpose(a)\n",
    "d=K.dot(a,b) #点积必须是二维数组\n",
    "e=K.dot(a,c)\n",
    "print('a.eval():',K.eval(a))\n",
    "print('b.eval():',K.eval(b))\n",
    "print('c.eval():',K.eval(c))\n",
    "print('d.eval():',K.eval(d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#大多数你需要的张量操作都可以通过统一的Keras后端接口完成，而不关心具体执行这些操作的是Theano还是TensorFlow\n",
    "#b=K.variable(value=[[1,2],[1,2]])\n",
    "#c=K.variable(value=[[2,3],[2,3]])\n",
    "#d=K.variable(value=[[3,4],[3,4]])\n",
    "#a = b + c * K.abs(d)\n",
    "#c = K.dot(a, K.transpose(b))\n",
    "#a = K.sum(b, axis=2)\n",
    "#a = K.softmax(b)\n",
    "#a = concatenate([b, c], axis=-1)\n",
    "# etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kera后端函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.epsilon(): 1e-07\n"
     ]
    }
   ],
   "source": [
    "#epsilon()\n",
    "#  以数值形式返回一个（一般来说很小的）数，用以防止除0错误\n",
    "print('K.epsilon():',K.epsilon())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.epsilon(): 1e-05\n",
      "K.epsilon(): 1e-05\n"
     ]
    }
   ],
   "source": [
    "#set_epsilon(e)\n",
    "#  设置在数值表达式中使用的fuzz factor，用于防止除0错误，该值应该是一个较小的浮点数，示例：\n",
    "print('K.epsilon():',K.epsilon())\n",
    "\n",
    "K.set_epsilon(1e-05)\n",
    "print('K.epsilon():',K.epsilon())\n",
    "K.set_epsilon(1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.floatx(): float32\n"
     ]
    }
   ],
   "source": [
    "#floatx()\n",
    "#  返回默认的浮点数数据类型，为字符串，如 'float16', 'float32', 'float64'\n",
    "print('K.floatx():',K.floatx())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.floatx(): float32\n",
      "K.floatx(): float16\n"
     ]
    }
   ],
   "source": [
    "#set_floatx(floatx)\n",
    "#  设置默认的浮点数数据类型，为字符串，如 'float16', 'float32', 'float64',示例：\n",
    "print('K.floatx():',K.floatx())\n",
    "K.set_floatx('float16')\n",
    "print('K.floatx():',K.floatx())\n",
    "\n",
    "K.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.floatx(): float32\n",
      "arr.dtype: float64\n",
      "new_arr.dtype: float32\n"
     ]
    }
   ],
   "source": [
    "#cast_to_floatx(x)\n",
    "#  将numpy array转换为默认的Keras floatx类型，x为numpy array，返回值也为numpy array但其数据类型变为floatx。示例：\n",
    "print('K.floatx():',K.floatx())\n",
    "arr = np.array([1.0, 2.0], dtype='float64')\n",
    "print('arr.dtype:',arr.dtype)\n",
    "new_arr = K.cast_to_floatx(arr)\n",
    "print('new_arr.dtype:',new_arr.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.image_dim_ordering(): tf\n"
     ]
    }
   ],
   "source": [
    "#image_dim_ordering()\n",
    "#  返回默认的图像的维度顺序（‘tf’或‘th’）\n",
    "print('K.image_dim_ordering():',K.image_dim_ordering())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.image_dim_ordering(): tf\n",
      "K.image_dim_ordering(): th\n"
     ]
    }
   ],
   "source": [
    "#set_image_dim_ordering(dim_ordering)\n",
    "#  设置图像的维度顺序（‘tf’或‘th’）,示例：\n",
    "print('K.image_dim_ordering():',K.image_dim_ordering())\n",
    "K.set_image_dim_ordering('th')\n",
    "print('K.image_dim_ordering():',K.image_dim_ordering())\n",
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "#get_uid(prefix='')\n",
    "#  依据给定的前缀提供一个唯一的UID，参数为表示前缀的字符串，返回值为整数，示例：\n",
    "print(K.get_uid('dense'))\n",
    "print(K.get_uid('dense'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#结果存疑？？？\n",
    "\n",
    "#is_keras_tensor(x)\n",
    "#  判断x是否是一个Keras tensor，返回一个布尔值，示例\n",
    "np_var = np.array([1, 2])\n",
    "#K.is_keras_tensor(np_var)\n",
    "keras_var = K.variable(np_var)\n",
    "print(K.is_keras_tensor(keras_var))  # A variable is not a Tensor.\n",
    "keras_placeholder = K.placeholder(shape=(2, 4, 5))\n",
    "print(K.is_keras_tensor(keras_placeholder))  # A placeholder is a Tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clear_session()\n",
    "#  结束当前的TF计算图，并新建一个。有效的避免模型/层的混乱\n",
    "K.clear_session()\n",
    "a=K.variable(value=1)\n",
    "K.eval(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual_variable_initialization(value)\n",
    "#  指出变量应该以其默认值被初始化还是由用户手动初始化，参数value为布尔值，默认False代表变量由其默认值初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learning_phase()\n",
    "#  返回训练模式/测试模式的flag，该flag是一个用以传入Keras模型的标记，以决定当前模型执行于训练模式下还是测试模式下\n",
    "K.learning_phase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#set_learning_phase(flag)\n",
    "#  设置训练模式/测试模式0或1\n",
    "K.set_learning_phase(1)\n",
    "print(K.learning_phase())\n",
    "K.set_learning_phase(0)\n",
    "print(K.learning_phase())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#is_sparse(tensor)\n",
    "#  判断一个tensor是不是一个稀疏的tensor(稀不稀疏由tensor的类型决定，而不是tensor实际上有多稀疏)，返回值是一个布尔值，示例：\n",
    "a = K.placeholder((2, 2), sparse=False)\n",
    "print(K.is_sparse(a))\n",
    "b = K.placeholder((2, 2), sparse=True)\n",
    "print(K.is_sparse(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#to_dense(tensor)\n",
    "#  将一个稀疏tensor转换一个不稀疏的tensor并返回之，示例：\n",
    "b = K.placeholder((2, 2), sparse=True)\n",
    "print(K.is_sparse(b))\n",
    "c = K.to_dense(b)\n",
    "print(K.is_sparse(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kvar <tf.Variable 'example_var_4:0' shape=(2, 2) dtype=float64_ref>\n",
      "kvar.eval():\n",
      " [[1. 2.]\n",
      " [3. 4.]]\n",
      "scalar: <tf.Variable 'scalar_var_1:0' shape=() dtype=float32_ref>\n",
      "scalar.eval():\n",
      " 1.0\n",
      "vec: <tf.Variable 'vector_var:0' shape=(3,) dtype=float32_ref>\n",
      "vec.eval():\n",
      " [1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "#variable(value, dtype='float32', name=None)\n",
    "#实例化一个张量，返回之\n",
    "#参数：\n",
    "#\n",
    "#    value：用来初始化张量的值\n",
    "#    dtype：张量数据类型\n",
    "#    name：张量的名字（可选）\n",
    "#\n",
    "#示例：\n",
    "val = np.array([[1, 2], [3, 4]])\n",
    "kvar = K.variable(value=val, dtype='float64', name='example_var')\n",
    "print('kvar',kvar)\n",
    "print('kvar.eval():\\n',K.eval(kvar))\n",
    "\n",
    "#标量\n",
    "scalar=K.variable(value=1,dtype='float32',name='scalar_var')\n",
    "print('scalar:',scalar)\n",
    "print('scalar.eval():\\n',K.eval(scalar))\n",
    "\n",
    "#向量\n",
    "vec=K.variable(value=[1,2,3],dtype='float32',name='vector_var')\n",
    "print('vec:',vec)\n",
    "print('vec.eval():\\n',K.eval(vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ph: Tensor(\"Placeholder_5:0\", shape=(2, 4, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#placeholder(shape=None, ndim=None, dtype='float32', name=None)\n",
    "#实例化一个占位符，返回之\n",
    "#参数：\n",
    "#    shape：占位符的shape（整数tuple，可能包含None）\n",
    "#    ndim: 占位符张量的阶数，要初始化一个占位符，至少指定shape和ndim之一，如果都指定则使用shape\n",
    "#    dtype: 占位符数据类型\n",
    "#    name: 占位符名称（可选）\n",
    "#示例：\n",
    "input_ph = K.placeholder(shape=(2, 4, 5))\n",
    "print('input_ph:',input_ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.shape(kvar): Tensor(\"Shape:0\", shape=(2,), dtype=int32)\n",
      "K.shape(input): Tensor(\"Shape_1:0\", shape=(3,), dtype=int32)\n",
      "K.shape(kvar).eval(session=tf_session): [2 2]\n",
      "K.shape(input).eval(session=tf_session): [2 4 5]\n"
     ]
    }
   ],
   "source": [
    "#shape(x)\n",
    "#  返回一个张量的符号shape，符号shape的意思是返回值本身也是一个tensor，示例：\n",
    "tf_session = K.get_session()\n",
    "val = np.array([[1, 2], [3, 4]])\n",
    "kvar = K.variable(value=val)\n",
    "print('K.shape(kvar):',K.shape(kvar))\n",
    "input = K.placeholder(shape=(2, 4, 5))\n",
    "print('K.shape(input):',K.shape(input))\n",
    "print('K.shape(kvar).eval(session=tf_session):',K.shape(kvar).eval(session=tf_session))\n",
    "print('K.shape(input).eval(session=tf_session):',K.shape(input).eval(session=tf_session))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.int_shape(input): (2, 4, 5)\n",
      "K.int_shape(kvar): (2, 2)\n"
     ]
    }
   ],
   "source": [
    "#int_shape(x)\n",
    "#  以整数Tuple或None的形式返回张量shape，示例：\n",
    "input = K.placeholder(shape=(2, 4, 5))\n",
    "print('K.int_shape(input):',K.int_shape(input))\n",
    "val = np.array([[1, 2], [3, 4]])\n",
    "kvar = K.variable(value=val)\n",
    "print('K.int_shape(kvar):',K.int_shape(kvar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.ndim(input): 3\n",
      "K.ndim(kvar): 2\n"
     ]
    }
   ],
   "source": [
    "#ndim(x)\n",
    "#  返回张量的阶数，为整数，示例：\n",
    "input = K.placeholder(shape=(2, 4, 5))\n",
    "val = np.array([[1, 2], [3, 4]])\n",
    "kvar = K.variable(value=val)\n",
    "print('K.ndim(input):',K.ndim(input))\n",
    "print('K.ndim(kvar):',K.ndim(kvar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.dtype(K.placeholder(shape=(2,4,5))): float32\n",
      "K.dtype(K.placeholder(shape=(2,4,5), dtype='float32')): float32\n",
      "K.dtype(K.placeholder(shape=(2,4,5), dtype='float64')): float64\n",
      "K.dtype(kvar): float32\n",
      "K.dtype(kvar): float32\n"
     ]
    }
   ],
   "source": [
    "#dtype(x)\n",
    "#  返回张量的数据类型，为字符串，示例：\n",
    "print('K.dtype(K.placeholder(shape=(2,4,5))):',K.dtype(K.placeholder(shape=(2,4,5))))\n",
    "print(\"K.dtype(K.placeholder(shape=(2,4,5), dtype='float32')):\",K.dtype(K.placeholder(shape=(2,4,5), dtype='float32')))\n",
    "print(\"K.dtype(K.placeholder(shape=(2,4,5), dtype='float64')):\",K.dtype(K.placeholder(shape=(2,4,5), dtype='float64')))\n",
    "kvar = K.variable(np.array([[1, 2], [3, 4]]))\n",
    "print('K.dtype(kvar):',K.dtype(kvar))\n",
    "kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')\n",
    "print('K.dtype(kvar):',K.dtype(kvar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.eval(kvar):\n",
      " [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "#eval(x)\n",
    "#  求得张量的值，返回一个Numpy array，示例：\n",
    "kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')\n",
    "print('K.eval(kvar):\\n',K.eval(kvar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.eval(kvar):\n",
      " [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#zeros(shape, dtype='float32', name=None)\n",
    "#  生成一个全0张量，示例：\n",
    "kvar = K.zeros((3,4))\n",
    "print('K.eval(kvar):\\n',K.eval(kvar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.eval(kvar):\n",
      " [[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#ones(shape, dtype='float32', name=None)\n",
    "#  生成一个全1张量，示例\n",
    "kvar = K.ones((3,4))\n",
    "print('K.eval(kvar):\\n',K.eval(kvar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.eval(kvar):\n",
      " [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#eye(size, dtype='float32', name=None)\n",
    "#  生成一个单位矩阵，示例：\n",
    "kvar = K.eye(3)\n",
    "print('K.eval(kvar):\\n',K.eval(kvar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.eval(kvar_zeros):\n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#zeros_like(x, name=None)\n",
    "#  生成与另一个张量x的shape相同的全0张量，示例：\n",
    "kvar = K.variable(np.random.random((2,3)))\n",
    "kvar_zeros = K.zeros_like(kvar)\n",
    "print('K.eval(kvar_zeros):\\n',K.eval(kvar_zeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.eval(kvar_ones):\n",
      " [[1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#ones_like(x, name=None)\n",
    "#  生成与另一个张量shape相同的全1张量，示例：\n",
    "kvar = K.variable(np.random.random((2,3)))\n",
    "kvar_ones = K.ones_like(kvar)\n",
    "print('K.eval(kvar_ones):\\n',K.eval(kvar_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kvar:\n",
      " <tf.Variable 'Variable_16:0' shape=(2, 3) dtype=float32_ref>\n",
      "K.eval(kvar):\n",
      " [[0.02021575 0.28859675 0.6882783 ]\n",
      " [0.6855142  0.4137349  0.17341638]]\n"
     ]
    }
   ],
   "source": [
    "#random_uniform_variable(shape, low, high, dtype=None, name=None, seed=None)\n",
    "#初始化一个Keras变量，其数值为从一个均匀分布中采样的样本，返回之。\n",
    "#参数：\n",
    "#    shape：张量shape\n",
    "#    low：浮点数，均匀分布之下界\n",
    "#    high：浮点数，均匀分布之上界\n",
    "#    dtype：数据类型\n",
    "#    name：张量名\n",
    "#    seed：随机数种子\n",
    "#示例：\n",
    "kvar = K.random_uniform_variable((2,3), 0, 1)\n",
    "print('kvar:\\n',kvar)\n",
    "print('K.eval(kvar):\\n',K.eval(kvar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.count_params(kvar): 6\n",
      "K.eval(kvar):\n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#count_params(x)\n",
    "#  返回张量中标量的个数，示例：\n",
    "kvar = K.zeros((2,3))\n",
    "print('K.count_params(kvar):',K.count_params(kvar))\n",
    "print('K.eval(kvar):\\n',K.eval(kvar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: Tensor(\"Placeholder_14:0\", shape=(2, 3), dtype=float32)\n",
      "new1_input: Tensor(\"Cast_3:0\", shape=(2, 3), dtype=float16)\n",
      "new2_input: Tensor(\"Cast_4:0\", shape=(2, 3), dtype=float16)\n"
     ]
    }
   ],
   "source": [
    "#cast(x, dtype)\n",
    "#  改变张量的数据类型，dtype只能是float16, float32或float64之一，示例：\n",
    "input = K.placeholder((2, 3), dtype='float32')\n",
    "print('input:',input)\n",
    "new1_input=K.cast(input, dtype='float16')\n",
    "print('new1_input:',new1_input)\n",
    "new2_input = K.cast(input, dtype=np.float16)\n",
    "print('new2_input:',new2_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xy: Tensor(\"MatMul_8:0\", shape=(2, 4), dtype=float32)\n",
      "xy: Tensor(\"Reshape_11:0\", shape=(32, 28, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#dot(x, y)\n",
    "#  求两个张量的乘积。当试图计算两个N阶张量的乘积时，与Theano行为相同，如(2, 3).(4, 3, 5) = (2, 4, 5))，示例：\n",
    "x = K.placeholder(shape=(2, 3))\n",
    "y = K.placeholder(shape=(3, 4))\n",
    "xy = K.dot(x, y)\n",
    "print('xy:',xy)\n",
    "\n",
    "x = K.placeholder(shape=(32, 28, 3))\n",
    "y = K.placeholder(shape=(3, 4))\n",
    "xy = K.dot(x, y)\n",
    "print('xy:',xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.int_shape(xy_batch_dot): (32, 1, 30)\n",
      "K.int_shape(xy_batch_dot): (2, 1, 3)\n",
      "[[[2. 2. 2.]]\n",
      "\n",
      " [[2. 2. 2.]]]\n"
     ]
    }
   ],
   "source": [
    "#batch_dot(x, y, axes=None)\n",
    "#  按批进行张量乘法，该函数用于计算x和y的点积，其中x和y都是成batch出现的数据。即它的数据shape形如(batch_size,:)。\n",
    "#batch_dot将产生比输入张量维度低的张量，如果张量的维度被减至1，则通过expand_dims保证其维度至少为2 \n",
    "#例如，假设x = [[1, 2],[3,4]] ， y = [[5, 6],[7, 8]]，则batch_dot(x, y, axes=1) = [[17, 53]]，\n",
    "#即x.dot(y.T)的主对角元素，此过程中我们没有计算过反对角元素的值\n",
    "#参数：\n",
    "#    x,y：阶数大于等于2的张量，在tensorflow下，只支持大于等于3阶的张量\n",
    "#    axes：目标结果的维度，为整数或整数列表，axes[0]和axes[1]应相同\n",
    "#示例： 假设x=[[1,2],[3,4]]，y=[[5,6],[7,8]]，则batch_dot(x, y, axes=1)为[[17, 53]]，恰好为x.dot(y.T)的主对角元，\n",
    "#整个过程没有计算反对角元的元素。\n",
    "#我们做一下shape的推导，假设x是一个shape为(100,20)的tensor，y是一个shape为(100,30,20)的tensor，假设axes=(1,2)，\n",
    "#则输出tensor的shape通过循环x.shape和y.shape确定：\n",
    "#    x.shape[0]：值为100，加入到输入shape里\n",
    "#    x.shape[1]：20，不加入输出shape里，因为该维度的值会被求和(dot_axes[0]=1)\n",
    "#    y.shape[0]：值为100，不加入到输出shape里，y的第一维总是被忽略\n",
    "#    y.shape[1]：30，加入到输出shape里#\n",
    "#    y.shape[2]：20，不加到output shape里，y的第二个维度会被求和(dot_axes[1]=2)\n",
    "#    结果为(100, 30)\n",
    "\n",
    "x_batch = K.ones(shape=(32, 20, 1))\n",
    "y_batch = K.ones(shape=(32, 30,20))\n",
    "xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])\n",
    "print('K.int_shape(xy_batch_dot):',K.int_shape(xy_batch_dot))\n",
    "\n",
    "x_batch = K.ones(shape=(2,2, 1))\n",
    "y_batch = K.ones(shape=(2,3, 2))\n",
    "xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1,2])\n",
    "print('K.int_shape(xy_batch_dot):',K.int_shape(xy_batch_dot))\n",
    "print(K.eval(xy_batch_dot))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.eval(var):\n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "K.eval(var_transposed):\n",
      " [[1. 4.]\n",
      " [2. 5.]\n",
      " [3. 6.]]\n",
      "input: Tensor(\"Placeholder_35:0\", shape=(2, 3), dtype=float32)\n",
      "input_transposed: Tensor(\"transpose_5:0\", shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#transpose(x)\n",
    "#  张量转置，返回转置后的tensor，示例：\n",
    "var = K.variable([[1, 2, 3], [4, 5, 6]])\n",
    "print('K.eval(var):\\n',K.eval(var))\n",
    "var_transposed = K.transpose(var)\n",
    "print('K.eval(var_transposed):\\n',K.eval(var_transposed))\n",
    "\n",
    "input = K.placeholder((2, 3))\n",
    "print('input:',input)\n",
    "input_transposed = K.transpose(input)\n",
    "print('input_transposed:',input_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_98:0' shape=(3, 4, 5) dtype=float32_ref>\n",
      "Tensor(\"embedding_lookup_4:0\", shape=(2, 4, 5), dtype=float32)\n",
      "<tf.Variable 'Variable_100:0' shape=(4, 5) dtype=float32_ref>\n",
      "Tensor(\"embedding_lookup_5:0\", shape=(2, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#gather(reference, indices)\n",
    "#  在给定的2D张量中检索给定下标的向量\n",
    "#参数：\n",
    "#    reference：2D张量\n",
    "#    indices：整数张量，其元素为要查询的下标\n",
    "#返回值：一个与reference数据类型相同的3D张量\n",
    "np_val=np.random.random((3,4,5))\n",
    "var=K.variable(value=np_val)\n",
    "indices=K.variable(value=[0,1],dtype='int32')\n",
    "gather_var=K.gather(var,indices)\n",
    "print(var)\n",
    "print(gather_var)\n",
    "\n",
    "np_val=np.random.random((4,5))\n",
    "var=K.variable(value=np_val)\n",
    "indices=K.variable(value=[0,1],dtype='int32')\n",
    "gather_var=K.gather(var,indices)\n",
    "print(var)\n",
    "print(gather_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_val:\n",
      " [[[1.31411829e-01 5.63953442e-01 3.17394308e-01 9.22746806e-01]\n",
      "  [8.45743250e-03 2.55561525e-04 1.87091242e-01 6.36773350e-01]\n",
      "  [3.38401413e-01 6.61877545e-01 1.88218115e-01 8.26177343e-01]]\n",
      "\n",
      " [[4.94803903e-01 2.35665208e-01 3.89225123e-01 9.47078016e-01]\n",
      "  [1.94513753e-01 7.52559173e-01 3.69761544e-01 7.13435253e-01]\n",
      "  [9.52236423e-01 4.58220393e-01 7.51677989e-01 1.17848928e-01]]]\n",
      "max_x:\n",
      " 0.9522364\n",
      "max_x:\n",
      " [[0.4948039  0.56395346 0.38922513 0.947078  ]\n",
      " [0.19451375 0.7525592  0.36976156 0.71343523]\n",
      " [0.9522364  0.6618776  0.751678   0.82617736]]\n",
      "max_x:\n",
      " [[0.3384014  0.6618776  0.31739432 0.9227468 ]\n",
      " [0.9522364  0.7525592  0.751678   0.947078  ]]\n",
      "max_x:\n",
      " [[0.9227468  0.63677335 0.82617736]\n",
      " [0.947078   0.7525592  0.9522364 ]]\n"
     ]
    }
   ],
   "source": [
    "#max(x, axis=None, keepdims=False)\n",
    "#  求张量中的最大值\n",
    "np_val=np.random.random((2,3,4))\n",
    "print('np_val:\\n',np_val)\n",
    "x=K.variable(value=np_val)\n",
    "max_x=K.max(x)\n",
    "print('max_x:\\n',K.eval(max_x))\n",
    "max_x=K.max(x,axis=0)\n",
    "print('max_x:\\n',K.eval(max_x))\n",
    "max_x=K.max(x,axis=1)\n",
    "print('max_x:\\n',K.eval(max_x))\n",
    "max_x=K.max(x,axis=2)\n",
    "print('max_x:\\n',K.eval(max_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_val:\n",
      " [[[0.94847442 0.19557186 0.1675426  0.90220799]\n",
      "  [0.67798362 0.45490861 0.10340898 0.45392399]\n",
      "  [0.91264745 0.42802316 0.6381998  0.08298229]]\n",
      "\n",
      " [[0.89808619 0.87338439 0.63070408 0.07428057]\n",
      "  [0.45907634 0.21111644 0.59305023 0.72040462]\n",
      "  [0.41785239 0.93421643 0.42992735 0.16800685]]]\n",
      "min_x:\n",
      " 0.074280575\n",
      "min_x:\n",
      " [[0.8980862  0.19557185 0.1675426  0.07428057]\n",
      " [0.45907634 0.21111645 0.10340898 0.453924  ]\n",
      " [0.4178524  0.42802316 0.42992735 0.08298229]]\n",
      "min_x:\n",
      " [[0.67798364 0.19557185 0.10340898 0.08298229]\n",
      " [0.4178524  0.21111645 0.42992735 0.07428057]]\n",
      "min_x:\n",
      " [[0.1675426  0.10340898 0.08298229]\n",
      " [0.07428057 0.21111645 0.16800685]]\n"
     ]
    }
   ],
   "source": [
    "#min(x, axis=None, keepdims=False)\n",
    "#  求张量中的最小值\n",
    "np_val=np.random.random((2,3,4))\n",
    "print('np_val:\\n',np_val)\n",
    "x=K.variable(value=np_val)\n",
    "min_x=K.min(x)\n",
    "print('min_x:\\n',K.eval(min_x))\n",
    "min_x=K.min(x,axis=0)\n",
    "print('min_x:\\n',K.eval(min_x))\n",
    "min_x=K.min(x,axis=1)\n",
    "print('min_x:\\n',K.eval(min_x))\n",
    "min_x=K.min(x,axis=2)\n",
    "print('min_x:\\n',K.eval(min_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_val:\n",
      " [[[0.17712808 0.96672699 0.18601349 0.96360343]\n",
      "  [0.90528473 0.59740785 0.05772159 0.41617274]\n",
      "  [0.6886427  0.41530343 0.26504028 0.12073365]]\n",
      "\n",
      " [[0.30981784 0.1741021  0.17489191 0.71479188]\n",
      "  [0.30590318 0.58069403 0.88076418 0.0220839 ]\n",
      "  [0.99017032 0.97092972 0.78773541 0.88923502]]]\n",
      "sum_x:\n",
      " 12.560899\n",
      "sum_x:\n",
      " [[0.48694593 1.1408291  0.3609054  1.6783953 ]\n",
      " [1.2111878  1.1781019  0.93848574 0.43825665]\n",
      " [1.678813   1.3862332  1.0527756  1.0099686 ]]\n",
      "sum_x:\n",
      " [[1.7710555  1.9794383  0.50877535 1.5005099 ]\n",
      " [1.6058912  1.7257259  1.8433914  1.6261108 ]]\n",
      "sum_x:\n",
      " [[2.293472  1.9765869 1.48972  ]\n",
      " [1.3736038 1.7894453 3.6380706]]\n"
     ]
    }
   ],
   "source": [
    "#sum(x, axis=None, keepdims=False)\n",
    "#  在给定轴上计算张量中元素之和\n",
    "np_val=np.random.random((2,3,4))\n",
    "print('np_val:\\n',np_val)\n",
    "x=K.variable(value=np_val)\n",
    "sum_x=K.sum(x)\n",
    "print('sum_x:\\n',K.eval(sum_x))\n",
    "sum_x=K.sum(x,axis=0)\n",
    "print('sum_x:\\n',K.eval(sum_x))\n",
    "sum_x=K.sum(x,axis=1)\n",
    "print('sum_x:\\n',K.eval(sum_x))\n",
    "sum_x=K.sum(x,axis=2)\n",
    "print('sum_x:\\n',K.eval(sum_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_val:\n",
      " [[[0.34574024 0.66155685 0.38360644 0.26711819]\n",
      "  [0.67762723 0.20639704 0.4490393  0.89007383]\n",
      "  [0.71654525 0.29003523 0.72316524 0.57168247]]\n",
      "\n",
      " [[0.09039276 0.82544141 0.68799535 0.25255285]\n",
      "  [0.44146853 0.47313552 0.48685166 0.19368599]\n",
      "  [0.05247178 0.80529524 0.8618623  0.81355364]]]\n",
      "prod_x:\n",
      " 8.5161e-10\n",
      "prod_x:\n",
      " [[0.03125241 0.5460764  0.26391944 0.06746146]\n",
      " [0.2991511  0.09765378 0.21861553 0.17239483]\n",
      " [0.0375984  0.233564   0.62326884 0.46509433]]\n",
      "prod_x:\n",
      " [[0.16787435 0.03960239 0.12456837 0.13592032]\n",
      " [0.00209392 0.31450456 0.28868225 0.03979575]]\n",
      "prod_x:\n",
      " [[0.02343724 0.05589909 0.08591852]\n",
      " [0.01296456 0.0196961  0.02962818]]\n"
     ]
    }
   ],
   "source": [
    "#prod(x, axis=None, keepdims=False)\n",
    "#  在给定轴上计算张量中元素之积\n",
    "np_val=np.random.random((2,3,4))\n",
    "print('np_val:\\n',np_val)\n",
    "x=K.variable(value=np_val)\n",
    "prod_x=K.prod(x)\n",
    "print('prod_x:\\n',K.eval(prod_x))\n",
    "prod_x=K.prod(x,axis=0)\n",
    "print('prod_x:\\n',K.eval(prod_x))\n",
    "prod_x=K.prod(x,axis=1)\n",
    "print('prod_x:\\n',K.eval(prod_x))\n",
    "prod_x=K.prod(x,axis=2)\n",
    "print('prod_x:\\n',K.eval(prod_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_val:\n",
      " [[[0.35284558 0.88251151 0.31220217 0.10453733]\n",
      "  [0.24418881 0.94908085 0.1567528  0.19312555]\n",
      "  [0.87341624 0.20491909 0.0999985  0.56485595]]\n",
      "\n",
      " [[0.62442646 0.02635919 0.71567655 0.95794761]\n",
      "  [0.23131146 0.78751582 0.31638346 0.54967745]\n",
      "  [0.23266986 0.06654846 0.86820463 0.32407783]]]\n",
      "var_x:\n",
      " 0.09438578\n",
      "var_x:\n",
      " [[1.8439047e-02 1.8324919e-01 4.0697888e-02 1.8207727e-01]\n",
      " [4.1456602e-05 6.5258127e-03 6.3704867e-03 3.1782310e-02]\n",
      " [1.0263898e-01 4.7866078e-03 1.4753518e-01 1.4493522e-02]]\n",
      "var_x:\n",
      " [[0.07541414 0.11303774 0.00804622 0.0397694 ]\n",
      " [0.03422384 0.12230762 0.05413405 0.06881896]]\n",
      "var_x:\n",
      " [[0.08234225 0.10673127 0.09355801]\n",
      " [0.11743488 0.04693227 0.09030651]]\n"
     ]
    }
   ],
   "source": [
    "#var(x, axis=None, keepdims=False)\n",
    "#  在给定轴上计算张量方差\n",
    "np_val=np.random.random((2,3,4))\n",
    "print('np_val:\\n',np_val)\n",
    "x=K.variable(value=np_val)\n",
    "var_x=K.var(x)\n",
    "print('var_x:\\n',K.eval(var_x))\n",
    "var_x=K.var(x,axis=0)\n",
    "print('var_x:\\n',K.eval(var_x))\n",
    "var_x=K.var(x,axis=1)\n",
    "print('var_x:\\n',K.eval(var_x))\n",
    "var_x=K.var(x,axis=2)\n",
    "print('var_x:\\n',K.eval(var_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_val:\n",
      " [[[0.05977404 0.20152378 0.52515561 0.481173  ]\n",
      "  [0.77147087 0.20253868 0.30459003 0.17935439]\n",
      "  [0.96887069 0.92178327 0.70491862 0.62311386]]\n",
      "\n",
      " [[0.81551875 0.63817568 0.50782808 0.55483277]\n",
      "  [0.18868109 0.50049538 0.97294642 0.52714189]\n",
      "  [0.27565026 0.93928177 0.74023229 0.64846093]]]\n",
      "std_x:\n",
      " 0.2694572\n",
      "std_x:\n",
      " [[0.37787238 0.21832594 0.00866377 0.03682987]\n",
      " [0.2913949  0.14897834 0.33417818 0.17389373]\n",
      " [0.34661022 0.00874925 0.01765683 0.01267353]]\n",
      "std_x:\n",
      " [[0.3904322  0.33929458 0.16371618 0.18504177]\n",
      " [0.27727783 0.18322852 0.1898838  0.05190947]]\n",
      "std_x:\n",
      " [[0.19350804 0.2396481  0.14455998]\n",
      " [0.11732095 0.27945456 0.24081248]]\n"
     ]
    }
   ],
   "source": [
    "#std(x, axis=None, keepdims=False)\n",
    "#  在给定轴上求张量元素之标准差\n",
    "np_val=np.random.random((2,3,4))\n",
    "print('np_val:\\n',np_val)\n",
    "x=K.variable(value=np_val)\n",
    "std_x=K.std(x)\n",
    "print('std_x:\\n',K.eval(std_x))\n",
    "std_x=K.std(x,axis=0)\n",
    "print('std_x:\\n',K.eval(std_x))\n",
    "std_x=K.std(x,axis=1)\n",
    "print('std_x:\\n',K.eval(std_x))\n",
    "std_x=K.std(x,axis=2)\n",
    "print('std_x:\\n',K.eval(std_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_val:\n",
      " [[[0.93956801 0.37005287 0.23761147 0.97642838]\n",
      "  [0.96089167 0.95410779 0.32678373 0.01124815]\n",
      "  [0.43376105 0.34766343 0.71113554 0.79964745]]\n",
      "\n",
      " [[0.22695161 0.75725425 0.22871023 0.80702581]\n",
      "  [0.43823239 0.56308911 0.11457299 0.89704138]\n",
      "  [0.28099254 0.99503055 0.89045146 0.86791718]]]\n",
      "mean_x:\n",
      " 0.5890071\n",
      "mean_x:\n",
      " [[0.5832598  0.5636536  0.23316085 0.8917271 ]\n",
      " [0.699562   0.75859845 0.22067836 0.45414478]\n",
      " [0.3573768  0.67134696 0.8007935  0.8337823 ]]\n",
      "mean_x:\n",
      " [[0.7780736  0.55727464 0.42517695 0.59577465]\n",
      " [0.31539217 0.7717913  0.4112449  0.8573281 ]]\n",
      "mean_x:\n",
      " [[0.63091516 0.5632578  0.5730519 ]\n",
      " [0.50498545 0.50323397 0.75859797]]\n"
     ]
    }
   ],
   "source": [
    "#mean(x, axis=None, keepdims=False)\n",
    "#  在给定轴上求张量元素之均值\n",
    "np_val=np.random.random((2,3,4))\n",
    "print('np_val:\\n',np_val)\n",
    "x=K.variable(value=np_val)\n",
    "mean_x=K.mean(x)\n",
    "print('mean_x:\\n',K.eval(mean_x))\n",
    "mean_x=K.mean(x,axis=0)\n",
    "print('mean_x:\\n',K.eval(mean_x))\n",
    "mean_x=K.mean(x,axis=1)\n",
    "print('mean_x:\\n',K.eval(mean_x))\n",
    "mean_x=K.mean(x,axis=2)\n",
    "print('mean_x:\\n',K.eval(mean_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_val:\n",
      " [[[1 1 0 1]\n",
      "  [1 1 1 1]\n",
      "  [1 0 1 0]]\n",
      "\n",
      " [[1 1 0 1]\n",
      "  [1 2 2 2]\n",
      "  [1 0 2 0]]]\n",
      "any_x:\n",
      " True\n",
      "any_x:\n",
      " [[ True  True False  True]\n",
      " [ True  True  True  True]\n",
      " [ True False  True False]]\n",
      "any_x:\n",
      " [[ True  True  True  True]\n",
      " [ True  True  True  True]]\n",
      "any_x:\n",
      " [[ True  True  True]\n",
      " [ True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "#any(x, axis=None, keepdims=False)\n",
    "#  按位或，返回数据类型为uint8的张量（元素为0或1）\n",
    "np_val=np.random.randint(0,3,size=(2,3,4))\n",
    "print('np_val:\\n',np_val)\n",
    "x=K.variable(value=np_val)\n",
    "any_x=K.any(x)\n",
    "print('any_x:\\n',K.eval(any_x))\n",
    "any_x=K.any(x,axis=0)\n",
    "print('any_x:\\n',K.eval(any_x))\n",
    "any_x=K.any(x,axis=1)\n",
    "print('any_x:\\n',K.eval(any_x))\n",
    "any_x=K.any(x,axis=2)\n",
    "print('any_x:\\n',K.eval(any_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_val:\n",
      " [[[0 2 1 2]\n",
      "  [2 2 1 2]\n",
      "  [0 1 0 2]]\n",
      "\n",
      " [[2 0 0 1]\n",
      "  [1 0 0 2]\n",
      "  [0 0 1 0]]]\n",
      "all_x:\n",
      " False\n",
      "all_x:\n",
      " [[False False False  True]\n",
      " [ True False False  True]\n",
      " [False False False False]]\n",
      "all_x:\n",
      " [[False  True False  True]\n",
      " [False False False False]]\n",
      "all_x:\n",
      " [[False  True False]\n",
      " [False False False]]\n"
     ]
    }
   ],
   "source": [
    "#all(x, axis=None, keepdims=False)\n",
    "#  按位与，返回类型为uint8de tensor\n",
    "np_val=np.random.randint(0,3,size=(2,3,4))\n",
    "print('np_val:\\n',np_val)\n",
    "x=K.variable(value=np_val)\n",
    "all_x=K.all(x)\n",
    "print('all_x:\\n',K.eval(all_x))\n",
    "all_x=K.all(x,axis=0)\n",
    "print('all_x:\\n',K.eval(all_x))\n",
    "all_x=K.all(x,axis=1)\n",
    "print('all_x:\\n',K.eval(all_x))\n",
    "all_x=K.all(x,axis=2)\n",
    "print('all_x:\\n',K.eval(all_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_val:\n",
      " [[[2 1 0 2]\n",
      "  [1 2 2 0]\n",
      "  [0 2 0 2]]\n",
      "\n",
      " [[0 0 0 2]\n",
      "  [0 2 1 0]\n",
      "  [0 2 0 0]]]\n",
      "argmax_x:\n",
      " [[0 1 1]\n",
      " [3 1 1]]\n",
      "argmax_x:\n",
      " [[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "argmax_x:\n",
      " [[0 1 1 0]\n",
      " [0 1 1 0]]\n",
      "argmax_x:\n",
      " [[0 1 1]\n",
      " [3 1 1]]\n"
     ]
    }
   ],
   "source": [
    "#argmax(x, axis=-1)\n",
    "#  在给定轴上求张量之最大元素下标\n",
    "np_val=np.random.randint(0,3,size=(2,3,4))\n",
    "print('np_val:\\n',np_val)\n",
    "x=K.variable(value=np_val)\n",
    "argmax_x=K.argmax(x)\n",
    "print('argmax_x:\\n',K.eval(argmax_x))\n",
    "argmax_x=K.argmax(x,axis=0)\n",
    "print('argmax_x:\\n',K.eval(argmax_x))\n",
    "argmax_x=K.argmax(x,axis=1)\n",
    "print('argmax_x:\\n',K.eval(argmax_x))\n",
    "argmax_x=K.argmax(x,axis=2)\n",
    "print('argmax_x:\\n',K.eval(argmax_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats: <tf.Variable 'Variable_124:0' shape=(2, 3, 4, 5) dtype=float32_ref>\n",
      "grid_y: Tensor(\"Tile_8:0\", shape=(3, 4, 1, 1), dtype=int32)\n",
      "grid_y.eval():\n",
      " [[[[0]]\n",
      "\n",
      "  [[0]]\n",
      "\n",
      "  [[0]]\n",
      "\n",
      "  [[0]]]\n",
      "\n",
      "\n",
      " [[[1]]\n",
      "\n",
      "  [[1]]\n",
      "\n",
      "  [[1]]\n",
      "\n",
      "  [[1]]]\n",
      "\n",
      "\n",
      " [[[2]]\n",
      "\n",
      "  [[2]]\n",
      "\n",
      "  [[2]]\n",
      "\n",
      "  [[2]]]]\n",
      "grid_x: Tensor(\"Tile_9:0\", shape=(3, 4, 1, 1), dtype=int32)\n",
      "grid_x.eval():\n",
      " [[[[0]]\n",
      "\n",
      "  [[1]]\n",
      "\n",
      "  [[2]]\n",
      "\n",
      "  [[3]]]\n",
      "\n",
      "\n",
      " [[[0]]\n",
      "\n",
      "  [[1]]\n",
      "\n",
      "  [[2]]\n",
      "\n",
      "  [[3]]]\n",
      "\n",
      "\n",
      " [[[0]]\n",
      "\n",
      "  [[1]]\n",
      "\n",
      "  [[2]]\n",
      "\n",
      "  [[3]]]]\n",
      "grid: Tensor(\"Cast_29:0\", shape=(3, 4, 1, 2), dtype=float32)\n",
      "grid.eval(): [[[[0. 0.]]\n",
      "\n",
      "  [[1. 0.]]\n",
      "\n",
      "  [[2. 0.]]\n",
      "\n",
      "  [[3. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 1.]]\n",
      "\n",
      "  [[1. 1.]]\n",
      "\n",
      "  [[2. 1.]]\n",
      "\n",
      "  [[3. 1.]]]\n",
      "\n",
      "\n",
      " [[[0. 2.]]\n",
      "\n",
      "  [[1. 2.]]\n",
      "\n",
      "  [[2. 2.]]\n",
      "\n",
      "  [[3. 2.]]]]\n"
     ]
    }
   ],
   "source": [
    "feats_val=np.random.random((2,3,4,5))\n",
    "feats=K.variable(value=feats_val)\n",
    "grid_shape = K.shape(feats)[1:3] # height, width; FeatureMap大小\n",
    "grid_y = K.tile(K.reshape(K.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]),[1, grid_shape[1], 1, 1])\n",
    "grid_x = K.tile(K.reshape(K.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),[grid_shape[0], 1, 1, 1])\n",
    "grid = K.concatenate([grid_x, grid_y])\n",
    "grid = K.cast(grid, K.dtype(feats))\n",
    "#print('feats_val:\\n',feats_val)\n",
    "print('feats:',feats)\n",
    "print('grid_y:',grid_y)\n",
    "print('grid_y.eval():\\n',K.eval(grid_y))\n",
    "print('grid_x:',grid_x)\n",
    "print('grid_x.eval():\\n',K.eval(grid_x))\n",
    "print('grid:',grid)\n",
    "print('grid.eval():',K.eval(grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
