{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取mat数据文件范例\n",
    "    https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.io.loadmat.html\n",
    "    scipy.io.loadmat\n",
    "    scipy.io.loadmat(file_name, mdict=None, appendmat=True, **kwargs)[source]\n",
    "\n",
    "    Load MATLAB file.\n",
    "    Parameters:\t\n",
    "\n",
    "    file_name : str\n",
    "        Name of the mat file (do not need .mat extension if appendmat==True). Can also pass open file-like object.\n",
    "\n",
    "    mdict : dict, optional\n",
    "        Dictionary in which to insert matfile variables.\n",
    "\n",
    "    appendmat : bool, optional\n",
    "        True to append the .mat extension to the end of the given filename, if not already present.\n",
    "\n",
    "    byte_order : str or None, optional\n",
    "        None by default, implying byte order guessed from mat file. Otherwise can be one of (‘native’, ‘=’, ‘little’, ‘<’, ‘BIG’, ‘>’).\n",
    "\n",
    "    mat_dtype : bool, optional\n",
    "        If True, return arrays in same dtype as would be loaded into MATLAB (instead of the dtype with which they are saved).\n",
    "\n",
    "    squeeze_me : bool, optional\n",
    "        Whether to squeeze unit matrix dimensions or not.\n",
    "\n",
    "    chars_as_strings : bool, optional\n",
    "        Whether to convert char arrays to string arrays.\n",
    "\n",
    "    matlab_compatible : bool, optional\n",
    "        Returns matrices as would be loaded by MATLAB (implies squeeze_me=False, chars_as_strings=False, mat_dtype=True, struct_as_record=True).\n",
    "\n",
    "    struct_as_record : bool, optional\n",
    "        Whether to load MATLAB structs as numpy record arrays, or as old-style numpy arrays with dtype=object. Setting this flag to False replicates the behavior of scipy version 0.7.x (returning numpy object arrays). The default setting is True, because it allows easier round-trip load and save of MATLAB files.\n",
    "\n",
    "    verify_compressed_data_integrity : bool, optional\n",
    "        Whether the length of compressed sequences in the MATLAB file should be checked, to ensure that they are not longer than we expect. It is advisable to enable this (the default) because overlong compressed sequences in MATLAB files generally indicate that the files have experienced some sort of corruption.\n",
    "\n",
    "    variable_names : None or sequence\n",
    "        If None (the default) - read all variables in file. Otherwise variable_names should be a sequence of strings, giving names of the matlab variables to read from the file. The reader will skip any variable with a name not in this sequence, possibly saving some read processing.\n",
    "\n",
    "    Returns:\t\n",
    "\n",
    "    mat_dict : dict\n",
    "        dictionary with variable names as keys, and loaded matrices as values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat \n",
    "\n",
    "data_file='%s/work/data/gtest/1.mat'%os.getenv('HOME') #数据文件\n",
    "\n",
    "data=loadmat(data_file) #加载数据文件\n",
    "#data.clear\n",
    "#data.copy\n",
    "#data.fromkeys\n",
    "#data.get\n",
    "#data.items\n",
    "#data.keys\n",
    "#data.pop\n",
    "#data.popitem\n",
    "#data.setdefault\n",
    "#data.update\n",
    "#data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "顶层数据结构\n",
      "__version__:<class 'str'>\n",
      "__header__:<class 'bytes'>\n",
      "synsets:<class 'numpy.ndarray'>\n",
      "__globals__:<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#顶层数据结构\n",
    "print('顶层数据结构')\n",
    "for k,v in data.items():\n",
    "    print('%s:%s'%(k,type(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "顶层关键字\n",
      "key:__version__\n",
      "key:__header__\n",
      "key:synsets\n",
      "key:__globals__\n"
     ]
    }
   ],
   "source": [
    "#顶层关键字\n",
    "print('顶层关键字')\n",
    "for k in data.keys():\n",
    "    print('key:%s'%(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1860, 1)\n",
      "[('ILSVRC2012_ID', 'O'), ('WNID', 'O'), ('words', 'O'), ('gloss', 'O'), ('num_children', 'O'), ('children', 'O'), ('wordnet_height', 'O'), ('num_train_images', 'O')]\n",
      "----------0---------------\n",
      "[array([[1]], dtype=uint8)]\n",
      "[array(['n02119789'], dtype='<U9')]\n",
      "[array(['kit fox, Vulpes macrotis'], dtype='<U24')]\n",
      "[array(['small grey fox of southwestern United States; may be a subspecies of Vulpes velox'],\n",
      "      dtype='<U81')]\n",
      "[array([[0]], dtype=uint8)]\n",
      "[array([], shape=(1, 0), dtype=uint8)]\n",
      "[array([[0]], dtype=uint8)]\n",
      "[array([[1300]], dtype=uint16)]\n",
      "----------1---------------\n",
      "[array([[2]], dtype=uint8)]\n",
      "[array(['n02100735'], dtype='<U9')]\n",
      "[array(['English setter'], dtype='<U14')]\n",
      "[array(['an English breed having a plumed tail and a soft silky coat that is chiefly white'],\n",
      "      dtype='<U81')]\n",
      "[array([[0]], dtype=uint8)]\n",
      "[array([], shape=(1, 0), dtype=uint8)]\n",
      "[array([[0]], dtype=uint8)]\n",
      "[array([[1300]], dtype=uint16)]\n"
     ]
    }
   ],
   "source": [
    "#数据集\n",
    "datasets=data['synsets']\n",
    "print(datasets.shape)\n",
    "print(datasets.dtype)\n",
    "\n",
    "for i in range(2):\n",
    "    print('----------%d---------------'%(i))\n",
    "    print(datasets[i]['ILSVRC2012_ID'])      #数据集训练LabelID\n",
    "    print(datasets[i]['WNID'])               #WordNet ID\n",
    "    print(datasets[i]['words'])              #简称\n",
    "    print(datasets[i]['gloss'])              #注释:print(datasets[i]['gloss'][0][0])\n",
    "    print(datasets[i]['num_children'])       #\n",
    "    print(datasets[i]['children'])           #\n",
    "    print(datasets[i]['wordnet_height'])     #\n",
    "    print(datasets[i]['num_train_images'])   #训练样本数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
