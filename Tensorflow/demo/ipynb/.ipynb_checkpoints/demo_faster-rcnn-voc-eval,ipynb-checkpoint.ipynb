{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# py-faster-rcnn-master /lib/datasets/voc_eval.py代码解析\n",
    "    在\n",
    "        Faster R-CNN/R-FCN里mAP的计算过程（voc_eval.py解析）\n",
    "        https://blog.csdn.net/hongxingabc/article/details/80090736\n",
    "    基础上补充注释!\n",
    "    \n",
    "    GitHub:https://github.com/rbgirshick/py-faster-rcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# Fast/er R-CNN\n",
    "# Licensed under The MIT License [see LICENSE for details]\n",
    "# Written by Bharath Hariharan\n",
    "# --------------------------------------------------------\n",
    " \n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "#import cPickle\n",
    "import _pickle as cPickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def parse_rec(filename): #读取标注的xml文件\n",
    "    \"\"\" Parse a PASCAL VOC xml file \"\"\"\n",
    "    tree = ET.parse(filename)\n",
    "    objects = []\n",
    "    for obj in tree.findall('object'):\n",
    "        obj_struct = {}\n",
    "        obj_struct['name'] = obj.find('name').text\n",
    "        obj_struct['pose'] = obj.find('pose').text\n",
    "        obj_struct['truncated'] = int(obj.find('truncated').text)\n",
    "        obj_struct['difficult'] = int(obj.find('difficult').text)\n",
    "        bbox = obj.find('bndbox')\n",
    "        obj_struct['bbox'] = [int(bbox.find('xmin').text),\n",
    "                              int(bbox.find('ymin').text),\n",
    "                              int(bbox.find('xmax').text),\n",
    "                              int(bbox.find('ymax').text)]\n",
    "        objects.append(obj_struct)\n",
    " \n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def voc_ap(rec, prec, use_07_metric=False):\n",
    "    \"\"\" ap = voc_ap(rec, prec, [use_07_metric])\n",
    "    Compute VOC AP given precision and recall.\n",
    "    If use_07_metric is true, uses the\n",
    "    VOC 07 11 point method (default:False).\n",
    "    计算AP值，若use_07_metric=true,则用11个点采样的方法，将rec从0-1分成11个点，这些点prec值求平均近似表示AP\n",
    "    若use_07_metric=false,则采用更为精确的逐点积分方法\n",
    "    \"\"\"\n",
    "    if use_07_metric:\n",
    "        # 11 point metric\n",
    "        ap = 0.\n",
    "        for t in np.arange(0., 1.1, 0.1):\n",
    "            if np.sum(rec >= t) == 0:\n",
    "                p = 0\n",
    "            else:\n",
    "                p = np.max(prec[rec >= t])\n",
    "            ap = ap + p / 11.\n",
    "    else:\n",
    "        # correct AP calculation\n",
    "        # first append sentinel values at the end\n",
    "        mrec = np.concatenate(([0.], rec, [1.]))\n",
    "        mpre = np.concatenate(([0.], prec, [0.]))\n",
    " \n",
    "        # compute the precision envelope\n",
    "        for i in range(mpre.size - 1, 0, -1):\n",
    "            mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    " \n",
    "        # to calculate area under PR curve, look for points\n",
    "        # where X axis (recall) changes value\n",
    "        i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    " \n",
    "        # and sum (\\Delta recall) * prec\n",
    "        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######主函数，计算当前类别的recall和precision ，原来的函数代码\n",
    "def voc_eval(detpath,            #检测结果文件\n",
    "             annopath,           #标记目录\n",
    "             imagesetfile,       #检测图像文件名\n",
    "             classname,          #筛选类别名称\n",
    "             cachedir,           #缓存目录\n",
    "             ovthresh=0.5,       #阈值\n",
    "             use_07_metric=False #AP计算方式\n",
    "            ):\n",
    "    \"\"\"rec, prec, ap = voc_eval(detpath,\n",
    "                                annopath,\n",
    "                                imagesetfile,\n",
    "                                classname,\n",
    "                                [ovthresh],\n",
    "                                [use_07_metric])\n",
    "    Top level function that does the PASCAL VOC evaluation.\n",
    "    #detpath检测结果txt文件，路径VOCdevkit/results/VOC20xx/Main/<comp_id>_det_test_aeroplane.txt。\n",
    "    该文件格式: imagename1 confidence xmin ymin xmax ymax  (图像1的第一个结果)\n",
    "               imagename1 confidence xmin ymin xmax ymax  (图像1的第二个结果)\n",
    "               imagename1 confidence xmin ymin xmax ymax  (图像2的第一个结果)\n",
    "               ......\n",
    "        每个结果占一行，检测到多少个BBox就有多少行，这里假设有20000个检测结果\n",
    "    \n",
    "    detpath: Path to detections\n",
    "        detpath.format(classname) should produce the detection results file.\n",
    "    annopath: Path to annotations\n",
    "        annopath.format(imagename) should be the xml annotations file. #xml 标注文件。\n",
    "    imagesetfile: Text file containing the list of images, one image per line. #数据集划分txt文件，路径VOCdevkit/VOC20xx/ImageSets/Main/test.txt这里假设测试图像1000张，那么该txt文件1000行。\n",
    "    classname: Category name (duh) #种类的名字，即类别，假设类别2（一类目标+背景）。\n",
    "    cachedir: Directory for caching the annotations #缓存标注的目录路径VOCdevkit/annotation_cache,图像数据只读文件，为了避免每次都要重新读数据集原始数据。\n",
    "    [ovthresh]: Overlap threshold (default = 0.5) #重叠的多少大小。\n",
    "    [use_07_metric]: Whether to use VOC07's 11 point AP computation \n",
    "        (default False) #是否使用VOC07的AP计算方法，voc07是11个点采样。\n",
    "    \"\"\"\n",
    "    ##############################################################\n",
    "    '''\n",
    "    @param detpath      [str ]某类检测结果文件\n",
    "        detpath.format(classname) should produce the detection results file.\n",
    "        detpath=>'test/det_test_{}.txt'=>detpath.format('aeroplane')=> 'test/det_test_aeroplane.txt'\n",
    "        路径VOCdevkit/results/VOC20xx/Main/<comp_id>_det_test_aeroplane.txt。\n",
    "        该文件格式: imagename1 confidence xmin ymin xmax ymax  (图像1的第一个结果)\n",
    "                   imagename1 confidence xmin ymin xmax ymax  (图像1的第二个结果)\n",
    "                   imagename2 confidence xmin ymin xmax ymax  (图像2的第一个结果)\n",
    "    @param annopath     [str ]标注目录\n",
    "        annopath.format(imagename) should be the xml annotations file. #xml 标注文件。\n",
    "        annopath=>'annotations/{}.xml'=>annopath.format('2008_000001')=>'annotations/2008_000001.xml'\n",
    "    @param imagesetfile [str ]检测图像集文件\n",
    "        文本文件，每行一个图像文件名,不含扩展名\n",
    "        该文件格式：\n",
    "            2008_000001\n",
    "            2008_000002\n",
    "    @param classname     [str  ]检测类别名称，用于筛选imagesetfile\n",
    "    @param cachedir      [str  ]缓存目录，用于存放原始数据集的加载文件\n",
    "    @param ovthresh      [float]IoU阈值\n",
    "    @param use_07_metric [bool ]AP计算模式\n",
    "        Whether to use VOC07's 11 point AP computation \n",
    "                (default False) #是否使用VOC07的AP计算方法，voc07是11个点采样。    \n",
    "    @return rec, prec, ap\n",
    "        rec ---召回率，向量\n",
    "        prec---准确率，向量\n",
    "        ap-----平均准确率,标量\n",
    "        计算方法：\n",
    "            检测结果数为:N=5\n",
    "            按置信度由高到低排序\n",
    "            TP/FP计算：\n",
    "                筛选某类的检测结果及该类的gt_bbox\n",
    "                TP[:],FP[:]初始化为False\n",
    "                遍历检测结果\n",
    "                    如果检测bbox与该类gt_bbox的IoU大于阈值,\n",
    "                    则\n",
    "                        TP[i]=1\n",
    "                        虚警处理(同一个gt_bbox在不同的检测结果中出现)：FP[i]=1\n",
    "                    否则\n",
    "                        FP[i]=1\n",
    "                    \n",
    "            TP:[1, 0, 1, 1, 0],积分值=>TP_int=[1,1,2,3,3]\n",
    "            FP:[0, 1, 0, 0, 1],积分值=>FP_int=[0,1,1,1,2]\n",
    "            prec:TP_int/(TP_int+FP_int)=>[1, 1/2, 2/3, 3/4, 3/5]\n",
    "            rec :TP_int/N=>[1/5, 1/5, 2/5, 3/5, 3/5]\n",
    "            ap:\n",
    "                if use_07_metric:\n",
    "                    # 11 point metric\n",
    "                    ap = 0.\n",
    "                    for t in np.arange(0., 1.1, 0.1):\n",
    "                        if np.sum(rec >= t) == 0:\n",
    "                            p = 0\n",
    "                        else:\n",
    "                            p = np.max(prec[rec >= t])\n",
    "                        ap = ap + p / 11.\n",
    "                else:\n",
    "                    # correct AP calculation\n",
    "                    # first append sentinel values at the end\n",
    "                    mrec = np.concatenate(([0.], rec, [1.]))\n",
    "                    mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "                    # compute the precision envelope\n",
    "                    for i in range(mpre.size - 1, 0, -1):\n",
    "                        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "                    # to calculate area under PR curve, look for points\n",
    "                    # where X axis (recall) changes value\n",
    "                    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "                    # and sum (\\Delta recall) * prec\n",
    "                    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])            \n",
    "    '''\n",
    "    # assumes detections are in detpath.format(classname)\n",
    "    # assumes annotations are in annopath.format(imagename)\n",
    "    # assumes imagesetfile is a text file with each line an image name\n",
    "    # cachedir caches the annotations in a pickle file\n",
    " \n",
    "    #原始数据集缓存文件 =>[str ] cachefile\n",
    "    # first load gt 加载ground truth。\n",
    "    if not os.path.isdir(cachedir):\n",
    "        os.mkdir(cachedir)\n",
    "    cachefile = os.path.join(cachedir, 'annots.pkl') #只读文件名称。\n",
    "    \n",
    "    #读取所有测试图片名称 =>[list] imagenames\n",
    "    # read list of images\n",
    "    with open(imagesetfile, 'r') as f:\n",
    "        lines = f.readlines() #读取所有待检测图片名。\n",
    "    imagenames = [x.strip() for x in lines] #待检测图像文件名字存于数组imagenames,长度1000。\n",
    " \n",
    "    #加载原始数据文件 =>[dict] recs{文件名:标注结构体数据}\n",
    "    if not os.path.isfile(cachefile): #如果只读文件不存在，则只好从原始数据集中重新加载数据\n",
    "        # load annots\n",
    "        recs = {}\n",
    "        for i, imagename in enumerate(imagenames):\n",
    "            recs[imagename] = parse_rec(annopath.format(imagename)) #parse_rec函数读取当前图像标注文件，返回当前图像标注，存于recs字典（key是图像名，values是gt）\n",
    "            if i % 100 == 0:\n",
    "                print('Reading annotation for {:d}/{:d}'.format(i + 1, len(imagenames))) #进度条。\n",
    "        # save\n",
    "        print('Saving cached annotations to {:s}'.format(cachefile))\n",
    "        with open(cachefile, 'w') as f:\n",
    "            cPickle.dump(recs, f) #recs字典c保存到只读文件。\n",
    "    else:\n",
    "        # load\n",
    "        with open(cachefile, 'r') as f:\n",
    "            recs = cPickle.load(f) #如果已经有了只读文件，加载到recs。\n",
    " \n",
    "    #提取类别为classname的原始数据集\n",
    "    # extract gt objects for this class #按类别获取标注文件，recall和precision都是针对不同类别而言的，AP也是对各个类别分别算的。\n",
    "    class_recs = {} #当前类别的标注\n",
    "    npos = 0 #npos标记的目标数量\n",
    "    for imagename in imagenames:\n",
    "        #筛选类别为classname的原始数据集 => R    \n",
    "        R = [obj for obj in recs[imagename] if obj['name'] == classname] #过滤，只保留recs中指定类别的项，存为R。\n",
    "        #提取bbox,gt\n",
    "        bbox = np.array([x['bbox'] for x in R]) #抽取bbox\n",
    "        difficult = np.array([x['difficult'] for x in R]).astype(np.bool) #如果数据集没有difficult,所有项都是0.\n",
    " \n",
    "        #检测结果,默认为False\n",
    "        det = [False] * len(R) #len(R)就是当前类别的gt目标个数，det表示是否检测到，初始化为false。\n",
    "        #gt目标数量(排除difficult为True的目标)\n",
    "        npos = npos + sum(~difficult) #自增，非difficult样本数量，如果数据集没有difficult，npos数量就是gt数量。\n",
    "        #当前类别标注(不含difficult为True的目标)\n",
    "        class_recs[imagename] = {'bbox': bbox,           #检测边框\n",
    "                                 'difficult': difficult, #difficult属性\n",
    "                                 'det': det              #检测结果\n",
    "                                }#三个属性值长度相同\n",
    "        \n",
    " \n",
    "    # read dets 读取检测结果\n",
    "    detfile = detpath.format(classname)\n",
    "    with open(detfile, 'r') as f:\n",
    "        lines = f.readlines()\n",
    " \n",
    "    splitlines = [x.strip().split(' ') for x in lines] #假设检测结果有20000个，则splitlines长度20000\n",
    "    image_ids = [x[0] for x in splitlines] #检测结果中的图像名，image_ids长度20000，但实际图像只有1000张，因为一张图像上可以有多个目标检测结果\n",
    "    confidence = np.array([float(x[1]) for x in splitlines]) #检测结果置信度\n",
    "    BB = np.array([[float(z) for z in x[2:]] for x in splitlines]) #变为浮点型的bbox。\n",
    " \n",
    "    # sort by confidence 将20000各检测结果按置信度排序\n",
    "    sorted_ind = np.argsort(-confidence)           #对confidence的index根据值大小进行降序排列。\n",
    "    sorted_scores = np.sort(-confidence)           #降序排列。\n",
    "    BB = BB[sorted_ind, :]                         #重排bbox，由大概率到小概率。\n",
    "    image_ids = [image_ids[x] for x in sorted_ind] #对image_ids相应地进行重排。\n",
    " \n",
    "    # go down dets and mark TPs and FPs \n",
    "    nd = len(image_ids) #注意这里是20000，不是1000\n",
    "    tp = np.zeros(nd)   # true positive，长度20000\n",
    "    fp = np.zeros(nd)   # false positive，长度20000\n",
    "    for d in range(nd): #遍历所有检测结果，因为已经排序，所以这里是从置信度最高到最低遍历\n",
    "        R = class_recs[image_ids[d]]   #当前检测结果所在图像的所有同类别gt\n",
    "        bb = BB[d, :].astype(float)    #当前检测结果bbox坐标,1个bbox\n",
    "        ovmax = -np.inf\n",
    "        BBGT = R['bbox'].astype(float) #当前检测结果所在图像的所有同类别gt的bbox坐标,含有N个\n",
    " \n",
    "        if BBGT.size > 0: \n",
    "            # compute overlaps 计算当前检测结果，与该检测结果所在图像的标注重合率，一对多用到python的broadcast机制\n",
    "            # intersection\n",
    "            ixmin = np.maximum(BBGT[:, 0], bb[0])\n",
    "            iymin = np.maximum(BBGT[:, 1], bb[1])\n",
    "            ixmax = np.minimum(BBGT[:, 2], bb[2])\n",
    "            iymax = np.minimum(BBGT[:, 3], bb[3])\n",
    "            iw = np.maximum(ixmax - ixmin + 1., 0.)\n",
    "            ih = np.maximum(iymax - iymin + 1., 0.)\n",
    "            inters = iw * ih\n",
    " \n",
    "            # union\n",
    "            uni = ((bb[2] - bb[0] + 1.) * (bb[3] - bb[1] + 1.) +\n",
    "                   (BBGT[:, 2] - BBGT[:, 0] + 1.) *\n",
    "                   (BBGT[:, 3] - BBGT[:, 1] + 1.) - inters)\n",
    " \n",
    "            overlaps = inters / uni\n",
    "            ovmax = np.max(overlaps)  #最大重合率\n",
    "            jmax = np.argmax(overlaps)#最大重合率对应的gt\n",
    " \n",
    "        if ovmax > ovthresh:#如果当前检测结果与真实标注最大重合率满足阈值\n",
    "            if not R['difficult'][jmax]:\n",
    "                if not R['det'][jmax]:\n",
    "                    tp[d] = 1. #正检数目+1\n",
    "                    R['det'][jmax] = 1 #该gt被置为已检测到，下一次若还有另一个检测结果与之重合率满足阈值，则不能认为多检测到一个目标\n",
    "                else: #相反，认为检测到一个虚警\n",
    "                    fp[d] = 1.\n",
    "        else: #不满足阈值，肯定是虚警\n",
    "            fp[d] = 1.\n",
    " \n",
    "    # compute precision recall\n",
    "    fp = np.cumsum(fp) #积分图，在当前节点前的虚警数量，fp长度\n",
    "    tp = np.cumsum(tp) #积分图，在当前节点前的正检数量\n",
    "    rec = tp / float(npos) #召回率，长度20000，从0到1\n",
    "    # avoid divide by zero in case the first detection matches a difficult\n",
    "    # ground truth 准确率，长度20000，长度20000，从1到0\n",
    "    prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n",
    "    ap = voc_ap(rec, prec, use_07_metric)\n",
    " \n",
    "    return rec, prec, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
