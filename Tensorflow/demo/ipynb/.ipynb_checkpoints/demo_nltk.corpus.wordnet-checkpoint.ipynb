{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet使用范例\n",
    "    https://wordnet.princeton.edu/\n",
    "    http://www.nltk.org\n",
    "    \n",
    "    WordNet NLTK API\n",
    "    http://www.nltk.org/api/nltk.corpus.reader.html?highlight=wordnet#module-nltk.corpus.reader.wordnet\n",
    "\n",
    "* 在代码中引入wordnet包\n",
    "* 返回所有同义词集\n",
    "* 返回所有词条\n",
    "* 查询一个词所在的所有词集\n",
    "* 查询一个同义词集的定义\n",
    "* 查询词语一个词义的例子\n",
    "* 查询词语某种词性所在的同义词集合\n",
    "* 查询一个同义词集中的所有词\n",
    "* 输出词集和词的配对——词条\n",
    "* 利用词条查询反义词\n",
    "* 查询两个词之间的语义相似度\n",
    "* 获取词集路径 hypernym_paths()\n",
    "* 获取根上位词集root_hypernyms()\n",
    "* 获取上位词集\n",
    "* 获取下位词集\n",
    "* 打印词语树形结构\n",
    "\n",
    "#### WordNet\n",
    "    WordNet是由Princeton 大学的心理学家，语言学家和计算机工程师联合设计的一种基于认知语言学的英语词典。它不是光把单词以字母顺序排列，而且按照单词的意义组成一个“单词的网络”。\n",
    "\n",
    "名词概念：\n",
    "* synset:同义词集\n",
    "* Lammas:词条\n",
    "\n",
    "#### word2vec\n",
    "    Word2vec，是一群用来产生词向量的相关模型。这些模型为浅而双层的神经网络，用来训练以重新建构语言学之词文本。网络以词表现，并且需猜测相邻位置的输入词，在word2vec中词袋模型假设下，词的顺序是不重要的。训练完成之后，word2vec模型可用来映射每个词到一个向量，可用来表示词对词之间的关系，该向量为神经网络之隐藏层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在代码中引入wordnet包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 返回所有同义词集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('a_cappella.r.01')\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "lst=wn.all_synsets()\n",
    "#--list不能与next同时使用--\n",
    "\n",
    "#每次检索下一个结果，效率高\n",
    "val1=next(lst)   \n",
    "print(val1)\n",
    "\n",
    "#list一次返回所有结果，效率低\n",
    "#vals=list(lst)  \n",
    "#print(vals[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 返回所有词条"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict_keyiterator'>\n",
      "serratus_anterior\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "lst=wn.all_lemma_names()\n",
    "print(type(lst))\n",
    "val1=next(lst)\n",
    "print(val1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查询一个词所在的所有词集（synsets）\n",
    "\n",
    "    synsets(lemma, pos=None, lang='eng', check_exceptions=True)[source]\n",
    "\n",
    "    Load all synsets with a given lemma and part of speech tag. If no pos is specified, all synsets for all parts of speech will be loaded. If lang is specified, all the synsets associated with the lemma name of that language will be returned.\n",
    "\n",
    "    dog.n.01 => n-名词,01-第一个`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dog.n.01'),\n",
       " Synset('frump.n.01'),\n",
       " Synset('dog.n.03'),\n",
       " Synset('cad.n.01'),\n",
       " Synset('frank.n.02'),\n",
       " Synset('pawl.n.01'),\n",
       " Synset('andiron.n.01'),\n",
       " Synset('chase.v.01')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查询一个同义词集的定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n"
     ]
    }
   ],
   "source": [
    "print(wn.synset('dog.n.01').definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查询词语一个词义的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the dog barked all night']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('dog.n.01').examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查询词语某种词性所在的同义词集合\n",
    "    注：pos值可以为——NOUN,VERB,ADJ,ADV…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dog.n.01'),\n",
       " Synset('frump.n.01'),\n",
       " Synset('dog.n.03'),\n",
       " Synset('cad.n.01'),\n",
       " Synset('frank.n.02'),\n",
       " Synset('pawl.n.01'),\n",
       " Synset('andiron.n.01')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('dog',pos=wn.NOUN) #名词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chase.v.01')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('dog',pos=wn.VERB) #动词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查询一个同义词集中的所有词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'domestic_dog', 'Canis_familiaris']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('dog.n.01').lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dog.n.01')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('Canis_familiaris')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出词集和词的配对——词条（lemma）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('dog.n.01.dog'), Lemma('dog.n.01.domestic_dog'), Lemma('dog.n.01.Canis_familiaris')]\n",
      "[]\n",
      "42\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "dog%1:05:00::\n",
      "eng\n",
      "dog\n",
      "[]\n",
      "Synset('dog.n.01')\n",
      "None\n",
      "Lemma('dog.n.01.dog')\n",
      "<bound method _WordNetObject.hypernyms of Lemma('dog.n.01.dog')>\n",
      "<bound method _WordNetObject.hyponyms of Lemma('dog.n.01.dog')>\n"
     ]
    }
   ],
   "source": [
    "lst=wn.synset('dog.n.01').lemmas()\n",
    "item=lst[0]\n",
    "print(wn.synset('dog.n.01').lemmas())\n",
    "\n",
    "print(item.antonyms()) # 反义词\n",
    "print(item.count())    # Return the frequency count for this Lemma\n",
    "print(item.derivationally_related_forms())\n",
    "print(item.frame_ids())\n",
    "print(item.frame_strings())\n",
    "print(item.key())\n",
    "print(item.lang())\n",
    "print(item.name())\n",
    "print(item.pertainyms())\n",
    "print(item.synset())\n",
    "print(item.syntactic_marker())\n",
    "print(item.unicode_repr())\n",
    "\n",
    "print(item.hypernyms)\n",
    "print(item.hyponyms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用词条查询反义词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('bad.a.01.bad')]\n"
     ]
    }
   ],
   "source": [
    "good = wn.synset('good.a.01')\n",
    "print(good.lemmas()[0].antonyms()) #反义词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查询两个词之间的语义相似度\n",
    "    path_similarity函数，值从0-1，越大表示相似度越高\n",
    "    值得注意的是，名词和动词被组织成了完整的层次式分类体系，形容词和副词没有被组织成分类体系，所以不能用path_distance。\n",
    "    形容词和副词最有用的关系是similar to。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog = wn.synset('dog.n.01')\n",
    "cat = wn.synset('cat.n.01')\n",
    "dog.path_similarity(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('beauteous.s.01'),\n",
       " Synset('bonny.s.01'),\n",
       " Synset('dishy.s.01'),\n",
       " Synset('exquisite.s.04'),\n",
       " Synset('fine-looking.s.01'),\n",
       " Synset('glorious.s.03'),\n",
       " Synset('gorgeous.s.01'),\n",
       " Synset('lovely.s.01'),\n",
       " Synset('picturesque.s.01'),\n",
       " Synset('pretty-pretty.s.01'),\n",
       " Synset('pretty.s.01'),\n",
       " Synset('pulchritudinous.s.01'),\n",
       " Synset('ravishing.s.01'),\n",
       " Synset('scenic.s.01'),\n",
       " Synset('stunning.s.04')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beau=wn.synset('beautiful.a.01')\n",
    "beau.similar_tos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取词集路径 hypernym_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('animal.n.01'), Synset('chordate.n.01'), Synset('vertebrate.n.01'), Synset('mammal.n.01'), Synset('placental.n.01'), Synset('carnivore.n.01'), Synset('canine.n.02'), Synset('dog.n.01')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('animal.n.01'), Synset('domestic_animal.n.01'), Synset('dog.n.01')]]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "paths= wn.synset('dog.n.01').hypernym_paths()\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  获取根上位词集root_hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('entity.n.01')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "paths= wn.synset('dog.n.01').root_hypernyms()\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取上位词集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('canine.n.02')\n",
      "Synset('domestic_animal.n.01')\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "top_syn=wn.synset('dog.n.01').hypernyms()\n",
    "for item in top_syn:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取下位词集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('basenji.n.01')\n",
      "Synset('corgi.n.01')\n",
      "Synset('cur.n.01')\n",
      "Synset('dalmatian.n.02')\n",
      "Synset('great_pyrenees.n.01')\n",
      "Synset('griffon.n.02')\n",
      "Synset('hunting_dog.n.01')\n",
      "Synset('lapdog.n.01')\n",
      "Synset('leonberg.n.01')\n",
      "Synset('mexican_hairless.n.01')\n",
      "Synset('newfoundland.n.01')\n",
      "Synset('pooch.n.01')\n",
      "Synset('poodle.n.01')\n",
      "Synset('pug.n.01')\n",
      "Synset('puppy.n.01')\n",
      "Synset('spitz.n.01')\n",
      "Synset('toy_dog.n.01')\n",
      "Synset('working_dog.n.01')\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "bot_syn=wn.synset('dog.n.01').hyponyms()\n",
    "for item in bot_syn:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 树形结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('dog.n.01'),\n",
      " [Synset('canine.n.02'),\n",
      "  [Synset('carnivore.n.01'),\n",
      "   [Synset('placental.n.01'),\n",
      "    [Synset('mammal.n.01'),\n",
      "     [Synset('vertebrate.n.01'),\n",
      "      [Synset('chordate.n.01'),\n",
      "       [Synset('animal.n.01'),\n",
      "        [Synset('organism.n.01'),\n",
      "         [Synset('living_thing.n.01'),\n",
      "          [Synset('whole.n.02'),\n",
      "           [Synset('object.n.01'),\n",
      "            [Synset('physical_entity.n.01'),\n",
      "             [Synset('entity.n.01')]]]]]]]]]]]]],\n",
      " [Synset('domestic_animal.n.01'),\n",
      "  [Synset('animal.n.01'),\n",
      "   [Synset('organism.n.01'),\n",
      "    [Synset('living_thing.n.01'),\n",
      "     [Synset('whole.n.02'),\n",
      "      [Synset('object.n.01'),\n",
      "       [Synset('physical_entity.n.01'), [Synset('entity.n.01')]]]]]]]]]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "dog = wn.synset('dog.n.01')\n",
    "hyp = lambda s:s.hypernyms()\n",
    "from pprint import pprint\n",
    "pprint(dog.tree(hyp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 层次关系\n",
    "<img src=\"images/wordnet_tree.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Belgian_griffon',\n",
       " 'Brussels_griffon',\n",
       " 'Great_Pyrenees',\n",
       " 'Leonberg',\n",
       " 'Mexican_hairless',\n",
       " 'Newfoundland',\n",
       " 'Newfoundland_dog',\n",
       " 'Welsh_corgi',\n",
       " 'barker',\n",
       " 'basenji',\n",
       " 'bow-wow',\n",
       " 'carriage_dog',\n",
       " 'coach_dog',\n",
       " 'corgi',\n",
       " 'cur',\n",
       " 'dalmatian',\n",
       " 'doggie',\n",
       " 'doggy',\n",
       " 'griffon',\n",
       " 'hunting_dog',\n",
       " 'lapdog',\n",
       " 'mongrel',\n",
       " 'mutt',\n",
       " 'pooch',\n",
       " 'poodle',\n",
       " 'poodle_dog',\n",
       " 'pug',\n",
       " 'pug-dog',\n",
       " 'puppy',\n",
       " 'spitz',\n",
       " 'toy',\n",
       " 'toy_dog',\n",
       " 'working_dog']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motorcar=wn.synset('dog.n.01')\n",
    "types_of_motorcar=motorcar.hyponyms()\n",
    "types_of_motorcar[0]\n",
    "sorted(\n",
    "    [lemma.name()\n",
    "    for synset in types_of_motorcar\n",
    "         for lemma in synset.lemmas()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('marriage.n.03'), Synset('marry.v.01'), Synset('marriage.n.01')]\n",
      "[Synset('windows.n.01'), Synset('window.n.01'), Synset('window.n.02'), Synset('window.n.03'), Synset('window.n.04'), Synset('window.n.05'), Synset('windowpane.n.01'), Synset('window.n.07'), Synset('window.n.08')]\n"
     ]
    }
   ],
   "source": [
    "print(wn.synsets(u'结婚', lang='cmn'))\n",
    "#for synset in wn.synsets(u'计算机', lang='cmn'):\n",
    "#    types_of_computer = synset.hyponyms()\n",
    "#    print(sorted([lemma.name() for synset in types_of_ computer for lemma in synset.lemmas('cmn')]))\n",
    "print(wn.synsets(u'windows', lang='eng'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  WordNetCorpusReader\n",
    "    class nltk.corpus.reader.wordnet.WordNetCorpusReader(root, omw_reader)\n",
    "    \n",
    "    A corpus reader used to access wordnet or its variants.\n",
    "    ADJ = 'a'\n",
    "    ADJ_SAT = 's'\n",
    "    ADV = 'r'\n",
    "    MORPHOLOGICAL_SUBSTITUTIONS = {'a': [('er', ''), ('est', ''), ('er', 'e'), ('est', 'e')], 'n': [('s', ''), ('ses', 's'), ('ves', 'f'), ('xes', 'x'), ('zes', 'z'), ('ches', 'ch'), ('shes', 'sh'), ('men', 'man'), ('ies', 'y')], 'r': [], 's': [('er', ''), ('est', ''), ('er', 'e'), ('est', 'e')], 'v': [('s', ''), ('ies', 'y'), ('es', 'e'), ('es', ''), ('ed', 'e'), ('ed', ''), ('ing', 'e'), ('ing', '')]}\n",
    "    NOUN = 'n'\n",
    "    VERB = 'v'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all_lemma_names\n",
    "    返回所有词条名称\n",
    "    \n",
    "    all_lemma_names(pos=None, lang='eng')[source]\n",
    "    Return all lemma names for all synsets for the given part of speech tag and language or languages. If pos is not specified, all synsets for all parts of speech will be used.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return Type:\n",
      "<class 'dict_keyiterator'>\n",
      "numuber of all_lemma_names:\n",
      "147306\n",
      "display top 2 lemmas:\n",
      "serratus_anterior\n",
      "genus_claviceps\n"
     ]
    }
   ],
   "source": [
    "#返回所有词条名称\n",
    "from nltk.corpus import wordnet as wn\n",
    "lst=wn.all_lemma_names()\n",
    "print('return Type:')\n",
    "print(type(lst))\n",
    "lst=list(lst)\n",
    "#词条数目\n",
    "print('numuber of all_lemma_names:')\n",
    "print(len(lst))\n",
    "#显示前2个词条名称 \n",
    "print('display top 2 lemmas:')\n",
    "for sname in lst[:2]:\n",
    "    print(sname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all_synsets\n",
    "    返回所有同义词集\n",
    "    \n",
    "    all_synsets(pos=None)\n",
    "    Iterate over all synsets with a given part of speech tag. If no pos is specified, all synsets for all parts of speech will be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "<class 'nltk.corpus.reader.wordnet.Synset'>\n",
      "Synset('a_cappella.r.01')\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "lst=wn.all_synsets()\n",
    "print(type(lst))\n",
    "\n",
    "#--list不能与next同时使用--\n",
    "\n",
    "#每次检索下一个结果，效率高\n",
    "val1=next(lst)   \n",
    "print(type(val1))\n",
    "print(val1)\n",
    "\n",
    "#list一次返回所有结果，效率低\n",
    "#vals=list(lst)  \n",
    "#print(type(vals))\n",
    "#print(vals[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lemma\n",
    "    lemma(name, lang='eng')[source]\n",
    "    Return lemma object that matches the name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.corpus.reader.wordnet.Synset'>\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "obj=wn.synset('dog.n.01')\n",
    "print(type(obj))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
