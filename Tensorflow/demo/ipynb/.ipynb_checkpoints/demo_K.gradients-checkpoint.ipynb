{
 "cells": [
  {
   "attachments": {
    "%E5%9B%BE%E7%89%87.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 梯度&矩阵求导实验(有未解决问题-矩阵求导)\n",
    "原文:https://blog.csdn.net/C_chuxin/article/details/85269471 \n",
    "\n",
    "keras.backend.gradients\n",
    "gradients\n",
    "\n",
    "gradients(loss, variables)\n",
    "\n",
    "返回loss函数关于variables的梯度，variables为张量变量的列表\n",
    "\n",
    "概述\n",
    "\n",
    "K.gradients（y，x）\n",
    "\n",
    "【功能】用于求y关于x 的导数（梯度）\n",
    "\n",
    "【输入】(y和x可以是张量tensor也可以是张量列表，形如 [tensor1, tensor2, …, tensorn]），\n",
    "\n",
    "【返回】返回的是一个张量列表，列表长度是张量列表x的长度，列表元素是与x具有一样shape的张量。\n",
    "\n",
    "     举个例子，比如：grads = K.gradients(y， x),若y是（2，2）张量，x是（1，7，7，512）张量，那么返回的grads是只有1个元素的（1，7，7，512）张量列表。\n",
    "\n",
    "    具体而言：\n",
    "\n",
    "    K.gradients()实现y对x求导\n",
    "    求导返回值是一个list，list的长度等于len(x)\n",
    "    假设返回值是[grad1, grad2, grad3]，y=[y1, y2]，x=[x1, x2, x3]。则，真实的计算过程为:\n",
    "![%E5%9B%BE%E7%89%87.png](attachment:%E5%9B%BE%E7%89%87.png)\n",
    "     \n",
    "\n",
    "    其中y1/x1表示求y1关于x1的偏导数。\n",
    "\n",
    "    tensorflow—tf.gradients()简单实用教程\n",
    "\n",
    "## 未解决问题\n",
    "    numpy ,SciPy用于求解矩阵导数的方法方案?\n",
    "    \n",
    "    \n",
    "\n",
    "## 参考\n",
    "\n",
    "    keras中的K.gradients（）函数\n",
    "    https://blog.csdn.net/C_chuxin/article/details/85269471\n",
    "    \n",
    "    tensorflow—tf.gradients()简单实用教程\n",
    "    https://blog.csdn.net/hustqb/article/details/80260002\n",
    "    \n",
    "    通过一个例子快速上手矩阵求导\n",
    "    https://blog.csdn.net/nomadlx53/article/details/50849941\n",
    "    \n",
    "    矩阵求导与实例\n",
    "    https://blog.csdn.net/young_gy/article/details/50008953\n",
    "    \n",
    "    矩阵求导公式\n",
    "    https://blog.csdn.net/weixin_34920941/article/details/82882602\n",
    "    \n",
    "    Deep Learning 学习笔记7：矩阵求导公式汇总\n",
    "    https://blog.csdn.net/WPR1991/article/details/82929843\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "sess=tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp1:\n",
      "-0.57129544\n",
      "tmp2:\n",
      "-0.5470154\n",
      "y:\n",
      "[-0.57129544 -0.5470154 ]\n",
      "x:\n",
      "[[-0.57129544 -0.2735077 ]]\n",
      "the gradient of y=x[0,0]+2*x[0,1] for x is : [array([[1., 2.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#范例1\n",
    "x = tf.get_variable('w1',shape=[1,2])\n",
    "tmp1=x[0,0]\n",
    "tmp2=2*x[0,1]\n",
    "y=tf.stack([tmp1,tmp2],0)  #y 是一个（2,1）的张量，x 是一个（1,2）的张量,而且y=x[0,0]+2*x[0,1] \n",
    "grads = tf.gradients(y,[x]) \n",
    "tf.global_variables_initializer().run() \n",
    "re = sess.run(grads) \n",
    "print('tmp1:')\n",
    "print(tmp1.eval())\n",
    "print('tmp2:')\n",
    "print(tmp2.eval())\n",
    "print('y:')\n",
    "print(y.eval())\n",
    "print('x:')\n",
    "print(x.eval())\n",
    "print('the gradient of y=x[0,0]+2*x[0,1] for x is :',re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp1:\n",
      "0.10136671\n",
      "tmp2:\n",
      "1.8084109\n",
      "y:\n",
      "[[0.10136671 0.90420544]]\n",
      "x:\n",
      "[[0.10136671 0.90420544]]\n",
      "the gradient of y=x[0,0]+2*x[0,1] for x is : [array([[1., 1.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#范例2\n",
    "x = tf.Variable(initial_value=np.random.rand(1,2),dtype=tf.float32,name='var1') \n",
    "tmp1=x[0,0]\n",
    "tmp2=2*x[0,1]\n",
    "#y=tf.stack([tmp1,tmp2],0)  #y 是一个（2,1）的张量，x 是一个（1,2）的张量,而且y=x[0,0]+2*x[0,1] \n",
    "y=x\n",
    "grads = tf.gradients(y,[x]) \n",
    "\n",
    "tf.global_variables_initializer().run() \n",
    "re = sess.run(grads) \n",
    "print('tmp1:')\n",
    "print(tmp1.eval())\n",
    "print('tmp2:')\n",
    "print(tmp2.eval())\n",
    "print('y:')\n",
    "print(y.eval())\n",
    "print('x:')\n",
    "print(x.eval())\n",
    "print('the gradient of y=x[0,0]+2*x[0,1] for x is :',re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 9., 10.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#范例3\n",
    "#w1 = tf.Variable([[1,2]])       #1x2\n",
    "#w2 = tf.Variable([[3,4]])       #1x2\n",
    "w1 = tf.Variable(initial_value=np.random.rand(1,2),dtype=tf.float32,name='var1') \n",
    "w2 = tf.Variable(initial_value=np.random.rand(3,4),dtype=tf.float32,name='var1') \n",
    "\n",
    "y = tf.matmul(w1,[[9.],[10.]])    #2x1\n",
    "#求w1的梯度\n",
    "grads = tf.gradients(y,w1)      #1x2\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "gradval = sess.run(grads)\n",
    "print(gradval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 标量对标量的求导 \n",
    "x:标量\n",
    "\n",
    "y=x\n",
    "\n",
    "$\\frac{dy}{dx}$=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'var1_3:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'var1_3:0' shape=() dtype=float32_ref>\n",
      "[<tf.Tensor 'gradients_3/Fill:0' shape=() dtype=float32>]\n",
      "[1.0]\n"
     ]
    }
   ],
   "source": [
    "#标量对标量的求导\n",
    "#  y=x => dy/dx\n",
    "x = tf.Variable(initial_value=np.random.rand(),dtype=tf.float32,name='var1') \n",
    "y = x\n",
    "tf.global_variables_initializer().run()\n",
    "grads=tf.gradients(y,x)\n",
    "grads_val=sess.run(grads)\n",
    "print(x)\n",
    "print(y)\n",
    "print(grads)\n",
    "print(grads_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 张量列表求导\n",
    "x:标量\n",
    "\n",
    "x1=1,y1=x1\n",
    "\n",
    "x2=2,y2=x2\n",
    "\n",
    "x3=3,y3=x3\n",
    "\n",
    "x=[x1,x2,x3]\n",
    "\n",
    "y=[y1,y2,y3]\n",
    "\n",
    "$\\frac{\\text{dy}}{\\text{dx}}$\n",
    "=\n",
    "$\\left[\n",
    "\\begin{array}{ccc}\n",
    "\\frac{dy1}{dx1} + \\frac{dy2}{dx1} + \\frac{dy3}{dx1} \\\\\n",
    "\\frac{dy1}{dx2} + \\frac{dy2}{dx2} + \\frac{dy3}{dx2} \\\\\n",
    "\\frac{dy1}{dx3} + \\frac{dy2}{dx3} + \\frac{dy3}{dx3} \\\\\n",
    "\\end{array} \n",
    "\\right]$\n",
    "=[1.0,1.0,1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'Variable:0' shape=() dtype=float32_ref>, <tf.Variable 'Variable_1:0' shape=() dtype=float32_ref>, <tf.Variable 'Variable_2:0' shape=() dtype=float32_ref>]\n",
      "[<tf.Variable 'Variable:0' shape=() dtype=float32_ref>, <tf.Variable 'Variable_1:0' shape=() dtype=float32_ref>, <tf.Variable 'Variable_2:0' shape=() dtype=float32_ref>]\n",
      "[<tf.Tensor 'gradients_4/Fill:0' shape=() dtype=float32>, <tf.Tensor 'gradients_4/Fill_1:0' shape=() dtype=float32>, <tf.Tensor 'gradients_4/Fill_2:0' shape=() dtype=float32>]\n",
      "[1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#张量列表求导\n",
    "#  y=[y1,y2]\n",
    "#  x=[x1,x2,x3]\n",
    "#  dy/dx=>[dy1/dx1+dy2/dx1, dy1/dx2+dy2/dx2, dy1/dx3+dy2/dx3]\n",
    "x1 = tf.Variable(initial_value=np.random.rand(),dtype=tf.float32) \n",
    "x2 = tf.Variable(initial_value=np.random.rand(),dtype=tf.float32) \n",
    "x3 = tf.Variable(initial_value=np.random.rand(),dtype=tf.float32) \n",
    "\n",
    "x1_op=tf.assign(x1,1.0)\n",
    "x2_op=tf.assign(x2,1.0)\n",
    "x3_op=tf.assign(x3,1.0)\n",
    "\n",
    "y1 = x1\n",
    "y2 = x2\n",
    "y3 = x3\n",
    "\n",
    "x=[x1,x2,x3]\n",
    "y=[y1,y2,y3]\n",
    "tf.global_variables_initializer().run()\n",
    "sess.run(x1_op)\n",
    "sess.run(x2_op)\n",
    "sess.run(x3_op)\n",
    "\n",
    "grads=tf.gradients(y,x)\n",
    "grads_val=sess.run(grads)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(grads)\n",
    "print(grads_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 张量列表求导\n",
    "x:标量\n",
    "\n",
    "y=x\n",
    "\n",
    "$\\frac{\\text{d[y,y]}}{\\text{d[x,x,x]}}$\n",
    "=\n",
    "$\\left[\n",
    "\\begin{array}{c}\n",
    "\\frac{dy}{dx} + \\frac{dy}{dx} \\\\\n",
    "\\frac{dy}{dx} + \\frac{dy}{dx} \\\\\n",
    "\\frac{dy}{dx} + \\frac{dy}{dx} \\\\\n",
    "\\end{array} \n",
    "\\right]$\n",
    "=[2.0,2.0,2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_3:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'Variable_3:0' shape=() dtype=float32_ref>\n",
      "[<tf.Tensor 'gradients_5/AddN:0' shape=() dtype=float32>, <tf.Tensor 'gradients_5/AddN:0' shape=() dtype=float32>, <tf.Tensor 'gradients_5/AddN:0' shape=() dtype=float32>]\n",
      "[2.0, 2.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "#张量列表求导\n",
    "#  y=[y1,y2]\n",
    "#  x=[x1,x2,x3]\n",
    "#  dy/dx=>[dy1/dx1+dy2/dx1, dy1/dx2+dy2/dx2, dy1/dx3+dy2/dx3]\n",
    "x = tf.Variable(initial_value=np.random.rand(),dtype=tf.float32) \n",
    "x_op=tf.assign(x,1.0)\n",
    "y = x\n",
    "tf.global_variables_initializer().run()\n",
    "sess.run(x_op)\n",
    "\n",
    "grads=tf.gradients([y,y],[x,x,x])\n",
    "grads_val=sess.run(grads)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(grads)\n",
    "print(grads_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 标量对向量求导\n",
    "x:列向量\n",
    "\n",
    "y:标量\n",
    "\n",
    "$x$=\n",
    "$\\left[\n",
    "\\begin{array}{c}\n",
    " x_{1} \\\\\n",
    " x_{2} \\\\\n",
    " x_{3} \\\\\n",
    "\\end{array}\n",
    "\\right]$\n",
    "\n",
    "$a$=$\\left[a_{1},a_{2},a_{3} \\right]$\n",
    "\n",
    "y=$a\\cdot x$=\n",
    "$\\left[ a_{1}x_{1}+a_{2}x_{2}+a_{3}x_{3}\\right]$\n",
    "\n",
    "$\\frac{dy}{dx}$\n",
    "=\n",
    "$\\left[\n",
    "\\begin{array}{c}\n",
    "\\frac{d(a_{1}x_{1}+a_{2}x_{2}+a_{3}x_{3})}{d{x_{1}}} \\\\\n",
    "\\frac{d(a_{1}x_{1}+a_{2}x_{2}+a_{3}x_{3})}{d{x_{2}}} \\\\\n",
    "\\frac{d(a_{1}x_{1}+a_{2}x_{2}+a_{3}x_{3})}{d{x_{3}}} \n",
    "\\end{array}\n",
    "\\right]$\n",
    "=\n",
    "$\\left[\n",
    "\\begin{array}{c}\n",
    "a_{1} \\\\\n",
    "a_{2} \\\\\n",
    "a_{3} \n",
    "\\end{array}\n",
    "\\right]$\n",
    "=$a'$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "[[1. 2. 3.]]\n",
      "x=\n",
      "[[1.]\n",
      " [2.]\n",
      " [3.]]\n",
      "y=a*x=\n",
      "[[14.]]\n",
      "grads_val=\n",
      "[array([[1.],\n",
      "       [2.],\n",
      "       [3.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#标量对向量求导\n",
    "a=tf.constant([[1.,2.,3.]],dtype=tf.float32)\n",
    "x=tf.Variable(initial_value=np.random.rand(3,1),dtype=tf.float32)\n",
    "x_op=tf.assign(x,[[1.],[2.],[3.]])\n",
    "y=tf.matmul(a,x)\n",
    "grads=tf.gradients(y,x)\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "sess.run(x_op)\n",
    "grads_val=sess.run(grads)\n",
    "\n",
    "print('a=')\n",
    "print(a.eval())\n",
    "print('x=')\n",
    "print(x.eval())\n",
    "print('y=a*x=')\n",
    "print(y.eval())\n",
    "print('grads_val=')\n",
    "print(grads_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 标量对向量求导\n",
    "x:横向量\n",
    "\n",
    "y:标量\n",
    "\n",
    "$x$=\n",
    "$\\left[ x_{1}  x_{2}  x_{3} \\right]$\n",
    "\n",
    "$a$=\n",
    "$\\left[\n",
    "\\begin{array}{c}\n",
    "a_{1} \\\\\n",
    "a_{2} \\\\\n",
    "a_{3} \n",
    "\\end{array}\n",
    "\\right]$\n",
    "\n",
    "y=$x\\cdot a$=\n",
    "$\\left[ a_{1}x_{1}+a_{2}x_{2}+a_{3}x_{3}\\right]$\n",
    "\n",
    "$\\frac{dy}{dx}$\n",
    "=\n",
    "$\\left[\n",
    "\\frac{d(a_{1}x_{1}+a_{2}x_{2}+a_{3}x_{3})}{d{x_{1}}} \\text{ }\n",
    "\\frac{d(a_{1}x_{1}+a_{2}x_{2}+a_{3}x_{3})}{d{x_{2}}} \\text{ }\n",
    "\\frac{d(a_{1}x_{1}+a_{2}x_{2}+a_{3}x_{3})}{d{x_{3}}} \\text{ }\n",
    "\\right]$\n",
    "=\n",
    "$\\left[\n",
    "\\begin{array}{ccc}\n",
    "a_{1} \\text{ }\n",
    "a_{2} \\text{ } \n",
    "a_{3} \\text{ }\n",
    "\\end{array}\n",
    "\\right]$\n",
    "=$a'$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'var1_4:0' shape=() dtype=float32_ref>\n",
      "Tensor(\"Pow:0\", shape=(), dtype=float32)\n",
      "[<tf.Tensor 'gradients_7/Pow_grad/Reshape:0' shape=() dtype=float32>]\n",
      "8.0\n",
      "[12.0]\n"
     ]
    }
   ],
   "source": [
    "#标量对标量的求导\n",
    "#  x:标量\n",
    "#    2.0\n",
    "#  y=x^3 => dy/dx\n",
    "\n",
    "x = tf.Variable(initial_value=np.random.rand(),dtype=tf.float32,name='var1') \n",
    "x_op=tf.assign(x,2.0)\n",
    "y=tf.pow(x,3)\n",
    "tf.global_variables_initializer().run()\n",
    "grads=tf.gradients(y,[x])\n",
    "sess.run(x_op)\n",
    "grads_val=sess.run(grads)\n",
    "print(x)\n",
    "print(y)\n",
    "print(grads)\n",
    "print(y.eval())\n",
    "print(sess.run(grads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 向量对标量求导\n",
    "x:标量\n",
    "\n",
    "y:列向量\n",
    "\n",
    "a=\n",
    "$\\left[\n",
    "\\begin{array}{c}\n",
    " a_{1} \\\\\n",
    " a_{2} \\\\\n",
    " a_{3} \\\\\n",
    "\\end{array}\n",
    "\\right]$\n",
    "\n",
    "y=$a\\cdot x$=\n",
    "$\\left[\n",
    "\\begin{array}{c}\n",
    "a_{1}x \\\\\n",
    "a_{2}x \\\\\n",
    "a_{3}x\n",
    "\\end{array}\n",
    "\\right]$\n",
    "\n",
    "$\\frac{dy}{dx}$\n",
    "=\n",
    "$\\left[\n",
    "\\begin{array}{c}\n",
    "\\frac{d(a_{1}x)}{dx} \\\\\n",
    "\\frac{d(a_{2}x)}{dx} \\\\\n",
    "\\frac{d(a_{3}x)}{dx} \n",
    "\\end{array}\n",
    "\\right]$\n",
    "=\n",
    "$\\left[\n",
    "\\begin{array}{c}\n",
    "a_{1} \\\\\n",
    "a_{2} \\\\\n",
    "a_{3} \n",
    "\\end{array}\n",
    "\\right]$\n",
    "=$a$\n",
    "\n",
    "???\n",
    "\n",
    "x:标量\n",
    "\n",
    "y:列向量=>相当于张量列表?\n",
    "\n",
    "a=\n",
    "$\\left[\n",
    "\\begin{array}{c}\n",
    " a_{1} \\\\\n",
    " a_{2} \\\\\n",
    " a_{3} \\\\\n",
    "\\end{array}\n",
    "\\right]$\n",
    "\n",
    "y=$a\\cdot x$=\n",
    "$\\left[\n",
    "\\begin{array}{c}\n",
    "a_{1}x \\\\\n",
    "a_{2}x \\\\\n",
    "a_{3}x\n",
    "\\end{array}\n",
    "\\right]$\n",
    "\n",
    "$\\frac{dy}{dx}$\n",
    "=\n",
    "$\\left[\n",
    "\\begin{array}{c}\n",
    "\\frac{d(a_{1}x)}{dx} + \\frac{d(a_{2}x)}{dx} + \\frac{d(a_{3}x)}{dx} \n",
    "\\end{array}\n",
    "\\right]$\n",
    "=\n",
    "$\\left[\n",
    "\\begin{array}{c}\n",
    "a_{1} + a_{2} + a_{3} \n",
    "\\end{array}\n",
    "\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "[[1.]\n",
      " [2.]\n",
      " [3.]]\n",
      "x=\n",
      "[[1.]]\n",
      "y=a*x=\n",
      "[[[1.]\n",
      "  [2.]\n",
      "  [3.]]]\n",
      "grads_val=\n",
      "[array([[6.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#向量对标量求导\n",
    "a=tf.constant([[1.],[2.],[3.]],dtype=tf.float32)\n",
    "x=tf.Variable(initial_value=np.random.rand(1,1),dtype=tf.float32)\n",
    "x_op=tf.assign(x,[[1.0]])\n",
    "y=tf.matmul(a,x)\n",
    "y=tf.expand_dims(y,0)\n",
    "grads=tf.gradients(y,x)\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "sess.run(x_op)\n",
    "grads_val=sess.run(grads)\n",
    "\n",
    "print('a=')\n",
    "print(a.eval())\n",
    "print('x=')\n",
    "print(x.eval())\n",
    "print('y=a*x=')\n",
    "print(y.eval())\n",
    "print('grads_val=')\n",
    "print(grads_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 向量对标量求导\n",
    "x:标量\n",
    "\n",
    "y:横向量\n",
    "\n",
    "a=\n",
    "$\\left[\n",
    "\\begin{array}{c}\n",
    " a_{1}\\text{ }  a_{2}\\text{ }  a_{3}\\text{ } \n",
    "\\end{array}\n",
    "\\right]$\n",
    "\n",
    "y=$a\\cdot x$=\n",
    "$\\left[\n",
    "\\begin{array}{c}\n",
    "a_{1}x\\text{ } a_{2}x\\text{ } a_{3}x\\text{ }\n",
    "\\end{array}\n",
    "\\right]$\n",
    "\n",
    "$\\frac{dy}{dx}$\n",
    "=\n",
    "$\\left[\n",
    "\\begin{array}{c}\n",
    "\\frac{d(a_{1}x)}{dx}\\text{ } \\frac{d(a_{2}x)}{dx}\\text{ } \\frac{d(a_{3}x)}{dx}\\text{ } \n",
    "\\end{array}\n",
    "\\right]$\n",
    "=\n",
    "$\\left[\n",
    "\\begin{array}{c}\n",
    "a_{1}\\text{ } a_{2}\\text{ } a_{3}\\text{ } \n",
    "\\end{array}\n",
    "\\right]$\n",
    "=$a$\n",
    "\n",
    "？？？？？？？？\n",
    "\n",
    "x:标量\n",
    "\n",
    "y:横向量=>相当于张量列表?\n",
    "\n",
    "a=\n",
    "$\\left[\n",
    "\\begin{array}{c}\n",
    " a_{1}\\text{ } a_{2}\\text{ } a_{3} \n",
    "\\end{array}\n",
    "\\right]$\n",
    "\n",
    "y=$a\\cdot x$=\n",
    "$\\left[\n",
    "\\begin{array}{c}\n",
    "a_{1}x\\text{ } a_{2}x\\text{ } a_{3}x\n",
    "\\end{array}\n",
    "\\right]$\n",
    "\n",
    "$\\frac{dy}{dx}$\n",
    "=\n",
    "$\\left[\n",
    "\\begin{array}{c}\n",
    "\\frac{d(a_{1}x)}{dx} + \\frac{d(a_{2}x)}{dx} + \\frac{d(a_{3}x)}{dx} \n",
    "\\end{array}\n",
    "\\right]$\n",
    "=\n",
    "$\\left[\n",
    "\\begin{array}{c}\n",
    "a_{1} + a_{2} + a_{3} \n",
    "\\end{array}\n",
    "\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "[[1. 2. 3.]]\n",
      "x=\n",
      "[[1.]]\n",
      "y=a*x=\n",
      "[[1. 2. 3.]]\n",
      "grads_val=\n",
      "[array([[6.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#向量对标量求导\n",
    "a=tf.constant([[1.,2.,3.]],dtype=tf.float32)\n",
    "x=tf.Variable(initial_value=np.random.rand(1,1),dtype=tf.float32)\n",
    "x_op=tf.assign(x,[[1.0]])\n",
    "y=tf.matmul(x,a)\n",
    "grads=tf.gradients(y,x)\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "sess.run(x_op)\n",
    "grads_val=sess.run(grads)\n",
    "\n",
    "print('a=')\n",
    "print(a.eval())\n",
    "print('x=')\n",
    "print(x.eval())\n",
    "print('y=a*x=')\n",
    "print(y.eval())\n",
    "print('grads_val=')\n",
    "print(grads_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 标量对矩阵求导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 矩阵对标量求导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 矩阵对列向量求导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 列向量对矩阵求导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 矩阵对横向量求导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 横向量对矩阵求导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([2., 2., 3.], dtype=float32), array([2., 2., 3.], dtype=float32), array([5., 4., 7.], dtype=float32), array([3., 2., 4.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "w1 = tf.get_variable('ww1', shape=[3])\n",
    "w2 = tf.get_variable('ww2', shape=[3])\n",
    "\n",
    "w3 = tf.get_variable('ww3', shape=[3])\n",
    "w4 = tf.get_variable('ww4', shape=[3])\n",
    "\n",
    "z1 = w1 + w2+ w3\n",
    "z2 = w3 + w4\n",
    "\n",
    "grads = tf.gradients([z1, z2], [w1, w2, w3, w4], grad_ys=[tf.convert_to_tensor([2.,2.,3.]),\n",
    "                                                          tf.convert_to_tensor([3.,2.,4.])])\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "print(sess.run(grads))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
