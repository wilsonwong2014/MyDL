{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 几何数据集测试\n",
    "* 测试数据集由 mylibs.data.gen_gemotry模块生成\n",
    "\n",
    "#### 数据集说明\n",
    "    数据集由以下几何图形构成：直线，圆，椭圆，多边形\n",
    "    \n",
    "#### 实验目的\n",
    "    观察MLP网络对几何数据集的分类性能\n",
    "    \n",
    "#### 实验步骤\n",
    "    * 构造几何数据集\n",
    "    * 构建MLP网络\n",
    "    * 网络训练\n",
    "    * 网路预测\n",
    "    \n",
    "#### 实验结果\n",
    "    ased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造数据集\n",
    "    由lab_gemotry-data.ipynb生成."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path='%s/work/data/gemotry'%os.getenv('HOME')#数据目录\n",
    "train_dir='%s/train'%data_path  #训练目录\n",
    "valid_dir='%s/valid'%data_path  #校验目录\n",
    "test_dir ='%s/test'%data_path   #测试目录\n",
    "out_dir='%s/work/data/labs_out/lab_geometry-cnn'%os.getenv('HOME')   #输出目录\n",
    "log_dir='%s/log_dir'%out_dir    #输出日志目录\n",
    "cp_file='%s/cp_file.h5'%out_dir #训练断点\n",
    "model_file='%s/model.h5'%out_dir#模型文件\n",
    "\n",
    "input_shape=(224,224,3)\n",
    "target_size=(224,224)\n",
    "epochs=3\n",
    "num_class=10\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据生成器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K\n",
    "\n",
    "#构造图像数据生成器:train\n",
    "gen_train = ImageDataGenerator(\n",
    "        featurewise_center           =False,\n",
    "        samplewise_center            =False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization =False,\n",
    "        zca_whitening                =False,\n",
    "        zca_epsilon                  =1e-6,\n",
    "        rotation_range               =0.,\n",
    "        width_shift_range            =0.,\n",
    "        height_shift_range           =0.,\n",
    "        shear_range                  =0.,\n",
    "        zoom_range                   =0.,\n",
    "        channel_shift_range          =0.,\n",
    "        fill_mode                    ='nearest',\n",
    "        cval                         =0.,\n",
    "        horizontal_flip              =False,\n",
    "        vertical_flip                =False,\n",
    "        rescale                      =1./255,\n",
    "        preprocessing_function       =None,\n",
    "        data_format                  =K.image_data_format()\n",
    "       )\n",
    "data_train=gen_train.flow_from_directory(directory='%s/train'%(data_path)\n",
    "                                         ,batch_size=batch_size\n",
    "                                         ,target_size=target_size)\n",
    "#构造图像数据生成器:valid\n",
    "gen_valid = ImageDataGenerator(\n",
    "        featurewise_center           =False,\n",
    "        samplewise_center            =False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization =False,\n",
    "        zca_whitening                =False,\n",
    "        zca_epsilon                  =1e-6,\n",
    "        rotation_range               =0.,\n",
    "        width_shift_range            =0.,\n",
    "        height_shift_range           =0.,\n",
    "        shear_range                  =0.,\n",
    "        zoom_range                   =0.,\n",
    "        channel_shift_range          =0.,\n",
    "        fill_mode                    ='nearest',\n",
    "        cval                         =0.,\n",
    "        horizontal_flip              =False,\n",
    "        vertical_flip                =False,\n",
    "        rescale                      =1./255,\n",
    "        preprocessing_function       =None,\n",
    "        data_format                  =K.image_data_format()\n",
    "       )\n",
    "data_valid=gen_valid.flow_from_directory(directory='%s/valid'%(data_path)\n",
    "                                         ,batch_size=batch_size\n",
    "                                         ,target_size=target_size)\n",
    "\n",
    "#构造图像数据生成器:test\n",
    "gen_test = ImageDataGenerator(\n",
    "        featurewise_center           =False,\n",
    "        samplewise_center            =False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization =False,\n",
    "        zca_whitening                =False,\n",
    "        zca_epsilon                  =1e-6,\n",
    "        rotation_range               =0.,\n",
    "        width_shift_range            =0.,\n",
    "        height_shift_range           =0.,\n",
    "        shear_range                  =0.,\n",
    "        zoom_range                   =0.,\n",
    "        channel_shift_range          =0.,\n",
    "        fill_mode                    ='nearest',\n",
    "        cval                         =0.,\n",
    "        horizontal_flip              =False,\n",
    "        vertical_flip                =False,\n",
    "        rescale                      =1./255,\n",
    "        preprocessing_function       =None,\n",
    "        data_format                  =K.image_data_format()\n",
    "       )\n",
    "data_test=gen_test.flow_from_directory(directory='%s/test'%(data_path)\n",
    "                                       ,batch_size=batch_size\n",
    "                                       ,shuffle=False                                       \n",
    "                                       ,target_size=target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=next(data_train)\n",
    "#print(data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 394272)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               201867776 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 201,873,802\n",
      "Trainable params: 201,873,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models,layers,optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=input_shape,name='conv2d_1'))\n",
    "model.add(layers.MaxPooling2D((2, 2),name='max_pooling2d_1'))\n",
    "model.add(layers.Flatten(name='flatten_1'))\n",
    "model.add(layers.Dense(512, activation='relu',name='dense_1'))\n",
    "model.add(layers.Dense(num_class, activation='softmax',name='dense_2'))\n",
    "\n",
    "#打印模型\n",
    "model.summary()\n",
    "\n",
    "#模型编译\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "          metrics=['acc'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training beginning ......\n",
      "load check point: /home/hjw/work/data/labs_out/lab_geometry-cnn/cp_file.h5\n",
      "Epoch 1/3\n",
      "  8/625 [..............................] - ETA: 17:21 - loss: 0.1051 - acc: 0.9727"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9239b04435df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   callbacks=callbacks_list)\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'history:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#模型训练\n",
    "print('training beginning ......')\n",
    "\n",
    "#断点加载\n",
    "if os.path.exists(cp_file):\n",
    "    print('load check point:',cp_file)\n",
    "    model.load_weights(cp_file)\n",
    "            \n",
    "#断点训练:monitor监控参数可以通过score = model.evaluate(x_test, y_test, verbose=0)的score查询\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(cp_file, monitor='val_acc', verbose=1, save_best_only=True, mode='auto',period=2)\n",
    "#EarlyStopping\n",
    "earlyStopping_cb=keras.callbacks.EarlyStopping(monitor='acc', patience=3, verbose=0, mode='max')\n",
    "#TensorBoard\n",
    "tensorBoard_cb=keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "#回调函数序列\n",
    "callbacks_list = [checkpoint_cb,earlyStopping_cb,tensorBoard_cb]\n",
    "\n",
    "#模型训练\n",
    "history = model.fit_generator(\n",
    "  data_train,\n",
    "  steps_per_epoch=np.ceil(data_train.samples/batch_size),\n",
    "  epochs=epochs,\n",
    "  validation_data=data_valid,\n",
    "  validation_steps=50,\n",
    "  callbacks=callbacks_list)\n",
    "print('history:',history.history)\n",
    "\n",
    "#保存模型\n",
    "print('save model file:',model_file)\n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型测试\n",
    "#计算精度\n",
    "def compute_acc(y_pred,y_true):\n",
    "    acc=(y_pred-y_true)==0\n",
    "    return acc.sum()/acc.size\n",
    "\n",
    "print('predicting beginning ......')\n",
    "#type(y_pred)=> <class 'numpy.ndarray'>\n",
    "y_pred=model.predict_generator(\n",
    "    data_test, \n",
    "    steps=None, #预测轮数\n",
    "    max_queue_size=32, \n",
    "    workers=1, \n",
    "    use_multiprocessing=False, \n",
    "    verbose=1)\n",
    "\n",
    "acc=compute_acc(np.argmax(y_pred,axis=1),data_test.classes)\n",
    "print('samples:',data_test.samples)\n",
    "print('classes[:2]:')\n",
    "print(data_test.classes[:2])\n",
    "print('y_pred.shape:',y_pred.shape)\n",
    "print('y_pred[:2]:')\n",
    "print(y_pred[:2])\n",
    "print('准确率:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
