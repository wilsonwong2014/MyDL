{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 几何数据集测试\n",
    "* 测试数据集由 mylibs.data.gen_gemotry模块生成\n",
    "\n",
    "#### 数据集说明\n",
    "    数据集由以下几何图形构成：直线，圆，椭圆，多边形\n",
    "    \n",
    "#### 实验目的\n",
    "    观察MLP网络对几何数据集的分类性能\n",
    "    \n",
    "#### 实验步骤\n",
    "    * 构造几何数据集\n",
    "    * 构建MLP网络\n",
    "    * 网络训练\n",
    "    * 网路预测\n",
    "    \n",
    "#### 实验结果\n",
    "    ased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造数据集\n",
    "    由lab_gemotry-data.ipynb生成."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path='%s/work/data/gemotry'%os.getenv('HOME')#数据目录\n",
    "train_dir='%s/train'%data_path  #训练目录\n",
    "valid_dir='%s/valid'%data_path  #校验目录\n",
    "test_dir ='%s/test'%data_path   #测试目录\n",
    "out_dir='%s/work/temp/fit_generator'%os.getenv('HOME')   #输出目录\n",
    "log_dir='%s/log_dir'%out_dir    #输出日志目录\n",
    "cp_file='%s/cp_file.h5'%out_dir #训练断点\n",
    "model_file='%s/model.h5'%out_dir#模型文件\n",
    "\n",
    "input_shape=(224,224,3)\n",
    "target_size=(224,224)\n",
    "epochs=3\n",
    "num_class=10\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据生成器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K\n",
    "\n",
    "#构造图像数据生成器:train\n",
    "gen_train = ImageDataGenerator(\n",
    "        featurewise_center           =False,\n",
    "        samplewise_center            =False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization =False,\n",
    "        zca_whitening                =False,\n",
    "        zca_epsilon                  =1e-6,\n",
    "        rotation_range               =0.,\n",
    "        width_shift_range            =0.,\n",
    "        height_shift_range           =0.,\n",
    "        shear_range                  =0.,\n",
    "        zoom_range                   =0.,\n",
    "        channel_shift_range          =0.,\n",
    "        fill_mode                    ='nearest',\n",
    "        cval                         =0.,\n",
    "        horizontal_flip              =False,\n",
    "        vertical_flip                =False,\n",
    "        rescale                      =1./255,\n",
    "        preprocessing_function       =None,\n",
    "        data_format                  =K.image_data_format()\n",
    "       )\n",
    "data_train=gen_train.flow_from_directory(directory='%s/train'%(data_path)\n",
    "                                         ,batch_size=batch_size\n",
    "                                         ,target_size=target_size)\n",
    "#构造图像数据生成器:valid\n",
    "gen_valid = ImageDataGenerator(\n",
    "        featurewise_center           =False,\n",
    "        samplewise_center            =False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization =False,\n",
    "        zca_whitening                =False,\n",
    "        zca_epsilon                  =1e-6,\n",
    "        rotation_range               =0.,\n",
    "        width_shift_range            =0.,\n",
    "        height_shift_range           =0.,\n",
    "        shear_range                  =0.,\n",
    "        zoom_range                   =0.,\n",
    "        channel_shift_range          =0.,\n",
    "        fill_mode                    ='nearest',\n",
    "        cval                         =0.,\n",
    "        horizontal_flip              =False,\n",
    "        vertical_flip                =False,\n",
    "        rescale                      =1./255,\n",
    "        preprocessing_function       =None,\n",
    "        data_format                  =K.image_data_format()\n",
    "       )\n",
    "data_valid=gen_valid.flow_from_directory(directory='%s/valid'%(data_path)\n",
    "                                         ,batch_size=batch_size\n",
    "                                         ,target_size=target_size)\n",
    "\n",
    "#构造图像数据生成器:test\n",
    "gen_test = ImageDataGenerator(\n",
    "        featurewise_center           =False,\n",
    "        samplewise_center            =False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization =False,\n",
    "        zca_whitening                =False,\n",
    "        zca_epsilon                  =1e-6,\n",
    "        rotation_range               =0.,\n",
    "        width_shift_range            =0.,\n",
    "        height_shift_range           =0.,\n",
    "        shear_range                  =0.,\n",
    "        zoom_range                   =0.,\n",
    "        channel_shift_range          =0.,\n",
    "        fill_mode                    ='nearest',\n",
    "        cval                         =0.,\n",
    "        horizontal_flip              =False,\n",
    "        vertical_flip                =False,\n",
    "        rescale                      =1./255,\n",
    "        preprocessing_function       =None,\n",
    "        data_format                  =K.image_data_format()\n",
    "       )\n",
    "data_test=gen_test.flow_from_directory(directory='%s/test'%(data_path)\n",
    "                                       ,batch_size=batch_size\n",
    "                                       ,shuffle=False                                       \n",
    "                                       ,target_size=target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=next(data_train)\n",
    "#print(data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 394272)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               201867776 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 201,873,802\n",
      "Trainable params: 201,873,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models,layers,optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=input_shape,name='conv2d_1'))\n",
    "model.add(layers.MaxPooling2D((2, 2),name='max_pooling2d_1'))\n",
    "model.add(layers.Flatten(name='flatten_1'))\n",
    "model.add(layers.Dense(512, activation='relu',name='dense_1'))\n",
    "model.add(layers.Dense(num_class, activation='softmax',name='dense_2'))\n",
    "\n",
    "#打印模型\n",
    "model.summary()\n",
    "\n",
    "#模型编译\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "          metrics=['acc'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training beginning ......\n",
      "Epoch 1/3\n",
      "625/625 [==============================] - 73s 117ms/step - loss: 0.1396 - acc: 0.9631 - val_loss: 0.1974 - val_acc: 0.9444\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 71s 114ms/step - loss: 0.0758 - acc: 0.9811 - val_loss: 0.1512 - val_acc: 0.9569\n",
      "\n",
      "Epoch 00002: val_acc improved from -inf to 0.95688, saving model to /home/hjw/work/temp/fit_generator/cp_file.h5\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 70s 112ms/step - loss: 0.0462 - acc: 0.9886 - val_loss: 0.1396 - val_acc: 0.9587\n",
      "history: {'val_loss': [0.197359684035182, 0.15115972824394702, 0.1396488678455353], 'val_acc': [0.944375, 0.956875, 0.95875], 'acc': [0.9631, 0.98115, 0.9886], 'loss': [0.13961113646179438, 0.07582676512002945, 0.046211803479492664]}\n"
     ]
    }
   ],
   "source": [
    "#模型训练\n",
    "print('training beginning ......')\n",
    "\n",
    "#断点加载\n",
    "if os.path.exists(cp_file):\n",
    "    model.load_weights(cp_file)\n",
    "            \n",
    "#断点训练:monitor监控参数可以通过score = model.evaluate(x_test, y_test, verbose=0)的score查询\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(cp_file, monitor='val_acc', verbose=1, save_best_only=True, mode='auto',period=2)\n",
    "#EarlyStopping\n",
    "earlyStopping_cb=keras.callbacks.EarlyStopping(monitor='acc', patience=3, verbose=0, mode='max')\n",
    "#TensorBoard\n",
    "tensorBoard_cb=keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "#回调函数序列\n",
    "callbacks_list = [checkpoint_cb,earlyStopping_cb,tensorBoard_cb]\n",
    "\n",
    "#模型训练\n",
    "history = model.fit_generator(\n",
    "  data_train,\n",
    "  steps_per_epoch=np.ceil(data_train.samples/batch_size),\n",
    "  epochs=epochs,\n",
    "  validation_data=data_valid,\n",
    "  validation_steps=50,\n",
    "  callbacks=callbacks_list)\n",
    "print('history:',history.history)\n",
    "\n",
    "#保存模型\n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting beginning ......\n",
      "313/313 [==============================] - 19s 60ms/step\n",
      "samples: 10000\n",
      "classes[:2]:\n",
      "[0 0]\n",
      "y_pred.shape: (10000, 10)\n",
      "y_pred[:2]:\n",
      "[[9.99986053e-01 5.50334880e-06 1.52007310e-10 1.45566993e-16\n",
      "  2.15621364e-15 1.01226263e-10 4.67223682e-09 1.68835811e-07\n",
      "  1.37725760e-06 6.92601634e-06]\n",
      " [9.98001516e-01 1.54661282e-03 7.08361414e-09 4.81797768e-10\n",
      "  9.72223457e-09 3.44942492e-07 5.13375937e-07 4.09931818e-05\n",
      "  2.86117283e-04 1.23890146e-04]]\n",
      "准确率: 0.9631\n"
     ]
    }
   ],
   "source": [
    "#模型测试\n",
    "#计算精度\n",
    "def compute_acc(y_pred,y_true):\n",
    "    acc=(y_pred-y_true)==0\n",
    "    return acc.sum()/acc.size\n",
    "\n",
    "print('predicting beginning ......')\n",
    "#type(y_pred)=> <class 'numpy.ndarray'>\n",
    "y_pred=model.predict_generator(\n",
    "    data_test, \n",
    "    steps=None, #预测轮数\n",
    "    max_queue_size=32, \n",
    "    workers=1, \n",
    "    use_multiprocessing=False, \n",
    "    verbose=1)\n",
    "\n",
    "acc=compute_acc(np.argmax(y_pred,axis=1),data_test.classes)\n",
    "print('samples:',data_test.samples)\n",
    "print('classes[:2]:')\n",
    "print(data_test.classes[:2])\n",
    "print('y_pred.shape:',y_pred.shape)\n",
    "print('y_pred[:2]:')\n",
    "print(y_pred[:2])\n",
    "print('准确率:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
