{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 几何数据集测试\n",
    "* 测试数据集由 mylibs.data.gen_gemotry模块生成\n",
    "\n",
    "#### 数据集说明\n",
    "    数据集由以下几何图形构成：直线，圆，椭圆，多边形\n",
    "    \n",
    "#### 实验目的\n",
    "    观察MLP网络对几何数据集的分类性能\n",
    "    \n",
    "#### 实验步骤\n",
    "    * 构造几何数据集\n",
    "    * 构建MLP网络\n",
    "    * 网络训练\n",
    "    * 网路预测\n",
    "    \n",
    "#### 实验结果\n",
    "    ased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造数据集\n",
    "    由lab_gemotry-data.ipynb生成."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path='%s/work/data/gemotry'%os.getenv('HOME')#数据目录\n",
    "train_dir='%s/train'%data_path  #训练目录\n",
    "valid_dir='%s/valid'%data_path  #校验目录\n",
    "test_dir ='%s/test'%data_path   #测试目录\n",
    "out_dir='%s/work/temp/fit_generator'%os.getenv('HOME')   #输出目录\n",
    "log_dir='%s/log_dir'%out_dir    #输出日志目录\n",
    "cp_file='%s/cp_file.h5'%out_dir #训练断点\n",
    "model_file='%s/model.h5'%out_dir#模型文件\n",
    "\n",
    "input_shape=(224,224,3)\n",
    "target_size=(224,224)\n",
    "epochs=3\n",
    "num_class=10\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据生成器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K\n",
    "\n",
    "#构造图像数据生成器:train\n",
    "gen_train = ImageDataGenerator(\n",
    "        featurewise_center           =False,\n",
    "        samplewise_center            =False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization =False,\n",
    "        zca_whitening                =False,\n",
    "        zca_epsilon                  =1e-6,\n",
    "        rotation_range               =0.,\n",
    "        width_shift_range            =0.,\n",
    "        height_shift_range           =0.,\n",
    "        shear_range                  =0.,\n",
    "        zoom_range                   =0.,\n",
    "        channel_shift_range          =0.,\n",
    "        fill_mode                    ='nearest',\n",
    "        cval                         =0.,\n",
    "        horizontal_flip              =False,\n",
    "        vertical_flip                =False,\n",
    "        rescale                      =1./255,\n",
    "        preprocessing_function       =None,\n",
    "        data_format                  =K.image_data_format()\n",
    "       )\n",
    "data_train=gen_train.flow_from_directory(directory='%s/train'%(data_path)\n",
    "                                         ,batch_size=batch_size\n",
    "                                         ,target_size=target_size)\n",
    "#构造图像数据生成器:valid\n",
    "gen_valid = ImageDataGenerator(\n",
    "        featurewise_center           =False,\n",
    "        samplewise_center            =False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization =False,\n",
    "        zca_whitening                =False,\n",
    "        zca_epsilon                  =1e-6,\n",
    "        rotation_range               =0.,\n",
    "        width_shift_range            =0.,\n",
    "        height_shift_range           =0.,\n",
    "        shear_range                  =0.,\n",
    "        zoom_range                   =0.,\n",
    "        channel_shift_range          =0.,\n",
    "        fill_mode                    ='nearest',\n",
    "        cval                         =0.,\n",
    "        horizontal_flip              =False,\n",
    "        vertical_flip                =False,\n",
    "        rescale                      =1./255,\n",
    "        preprocessing_function       =None,\n",
    "        data_format                  =K.image_data_format()\n",
    "       )\n",
    "data_valid=gen_valid.flow_from_directory(directory='%s/valid'%(data_path)\n",
    "                                         ,batch_size=batch_size\n",
    "                                         ,target_size=target_size)\n",
    "\n",
    "#构造图像数据生成器:test\n",
    "gen_test = ImageDataGenerator(\n",
    "        featurewise_center           =False,\n",
    "        samplewise_center            =False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization =False,\n",
    "        zca_whitening                =False,\n",
    "        zca_epsilon                  =1e-6,\n",
    "        rotation_range               =0.,\n",
    "        width_shift_range            =0.,\n",
    "        height_shift_range           =0.,\n",
    "        shear_range                  =0.,\n",
    "        zoom_range                   =0.,\n",
    "        channel_shift_range          =0.,\n",
    "        fill_mode                    ='nearest',\n",
    "        cval                         =0.,\n",
    "        horizontal_flip              =False,\n",
    "        vertical_flip                =False,\n",
    "        rescale                      =1./255,\n",
    "        preprocessing_function       =None,\n",
    "        data_format                  =K.image_data_format()\n",
    "       )\n",
    "data_test=gen_test.flow_from_directory(directory='%s/test'%(data_path)\n",
    "                                       ,batch_size=batch_size\n",
    "                                       ,shuffle=False                                       \n",
    "                                       ,target_size=target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=next(data_train)\n",
    "#print(data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 394272)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               201867776 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 201,873,802\n",
      "Trainable params: 201,873,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models,layers,optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=input_shape,name='conv2d_1'))\n",
    "model.add(layers.MaxPooling2D((2, 2),name='max_pooling2d_1'))\n",
    "model.add(layers.Flatten(name='flatten_1'))\n",
    "model.add(layers.Dense(512, activation='relu',name='dense_1'))\n",
    "model.add(layers.Dense(num_class, activation='softmax',name='dense_2'))\n",
    "\n",
    "#打印模型\n",
    "model.summary()\n",
    "\n",
    "#模型编译\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "          metrics=['acc'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training beginning ......\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed to create session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bfe7f416c846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#断点加载\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcp_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcp_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#断点训练:monitor监控参数可以通过score = model.evaluate(x_test, y_test, verbose=0)的score查询\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[0;32m-> 1166\u001b[0;31m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   1056\u001b[0m                              ' elements.')\n\u001b[1;32m   1057\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2468\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2469\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2470\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m                 config = tf.ConfigProto(intra_op_parallelism_threads=num_thread,\n\u001b[1;32m    185\u001b[0m                                         allow_soft_placement=True)\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0m_SESSION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m     \"\"\"\n\u001b[0;32m-> 1494\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1495\u001b[0m     \u001b[0;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed to create session."
     ]
    }
   ],
   "source": [
    "#模型训练\n",
    "print('training beginning ......')\n",
    "\n",
    "#断点加载\n",
    "if os.path.exists(cp_file):\n",
    "    model.load_weights(cp_file)\n",
    "            \n",
    "#断点训练:monitor监控参数可以通过score = model.evaluate(x_test, y_test, verbose=0)的score查询\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(cp_file, monitor='val_acc', verbose=1, save_best_only=True, mode='auto',period=2)\n",
    "#EarlyStopping\n",
    "earlyStopping_cb=keras.callbacks.EarlyStopping(monitor='acc', patience=3, verbose=0, mode='max')\n",
    "#TensorBoard\n",
    "tensorBoard_cb=keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "#回调函数序列\n",
    "callbacks_list = [checkpoint_cb,earlyStopping_cb,tensorBoard_cb]\n",
    "\n",
    "#模型训练\n",
    "history = model.fit_generator(\n",
    "  data_train,\n",
    "  steps_per_epoch=np.ceil(data_train.samples/batch_size),\n",
    "  epochs=epochs,\n",
    "  validation_data=data_valid,\n",
    "  validation_steps=50,\n",
    "  callbacks=callbacks_list)\n",
    "print('history:',history.history)\n",
    "\n",
    "#保存模型\n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型测试\n",
    "#计算精度\n",
    "def compute_acc(y_pred,y_true):\n",
    "    acc=(y_pred-y_true)==0\n",
    "    return acc.sum()/acc.size\n",
    "\n",
    "print('predicting beginning ......')\n",
    "#type(y_pred)=> <class 'numpy.ndarray'>\n",
    "y_pred=model.predict_generator(\n",
    "    data_test, \n",
    "    steps=None, #预测轮数\n",
    "    max_queue_size=32, \n",
    "    workers=1, \n",
    "    use_multiprocessing=False, \n",
    "    verbose=1)\n",
    "\n",
    "acc=compute_acc(np.argmax(y_pred,axis=1),data_test.classes)\n",
    "print('samples:',data_test.samples)\n",
    "print('classes[:2]:')\n",
    "print(data_test.classes[:2])\n",
    "print('y_pred.shape:',y_pred.shape)\n",
    "print('y_pred[:2]:')\n",
    "print(y_pred[:2])\n",
    "print('准确率:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
