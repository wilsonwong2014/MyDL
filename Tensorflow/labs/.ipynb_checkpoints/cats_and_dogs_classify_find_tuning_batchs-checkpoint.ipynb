{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from mylibs.ProcessBar import ShowProcess\n",
    "from mylibs import funs\n",
    "from mylibs.my_contrib import *\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 猫狗分类实验\n",
    "## 实验目的\n",
    "创建一个简单图像二分类的卷积模型,掌握以下知识点：\n",
    "* 数据生成器的使用方法\n",
    "    ./MyDL/Tensorflow/demo/python/demo_ImageDataGenerator2.py\n",
    "* 卷积神经网络模型创建：卷积层，密度层，激活函数，损失函数，优化函数\n",
    "* 模型训练方法\n",
    "* 模型预测方法\n",
    "* plt基本使用方法\n",
    "* 训练曲线绘制\n",
    "* 可视化FeatureMap\n",
    "* 可视化神经网络的过滤器\n",
    "* 可视化类激活的热力图\n",
    "\n",
    "本实验的数据将作为基础参考\n",
    "\n",
    "## 实验数据说明\n",
    "  * 网络数据下载地址：https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "  * 本地数据存储路径：~/e/dataset_tiptical/cats_and_dogs\n",
    "  * 实验数据根目录：~/data/cats_and_dogs\n",
    "      - ./ori      ------------猫狗分类原始数据目录\n",
    "      - ./lab_base ------------实验方案目录\n",
    "      - ./lab_base/train ------训练目录\n",
    "      - ./lab_base/valid ------校验目录\n",
    "      - ./lab_base/test  ------测试目录\n",
    "      - ./lab_base/test.jpg ---测试图片\n",
    "      \n",
    "\n",
    "## 参考资料\n",
    "visualization of filters keras 基于Keras的卷积神经网络（CNN）可视化\n",
    "\n",
    "http://www.cnblogs.com/bnuvincent/p/9612686.html\n",
    "\n",
    "python深度学习{eep learning with python中文版.pdf}源码\n",
    "\n",
    "https://github.com/fchollet/deep-learning-with-python-notebooks\n",
    "\n",
    "数据下载：\n",
    "\n",
    "https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "\n",
    "本地数据\n",
    "\n",
    "~/e/dataset_tiptical/cats_and_dogs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验4\n",
    "VGG19预训练模型提取特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================\n",
      "设置实验参数\n"
     ]
    }
   ],
   "source": [
    "##实验参数\n",
    "print('\\n==============================================')\n",
    "print('设置实验参数')\n",
    "lab_name='猫狗分类实验-VGG16预训练模型调参'              #实验名称\n",
    "data_path='%s/data/cats_and_dogs'%(os.getenv('HOME')) #猫狗分类数据根目录\n",
    "ori_path='%s/ori'%(data_path)                         #猫狗分类原始文件目录\n",
    "lab_path='%s/lab_vgg19_fine_tuning'%(data_path)          #实验方案目录\n",
    "split_num=\"10000,2000,2000\"                           #实验数据分割方案,<1：比例分割，>1：数量分割\n",
    "batch_size=32                                         #批量大小\n",
    "data_enhance=False                                    #ImageDataGenerator数据启用数据增强\n",
    "epochs=10                                             #训练轮次\n",
    "img_width=224                                         #训练图像宽度\n",
    "img_height=224                                        #训练图像高度 \n",
    "test_img_path='%s/test.jpg'%(data_path)               #测试图片路径\n",
    "images_per_row=16       #图像显示每行显示的单元个数\n",
    "#feature_map_top_num=12  #FeatureMap前面N层{include_top=False}\n",
    "img_margin=3            #图像单元空隙\n",
    "layers_name=['conv2d_1','conv2d_2','conv2d_3','conv2d_4'] #卷积层名称\n",
    "#layers_name=['conv2d_1'] #卷积层名称\n",
    "last_conv_layer_name='conv2d_4' #最后一层卷积层\n",
    "gen_pat_steps=40                           #构造迭代次数\n",
    "cp_file='%s/checkpoint.h5'%(lab_path)      #ModelCheckpoint 文件路径\n",
    "his_file='%s/history.json'%(lab_path)      #训练日志文件路径\n",
    "class_mode='binary'                        #分类方法,'binary':二分类，'categorical':多分类\n",
    "loss='binary_crossentropy'  #损失函数,'binary_crossentropy':二分类，'categorical_crossentropy':多分类\n",
    "\n",
    "test_cat_path='%s/test_cat.jpg'%(data_path) #猫的测试图像\n",
    "test_dog_path='%s/test_dog.jpg'%(data_path) #狗的测试图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================\n",
      "加载数据......\n",
      "enhance:False\n",
      "img_height:224\n",
      "split_num:10000,2000,2000\n",
      "reset:True\n",
      "img_width:224\n",
      "class_mode:binary\n",
      "batch_size:32\n",
      "delete folder:/home/hjw/data/cats_and_dogs/lab_vgg19_fine_tuning\n",
      "imgages_split:/home/hjw/data/cats_and_dogs/ori=>/home/hjw/data/cats_and_dogs/lab_vgg19_fine_tuning\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 4000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "##加载数据\n",
    "print('\\n==============================================')\n",
    "print('加载数据......')\n",
    "#删除lab_path\n",
    "#shutil.rmtree(lab_path) if os.path.exists(lab_path) else ''\n",
    "\n",
    "#数据生成器\n",
    "(train_gen,valid_gen,test_gen)=DataGen(ori_path,lab_path,reset=True,split_num=split_num\n",
    "                                   ,img_width=img_width,img_height=img_height\n",
    "                                   ,batch_size=batch_size,enhance=data_enhance,class_mode=class_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.applications import VGG19\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications import Xception\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications import MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "构建网络\n"
     ]
    }
   ],
   "source": [
    "print('构建网络')\n",
    "## 创建网络\n",
    "def CreateModel(BaseNet_name,BaseNet=VGG16,trainable_name='block5_conv1',input_shape=(150,150,3),flag=0):\n",
    "    #print('\\n==============================================')\n",
    "    #print('BaseNet:%s'%(BaseNet_name))\n",
    "    conv_base=BaseNet(weights='imagenet',include_top=False,input_shape=input_shape)\n",
    "    if flag==1:\n",
    "        for layer in conv_base.layers:\n",
    "            layer.trainable=False\n",
    "    \n",
    "    elif flag==2:\n",
    "        set_trainable = False\n",
    "        for layer in conv_base.layers:\n",
    "            if layer.name == trainable_name:\n",
    "                set_trainable = True\n",
    "            if set_trainable:\n",
    "                layer.trainable = True\n",
    "            else:\n",
    "                layer.trainable = False\n",
    "    #conv_base.summary()\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(conv_base)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    #打印模型\n",
    "    #model.summary()\n",
    "    #模型编译\n",
    "    model.compile(loss=loss,\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])\n",
    "    return (conv_base,model)\n",
    "\n",
    "    \n",
    "#记录日志回调函数    \n",
    "class train_callback(keras.callbacks.Callback):\n",
    "    def __init__(self,log_file,history={},verbose=0):\n",
    "        super(train_callback,self).__init__() #调用父类构造函数\n",
    "        self.log_file=log_file #训练日志文件路径\n",
    "        self.history=history   #训练日志\n",
    "        self.verbose=verbose   #是否显示保存信息\n",
    "        \n",
    "    #on_epoch_end: 在每个epoch结束时调用\n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        #最佳日志\n",
    "        if len(self.history)==0:\n",
    "            for k,v in logs.items():\n",
    "                self.history[k]=[v]\n",
    "        else:\n",
    "            for k,v in logs.items():\n",
    "                self.history[k].append(v)\n",
    "        #保存日志\n",
    "        json.dump(self.history,open(self.log_file,'w'))\n",
    "        if self.verbose==1:\n",
    "            print('更新训练日志(%d):%s'%(len(self.history),self.log_file))  \n",
    "\n",
    "def TrainModel(model):\n",
    "    #回调函数保存训练日志    \n",
    "    his_cb=train_callback(his_file,history=history2)\n",
    "\n",
    "    #断点训练:monitor监控参数可以通过self.score = self.model.evaluate(self.x_test, self.y_test, verbose=0)的score查询\n",
    "    checkpoint_cb = ModelCheckpoint(cp_file, monitor='val_acc', verbose=1, save_best_only=True, mode='auto',period=2)\n",
    "    #EarlyStopping\n",
    "    earlyStopping_cb=keras.callbacks.EarlyStopping(monitor='acc', patience=3, verbose=0, mode='max')\n",
    "    #TensorBoard\n",
    "    #tensorBoard_cb=TensorBoard(log_dir=self.log_dir)\n",
    "    #回调函数序列\n",
    "    callbacks_list = [checkpoint_cb,earlyStopping_cb,his_cb]\n",
    "\n",
    "    history = model.fit_generator(\n",
    "      train_gen,\n",
    "      steps_per_epoch=np.ceil(train_gen.samples/batch_size),\n",
    "      epochs=epochs,\n",
    "      validation_data=valid_gen,\n",
    "      validation_steps=50,\n",
    "      callbacks=callbacks_list)            \n",
    "    \n",
    "\n",
    "#简报\n",
    "def Report(BaseNet_name,model):\n",
    "    core_valid = model.evaluate_generator(valid_gen, steps=100, max_q_size=10, workers=1, pickle_safe=False,verbose=1)\n",
    "    preds=model.predict_generator(\n",
    "        test_gen, \n",
    "        steps=None, #预测轮数\n",
    "        max_queue_size=32, \n",
    "        workers=1, \n",
    "        use_multiprocessing=False,     \n",
    "        verbose=1)\n",
    "    \n",
    "    preds_acc_val=preds_acc(preds,test_gen)\n",
    "    print('\\n\\n')\n",
    "    print('================测试简报(%s[%s])=================='%(lab_name,lab_path))\n",
    "    #网络模型\n",
    "    print('ResNet50')\n",
    "    print(['%s:%s'%(layer.name,'True' if layer.trainable else 'False') for layer in conv_base.layers])\n",
    "    conv_base.summary()\n",
    "    model.summary()\n",
    "    #网络输入\n",
    "    print('input_shape:%s'%(model.input.shape))\n",
    "    #网络训练\n",
    "    print('train=>epochs :%d,samples:%d,loss:%f,acc:%f'\n",
    "              %(epochs,len(train_gen.filenames),history.history['loss'][-1],history.history['acc'][-1]))\n",
    "    #网络评估\n",
    "    print('valid=>samples:%d,val_loss:%f,val_acc:%f'%(len(valid_gen.filenames),score_valid[0],score_valid[1]))\n",
    "    #网络测试\n",
    "    print('test =>samples:%d,acc:%f'%(len(test_gen.filenames),preds_acc_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 批量训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#预训练模型\n",
    "conv_bases={\n",
    "    'VGG16':[VGG16,'block_conv5',(150,150,3)],\n",
    "    'VGG19':[VGG19,'block_conv5',(150,150,3)],\n",
    "    'ResNet50':[ResNet50,'block_conv5',(224,224,3)],\n",
    "    'Xception':[Xception,'block_conv5',(224,224,3)],\n",
    "    'InceptionV3':[inception_v3,'block_conv5',(224,224,3)],\n",
    "    'MobileNet':[MobileNet,'block_conv5',(224,224,3)]\n",
    "    }\n",
    "\n",
    "for k,v in conv_bases.items():\n",
    "    #def CreateModel(BaseNet_name,BaseNet,input_shape,flag):\n",
    "    for flag in range(3):\n",
    "        print('==============%s==============='%(k))\n",
    "        conv_base,model=CreateModel(k,v[0],v[1],v[2],flag)\n",
    "        conv_base.summary()\n",
    "        model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
