{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from mylibs.ProcessBar import ShowProcess\n",
    "from mylibs import funs\n",
    "from mylibs.my_contrib import *\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 猫狗分类实验\n",
    "## 实验目的\n",
    "创建一个简单图像二分类的卷积模型,掌握以下知识点：\n",
    "* 数据生成器的使用方法\n",
    "    ./MyDL/Tensorflow/demo/python/demo_ImageDataGenerator2.py\n",
    "* 卷积神经网络模型创建：卷积层，密度层，激活函数，损失函数，优化函数\n",
    "* 模型训练方法\n",
    "* 模型预测方法\n",
    "* plt基本使用方法\n",
    "* 训练曲线绘制\n",
    "* 可视化FeatureMap\n",
    "* 可视化神经网络的过滤器\n",
    "* 可视化类激活的热力图\n",
    "\n",
    "本实验的数据将作为基础参考\n",
    "\n",
    "## 实验数据说明\n",
    "  * 网络数据下载地址：https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "  * 本地数据存储路径：~/e/dataset_tiptical/cats_and_dogs\n",
    "  * 实验数据根目录：~/data/cats_and_dogs\n",
    "      - ./ori      ------------猫狗分类原始数据目录\n",
    "      - ./lab_base ------------实验方案目录\n",
    "      - ./lab_base/train ------训练目录\n",
    "      - ./lab_base/valid ------校验目录\n",
    "      - ./lab_base/test  ------测试目录\n",
    "      - ./lab_base/test.jpg ---测试图片\n",
    "      \n",
    "\n",
    "## 参考资料\n",
    "visualization of filters keras 基于Keras的卷积神经网络（CNN）可视化\n",
    "\n",
    "http://www.cnblogs.com/bnuvincent/p/9612686.html\n",
    "\n",
    "python深度学习{eep learning with python中文版.pdf}源码\n",
    "\n",
    "https://github.com/fchollet/deep-learning-with-python-notebooks\n",
    "\n",
    "数据下载：\n",
    "\n",
    "https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "\n",
    "本地数据\n",
    "\n",
    "~/e/dataset_tiptical/cats_and_dogs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验4\n",
    "VGG16预训练模型提取特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================\n",
      "设置实验参数\n"
     ]
    }
   ],
   "source": [
    "##实验参数\n",
    "print('\\n==============================================')\n",
    "print('设置实验参数')\n",
    "lab_name='猫狗分类实验-VGG16预训练模型调参'              #实验名称\n",
    "data_path='%s/data/cats_and_dogs'%(os.getenv('HOME')) #猫狗分类数据根目录\n",
    "ori_path='%s/ori'%(data_path)                         #猫狗分类原始文件目录\n",
    "lab_path='%s/lab_vgg16_features'%(data_path)          #实验方案目录\n",
    "split_num=\"10000,2000,2000\"                           #实验数据分割方案,<1：比例分割，>1：数量分割\n",
    "batch_size=32                                         #批量大小\n",
    "data_enhance=False                                    #ImageDataGenerator数据启用数据增强\n",
    "epochs=10                                             #训练轮次\n",
    "img_width=224                                         #训练图像宽度\n",
    "img_height=224                                        #训练图像高度 \n",
    "test_img_path='%s/test.jpg'%(data_path)               #测试图片路径\n",
    "images_per_row=16       #图像显示每行显示的单元个数\n",
    "#feature_map_top_num=12  #FeatureMap前面N层{include_top=False}\n",
    "img_margin=3            #图像单元空隙\n",
    "layers_name=['conv2d_1','conv2d_2','conv2d_3','conv2d_4'] #卷积层名称\n",
    "#layers_name=['conv2d_1'] #卷积层名称\n",
    "last_conv_layer_name='conv2d_4' #最后一层卷积层\n",
    "gen_pat_steps=40                           #构造迭代次数\n",
    "cp_file='%s/checkpoint.h5'%(lab_path)      #ModelCheckpoint 文件路径\n",
    "his_file='%s/history.json'%(lab_path)      #训练日志文件路径\n",
    "class_mode='binary'                        #分类方法,'binary':二分类，'categorical':多分类\n",
    "loss='binary_crossentropy'  #损失函数,'binary_crossentropy':二分类，'categorical_crossentropy':多分类\n",
    "\n",
    "test_cat_path='%s/test_cat.jpg'%(data_path) #猫的测试图像\n",
    "test_dog_path='%s/test_dog.jpg'%(data_path) #狗的测试图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================\n",
      "加载数据......\n",
      "img_width:224\n",
      "batch_size:32\n",
      "enhance:False\n",
      "split_num:10000,2000,2000\n",
      "class_mode:binary\n",
      "reset:True\n",
      "img_height:224\n",
      "delete folder:/home/hjw/data/cats_and_dogs/lab_vgg16_features\n",
      "imgages_split:/home/hjw/data/cats_and_dogs/ori=>/home/hjw/data/cats_and_dogs/lab_vgg16_features\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 4000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "##加载数据\n",
    "print('\\n==============================================')\n",
    "print('加载数据......')\n",
    "#删除lab_path\n",
    "#shutil.rmtree(lab_path) if os.path.exists(lab_path) else ''\n",
    "\n",
    "#数据生成器\n",
    "(train_gen,valid_gen,test_gen)=DataGen(ori_path,lab_path,reset=True,split_num=split_num\n",
    "                                   ,img_width=img_width,img_height=img_height\n",
    "                                   ,batch_size=batch_size,enhance=data_enhance,class_mode=class_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================\n",
      "构建网络\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 7,079,424\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 21,137,729\n",
      "Trainable params: 13,502,465\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('\\n==============================================')\n",
    "print('构建网络')\n",
    "from keras.applications import VGG16\n",
    "## 创建网络\n",
    "model_vgg16=VGG16(weights='imagenet',include_top=False,input_shape=(224, 224, 3))\n",
    "\n",
    "#model_vgg16.trainable=False\n",
    "#for layer in model_vgg16.layers:\n",
    "#    layer.trainable=False\n",
    "    \n",
    "set_trainable = False\n",
    "for layer in model_vgg16.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "        \n",
    "model_vgg16.summary()\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(model_vgg16)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "#打印模型\n",
    "model.summary()\n",
    "#模型编译\n",
    "model.compile(loss=loss,\n",
    "          optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "          metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_callback(keras.callbacks.Callback):\n",
    "    def __init__(self,log_file,history={},verbose=0):\n",
    "        super(train_callback,self).__init__() #调用父类构造函数\n",
    "        self.log_file=log_file #训练日志文件路径\n",
    "        self.history=history   #训练日志\n",
    "        self.verbose=verbose   #是否显示保存信息\n",
    "        \n",
    "    #on_epoch_end: 在每个epoch结束时调用\n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        #最佳日志\n",
    "        if len(self.history)==0:\n",
    "            for k,v in logs.items():\n",
    "                self.history[k]=[v]\n",
    "        else:\n",
    "            for k,v in logs.items():\n",
    "                self.history[k].append(v)\n",
    "        #保存日志\n",
    "        json.dump(self.history,open(self.log_file,'w'))\n",
    "        if self.verbose==1:\n",
    "            print('更新训练日志(%d):%s'%(len(self.history),self.log_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================\n",
      "网络训练 ......\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (64, 3, 3, 3) for Tensor 'Placeholder_76:0', which has shape '(3, 3, 512, 512)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-9f172f49dd7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#加载断点\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcp_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcp_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'加载模型文件:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcp_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#训练日志\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[0;32m-> 1166\u001b[0;31m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   1056\u001b[0m                              ' elements.')\n\u001b[1;32m   1057\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2468\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2469\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2470\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1074\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1076\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1077\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (64, 3, 3, 3) for Tensor 'Placeholder_76:0', which has shape '(3, 3, 512, 512)'"
     ]
    }
   ],
   "source": [
    "##网络训练\n",
    "print('\\n==============================================')\n",
    "print('网络训练 ......')\n",
    "#加载断点\n",
    "if os.path.exists(cp_file):\n",
    "    model.load_weights(cp_file)\n",
    "    print('加载模型文件:',cp_file)\n",
    "#训练日志\n",
    "history2={}\n",
    "if os.path.exists(his_file):\n",
    "    history2=json.load(open(his_file,'r'))\n",
    "    print('加载训练日志:',his_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "233/625 [==========>...................] - ETA: 47s - loss: 0.2738 - acc: 0.8853"
     ]
    }
   ],
   "source": [
    "#回调函数保存训练日志    \n",
    "his_cb=train_callback(his_file,history=history2)\n",
    "\n",
    "#断点训练:monitor监控参数可以通过self.score = self.model.evaluate(self.x_test, self.y_test, verbose=0)的score查询\n",
    "checkpoint_cb = ModelCheckpoint(cp_file, monitor='val_acc', verbose=1, save_best_only=True, mode='auto',period=2)\n",
    "#EarlyStopping\n",
    "earlyStopping_cb=keras.callbacks.EarlyStopping(monitor='acc', patience=3, verbose=0, mode='max')\n",
    "#TensorBoard\n",
    "#tensorBoard_cb=TensorBoard(log_dir=self.log_dir)\n",
    "#回调函数序列\n",
    "callbacks_list = [checkpoint_cb,earlyStopping_cb,his_cb]\n",
    "\n",
    "history = model.fit_generator(\n",
    "  train_gen,\n",
    "  steps_per_epoch=np.ceil(train_gen.samples/batch_size),\n",
    "  epochs=epochs,\n",
    "  validation_data=valid_gen,\n",
    "  validation_steps=50,\n",
    "  callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##保存模型\n",
    "print('\\n==============================================')\n",
    "print('保存模型 ......') \n",
    "save_model(model,lab_path,train_gen.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试简报"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_valid = model.evaluate_generator(valid_gen, steps=100, max_q_size=10, workers=1, pickle_safe=False,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=model.predict_generator(\n",
    "    test_gen, \n",
    "    steps=None, #预测轮数\n",
    "    max_queue_size=32, \n",
    "    workers=1, \n",
    "    use_multiprocessing=False,     \n",
    "    verbose=1)\n",
    "print(valid_gen.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_acc_val=preds_acc(preds,test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('\\n\\n')\n",
    "print('================测试简报(%s[%s])=================='%(lab_name,lab_path))\n",
    "#网络模型\n",
    "print('VGG16')\n",
    "print(['%s:%s'%(layer.name,'True' if layer.trainable else 'False') for layer in model_vgg16.layers])\n",
    "model_vgg16.summary()\n",
    "model.summary()\n",
    "#网络输入\n",
    "print('input_shape:%s'%(model.input.shape))\n",
    "#网络训练\n",
    "print('train=>epochs :%d,samples:%d,loss:%f,acc:%f'\n",
    "          %(epochs,len(train_gen.filenames),history.history['loss'][-1],history.history['acc'][-1]))\n",
    "#网络评估\n",
    "print('valid=>samples:%d,val_loss:%f,val_acc:%f'%(len(valid_gen.filenames),score_valid[0],score_valid[1]))\n",
    "#网络测试\n",
    "print('test =>samples:%d,acc:%f'%(len(test_gen.filenames),preds_acc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "funs.GatherFilesEx('%s/test_small'%(data_path),images,exts='.jpg,.jpeg')\n",
    "predict_images(model,images,train_gen.class_indices,img_width=img_width,img_height=img_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##训练曲线\n",
    "print('\\n==============================================')\n",
    "print('训练曲线')\n",
    "visualizer_scalar(history.history)\n",
    "visualizer_scalar(history2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化FeatureMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##可视化FeatureMap\n",
    "print('\\n==============================================')\n",
    "print('可视化FeatureMap-猫')\n",
    "#visualizer_feature_map(model,test_cat_path,target_size=(img_height,img_width)\n",
    "#                       ,images_per_row=images_per_row,img_margin=img_margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('可视化FeatureMap-狗')\n",
    "#visualizer_feature_map(model,test_dog_path,target_size=(img_height,img_width)\n",
    "#                       ,images_per_row=images_per_row,img_margin=img_margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化类激活热力图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##可视化类激活热力图\n",
    "print('可视化类激活热力图-猫')\n",
    "#visualizer_heatmap(model,test_cat_path,last_conv_layer_name,target_size=(img_height,img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##可视化类激活热力图\n",
    "print('可视化类激活热力图-狗')\n",
    "#visualizer_heatmap(model,test_dog_path,last_conv_layer_name,target_size=(img_height,img_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化网络过滤器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##可视化网络过滤器\n",
    "print('\\n==============================================')\n",
    "print('可视化网络过滤器')\n",
    "#visualizer_filter_input(model,layers_name,gen_pat_steps=gen_pat_steps,images_per_row=images_per_row\n",
    "#                        ,img_width=img_width,img_height=img_height,img_margin=img_margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
