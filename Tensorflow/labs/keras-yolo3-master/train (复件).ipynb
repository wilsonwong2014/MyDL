{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练执行流程线索\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#-----GPU配置-----\n",
    "#  提示：在其他代码之前进行以下配置\n",
    "\n",
    "#禁用GPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #-1:禁用,0-n启用第几块显卡，多个以逗号隔开\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "#ConfigProto配置\n",
    "config = tf.ConfigProto()\n",
    "\n",
    "#设置GPU的百分比，程序需要还是会突破阈值\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8 #0-1之间的浮点数表示占用百分比\n",
    "#GPU按需使用,不全部占满显存, 按需分配\n",
    "config.gpu_options.allow_growth=True #True:按需分配,False:一次性满额分配\n",
    "\n",
    "# 设置session\n",
    "sess = tf.Session(config=config)\n",
    "KTF.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============train_model================\n",
      "--------params--------\n",
      "path: /home/hjw/work/data/yolo/mytrain_model_data\n",
      "start_layer: -1\n",
      "lr: 0.001\n",
      "batch_size: 14\n",
      "epochs: 50\n",
      "log_dir: /home/hjw/work/data/yolo/mytrain_model_data/log\n",
      "annotation_path: /home/hjw/work/data/yolo/mytrain_model_data/train.txt\n",
      "classes_path: /home/hjw/work/data/yolo/mytrain_model_data/voc_classes.txt\n",
      "anchors_path: /home/hjw/work/data/yolo/mytrain_model_data/yolo_anchors.txt\n",
      "input_shape: (416, 416)\n",
      "num_classes: 20\n",
      "class_names: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
      "anchors: [[ 22.  33.]\n",
      " [ 46.  52.]\n",
      " [ 58. 113.]\n",
      " [106. 186.]\n",
      " [107.  76.]\n",
      " [188. 274.]\n",
      " [202. 132.]\n",
      " [374. 195.]\n",
      " [374. 337.]]\n",
      "num_anchors: 9\n",
      "\n",
      "\n",
      "create_model!\n",
      "Create YOLOv3 model with 9 anchors and 20 classes.\n",
      "Load weights /home/hjw/work/data/yolo/mytrain_model_data/yolo_weights.h5.\n",
      "Freeze the first 249 layers of total 252 layers.\n",
      "==========yolo_loss===========\n",
      "mdoel.input_shape: [(None, None, None, 3), (None, 13, 13, 3, 25), (None, 26, 26, 3, 25), (None, 52, 52, 3, 25)]\n",
      "mdoel.output_shape: (None, 1)\n",
      "Train on 5146 samples, val on 571 samples, with batch size 14.\n",
      "<class 'generator'>\n",
      "Epoch 1/50\n",
      "367/367 [==============================] - 281s 764ms/step - loss: 336.4946 - acc: 0.0000e+00 - val_loss: 53.1285 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "367/367 [==============================] - 272s 742ms/step - loss: 45.9254 - acc: 0.0000e+00 - val_loss: 39.8331 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "367/367 [==============================] - 274s 746ms/step - loss: 38.5991 - acc: 0.0000e+00 - val_loss: 37.4997 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "367/367 [==============================] - 273s 744ms/step - loss: 35.7660 - acc: 0.0000e+00 - val_loss: 35.3973 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "367/367 [==============================] - 272s 740ms/step - loss: 34.3322 - acc: 0.0000e+00 - val_loss: 34.2477 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "367/367 [==============================] - 273s 743ms/step - loss: 33.1233 - acc: 0.0000e+00 - val_loss: 32.4969 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "367/367 [==============================] - 273s 744ms/step - loss: 32.3769 - acc: 0.0000e+00 - val_loss: 31.9106 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "367/367 [==============================] - 273s 745ms/step - loss: 31.6369 - acc: 0.0000e+00 - val_loss: 31.9747 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "367/367 [==============================] - 273s 743ms/step - loss: 31.0489 - acc: 0.0000e+00 - val_loss: 30.9618 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "367/367 [==============================] - 273s 743ms/step - loss: 30.5709 - acc: 0.0000e+00 - val_loss: 31.0992 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "367/367 [==============================] - 273s 744ms/step - loss: 30.0148 - acc: 0.0000e+00 - val_loss: 30.5554 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "367/367 [==============================] - 273s 745ms/step - loss: 29.7606 - acc: 0.0000e+00 - val_loss: 29.5037 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "367/367 [==============================] - 272s 742ms/step - loss: 29.3270 - acc: 0.0000e+00 - val_loss: 29.8372 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "367/367 [==============================] - 273s 743ms/step - loss: 29.0286 - acc: 0.0000e+00 - val_loss: 29.4837 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "367/367 [==============================] - 274s 745ms/step - loss: 28.6121 - acc: 0.0000e+00 - val_loss: 29.4459 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "367/367 [==============================] - 273s 744ms/step - loss: 28.3471 - acc: 0.0000e+00 - val_loss: 29.2690 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "367/367 [==============================] - 273s 744ms/step - loss: 28.0349 - acc: 0.0000e+00 - val_loss: 28.5871 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "367/367 [==============================] - 273s 743ms/step - loss: 27.6511 - acc: 0.0000e+00 - val_loss: 28.1104 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "367/367 [==============================] - 273s 744ms/step - loss: 27.5032 - acc: 0.0000e+00 - val_loss: 27.8113 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "367/367 [==============================] - 273s 743ms/step - loss: 27.3053 - acc: 0.0000e+00 - val_loss: 27.7623 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "367/367 [==============================] - 274s 746ms/step - loss: 27.2325 - acc: 0.0000e+00 - val_loss: 27.7582 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "367/367 [==============================] - 272s 742ms/step - loss: 26.8909 - acc: 0.0000e+00 - val_loss: 27.1994 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "367/367 [==============================] - 274s 746ms/step - loss: 26.7954 - acc: 0.0000e+00 - val_loss: 26.6946 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "367/367 [==============================] - 273s 745ms/step - loss: 26.4775 - acc: 0.0000e+00 - val_loss: 27.2380 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "367/367 [==============================] - 272s 742ms/step - loss: 26.5416 - acc: 0.0000e+00 - val_loss: 26.9884 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "367/367 [==============================] - 274s 746ms/step - loss: 26.5798 - acc: 0.0000e+00 - val_loss: 26.5050 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "367/367 [==============================] - 274s 747ms/step - loss: 26.2718 - acc: 0.0000e+00 - val_loss: 27.4780 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "367/367 [==============================] - 273s 744ms/step - loss: 26.3532 - acc: 0.0000e+00 - val_loss: 26.9595 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "367/367 [==============================] - 272s 742ms/step - loss: 26.2573 - acc: 0.0000e+00 - val_loss: 26.3425 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "367/367 [==============================] - 272s 742ms/step - loss: 26.0679 - acc: 0.0000e+00 - val_loss: 26.0513 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "367/367 [==============================] - 273s 745ms/step - loss: 25.9998 - acc: 0.0000e+00 - val_loss: 26.8175 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "367/367 [==============================] - 273s 744ms/step - loss: 25.9284 - acc: 0.0000e+00 - val_loss: 26.8499 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "367/367 [==============================] - 272s 742ms/step - loss: 25.9878 - acc: 0.0000e+00 - val_loss: 26.7292 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "367/367 [==============================] - 273s 743ms/step - loss: 25.7996 - acc: 0.0000e+00 - val_loss: 26.0216 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "367/367 [==============================] - 273s 744ms/step - loss: 25.7622 - acc: 0.0000e+00 - val_loss: 26.6228 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "367/367 [==============================] - 274s 746ms/step - loss: 25.7369 - acc: 0.0000e+00 - val_loss: 26.6806 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "367/367 [==============================] - 273s 743ms/step - loss: 25.9611 - acc: 0.0000e+00 - val_loss: 26.4869 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "367/367 [==============================] - 273s 745ms/step - loss: 25.7212 - acc: 0.0000e+00 - val_loss: 26.5055 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "367/367 [==============================] - 271s 740ms/step - loss: 25.6722 - acc: 0.0000e+00 - val_loss: 26.7481 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "367/367 [==============================] - 274s 746ms/step - loss: 25.8731 - acc: 0.0000e+00 - val_loss: 25.4061 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "367/367 [==============================] - 273s 744ms/step - loss: 25.6461 - acc: 0.0000e+00 - val_loss: 26.5642 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "367/367 [==============================] - 273s 743ms/step - loss: 25.6471 - acc: 0.0000e+00 - val_loss: 26.8392 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "367/367 [==============================] - 273s 744ms/step - loss: 25.8739 - acc: 0.0000e+00 - val_loss: 25.5588 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "367/367 [==============================] - 273s 745ms/step - loss: 25.6301 - acc: 0.0000e+00 - val_loss: 25.7608 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "367/367 [==============================] - 273s 743ms/step - loss: 25.6934 - acc: 0.0000e+00 - val_loss: 27.0727 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "367/367 [==============================] - 273s 743ms/step - loss: 25.9225 - acc: 0.0000e+00 - val_loss: 26.1530 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "367/367 [==============================] - 271s 739ms/step - loss: 25.9962 - acc: 0.0000e+00 - val_loss: 26.7627 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 274s 745ms/step - loss: 25.6402 - acc: 0.0000e+00 - val_loss: 25.9799 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "367/367 [==============================] - 273s 744ms/step - loss: 25.6342 - acc: 0.0000e+00 - val_loss: 26.1270 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "367/367 [==============================] - 274s 745ms/step - loss: 25.5185 - acc: 0.0000e+00 - val_loss: 26.8417 - val_acc: 0.0000e+00\n",
      "save model to file: /home/hjw/work/data/yolo/mytrain_model_data/yolo_weights.h5\n",
      "\n",
      "\n",
      "\n",
      "===============train_model================\n",
      "--------params--------\n",
      "path: /home/hjw/work/data/yolo/mytrain_model_data\n",
      "start_layer: 0\n",
      "lr: 0.0001\n",
      "batch_size: 14\n",
      "epochs: 200\n",
      "log_dir: /home/hjw/work/data/yolo/mytrain_model_data/log\n",
      "annotation_path: /home/hjw/work/data/yolo/mytrain_model_data/train.txt\n",
      "classes_path: /home/hjw/work/data/yolo/mytrain_model_data/voc_classes.txt\n",
      "anchors_path: /home/hjw/work/data/yolo/mytrain_model_data/yolo_anchors.txt\n",
      "input_shape: (416, 416)\n",
      "num_classes: 20\n",
      "class_names: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
      "anchors: [[ 22.  33.]\n",
      " [ 46.  52.]\n",
      " [ 58. 113.]\n",
      " [106. 186.]\n",
      " [107.  76.]\n",
      " [188. 274.]\n",
      " [202. 132.]\n",
      " [374. 195.]\n",
      " [374. 337.]]\n",
      "num_anchors: 9\n",
      "\n",
      "\n",
      "create_model!\n",
      "Create YOLOv3 model with 9 anchors and 20 classes.\n",
      "Load weights /home/hjw/work/data/yolo/mytrain_model_data/yolo_weights.h5.\n",
      "Freeze the first 249 layers of total 252 layers.\n",
      "==========yolo_loss===========\n",
      "mdoel.input_shape: [(None, None, None, 3), (None, 13, 13, 3, 25), (None, 26, 26, 3, 25), (None, 52, 52, 3, 25)]\n",
      "mdoel.output_shape: (None, 1)\n",
      "unfreeze from start_layer: 0\n",
      "Train on 5146 samples, val on 571 samples, with batch size 14.\n",
      "<class 'generator'>\n",
      "Epoch 51/200\n",
      "367/367 [==============================] - 289s 787ms/step - loss: 25.1810 - acc: 0.0000e+00 - val_loss: 25.0826 - val_acc: 0.0000e+00\n",
      "Epoch 52/200\n",
      "367/367 [==============================] - 275s 750ms/step - loss: 23.7883 - acc: 0.0000e+00 - val_loss: 23.6417 - val_acc: 0.0000e+00\n",
      "Epoch 53/200\n",
      "367/367 [==============================] - 276s 751ms/step - loss: 23.2746 - acc: 0.0000e+00 - val_loss: 24.5882 - val_acc: 0.0000e+00\n",
      "Epoch 54/200\n",
      "367/367 [==============================] - 276s 752ms/step - loss: 22.8989 - acc: 0.0000e+00 - val_loss: 24.1320 - val_acc: 0.0000e+00\n",
      "Epoch 55/200\n",
      "367/367 [==============================] - 276s 751ms/step - loss: 22.6695 - acc: 0.0000e+00 - val_loss: 24.2252 - val_acc: 0.0000e+00\n",
      "Epoch 56/200\n",
      "367/367 [==============================] - 276s 753ms/step - loss: 22.3281 - acc: 0.0000e+00 - val_loss: 24.2219 - val_acc: 0.0000e+00\n",
      "Epoch 57/200\n",
      "367/367 [==============================] - 276s 752ms/step - loss: 22.2323 - acc: 0.0000e+00 - val_loss: 24.0432 - val_acc: 0.0000e+00\n",
      "Epoch 58/200\n",
      "367/367 [==============================] - 276s 752ms/step - loss: 22.0091 - acc: 0.0000e+00 - val_loss: 23.8322 - val_acc: 0.0000e+00\n",
      "Epoch 59/200\n",
      "367/367 [==============================] - 276s 752ms/step - loss: 21.8197 - acc: 0.0000e+00 - val_loss: 24.0596 - val_acc: 0.0000e+00\n",
      "Epoch 60/200\n",
      "367/367 [==============================] - 276s 751ms/step - loss: 21.7189 - acc: 0.0000e+00 - val_loss: 24.2778 - val_acc: 0.0000e+00\n",
      "Epoch 61/200\n",
      "367/367 [==============================] - 276s 751ms/step - loss: 21.4987 - acc: 0.0000e+00 - val_loss: 23.3735 - val_acc: 0.0000e+00\n",
      "Epoch 62/200\n",
      "367/367 [==============================] - 276s 751ms/step - loss: 21.3580 - acc: 0.0000e+00 - val_loss: 23.9267 - val_acc: 0.0000e+00\n",
      "Epoch 63/200\n",
      "367/367 [==============================] - 276s 753ms/step - loss: 21.1622 - acc: 0.0000e+00 - val_loss: 24.4672 - val_acc: 0.0000e+00\n",
      "Epoch 64/200\n",
      "367/367 [==============================] - 276s 753ms/step - loss: 21.0929 - acc: 0.0000e+00 - val_loss: 23.6048 - val_acc: 0.0000e+00\n",
      "Epoch 65/200\n",
      "367/367 [==============================] - 276s 753ms/step - loss: 20.9466 - acc: 0.0000e+00 - val_loss: 23.8883 - val_acc: 0.0000e+00\n",
      "Epoch 66/200\n",
      "367/367 [==============================] - 276s 751ms/step - loss: 21.1035 - acc: 0.0000e+00 - val_loss: 23.7778 - val_acc: 0.0000e+00\n",
      "Epoch 67/200\n",
      "367/367 [==============================] - 276s 751ms/step - loss: 20.9118 - acc: 0.0000e+00 - val_loss: 23.6238 - val_acc: 0.0000e+00\n",
      "Epoch 68/200\n",
      "367/367 [==============================] - 276s 752ms/step - loss: 20.6379 - acc: 0.0000e+00 - val_loss: 25.0998 - val_acc: 0.0000e+00\n",
      "Epoch 69/200\n",
      "367/367 [==============================] - 276s 752ms/step - loss: 20.5373 - acc: 0.0000e+00 - val_loss: 22.1721 - val_acc: 0.0000e+00\n",
      "Epoch 70/200\n",
      "367/367 [==============================] - 276s 753ms/step - loss: 20.3582 - acc: 0.0000e+00 - val_loss: 24.2890 - val_acc: 0.0000e+00\n",
      "Epoch 71/200\n",
      "367/367 [==============================] - 276s 752ms/step - loss: 20.4325 - acc: 0.0000e+00 - val_loss: 23.9071 - val_acc: 0.0000e+00\n",
      "Epoch 72/200\n",
      "367/367 [==============================] - 276s 753ms/step - loss: 20.1164 - acc: 0.0000e+00 - val_loss: 24.6012 - val_acc: 0.0000e+00\n",
      "Epoch 73/200\n",
      "367/367 [==============================] - 276s 752ms/step - loss: 19.9410 - acc: 0.0000e+00 - val_loss: 24.3221 - val_acc: 0.0000e+00\n",
      "Epoch 74/200\n",
      "367/367 [==============================] - 276s 751ms/step - loss: 20.0834 - acc: 0.0000e+00 - val_loss: 23.2230 - val_acc: 0.0000e+00\n",
      "Epoch 75/200\n",
      "367/367 [==============================] - 276s 752ms/step - loss: 19.9731 - acc: 0.0000e+00 - val_loss: 24.7281 - val_acc: 0.0000e+00\n",
      "Epoch 76/200\n",
      "367/367 [==============================] - 276s 752ms/step - loss: 19.8234 - acc: 0.0000e+00 - val_loss: 23.2585 - val_acc: 0.0000e+00\n",
      "Epoch 77/200\n",
      "367/367 [==============================] - 276s 752ms/step - loss: 19.7526 - acc: 0.0000e+00 - val_loss: 23.7630 - val_acc: 0.0000e+00\n",
      "Epoch 78/200\n",
      "367/367 [==============================] - 276s 752ms/step - loss: 19.7158 - acc: 0.0000e+00 - val_loss: 24.1126 - val_acc: 0.0000e+00\n",
      "Epoch 79/200\n",
      "367/367 [==============================] - 276s 751ms/step - loss: 19.5335 - acc: 0.0000e+00 - val_loss: 24.1238 - val_acc: 0.0000e+00\n",
      "Epoch 80/200\n",
      "367/367 [==============================] - 276s 752ms/step - loss: 19.4313 - acc: 0.0000e+00 - val_loss: 23.2196 - val_acc: 0.0000e+00\n",
      "Epoch 81/200\n",
      "367/367 [==============================] - 276s 752ms/step - loss: 19.3852 - acc: 0.0000e+00 - val_loss: 23.4668 - val_acc: 0.0000e+00\n",
      "Epoch 82/200\n",
      "367/367 [==============================] - 276s 752ms/step - loss: 19.2594 - acc: 0.0000e+00 - val_loss: 24.1574 - val_acc: 0.0000e+00\n",
      "Epoch 83/200\n",
      "367/367 [==============================] - 276s 751ms/step - loss: 19.2849 - acc: 0.0000e+00 - val_loss: 23.1940 - val_acc: 0.0000e+00\n",
      "Epoch 84/200\n",
      "367/367 [==============================] - 276s 751ms/step - loss: 19.1364 - acc: 0.0000e+00 - val_loss: 23.3378 - val_acc: 0.0000e+00\n",
      "Epoch 85/200\n",
      "367/367 [==============================] - 276s 752ms/step - loss: 19.2419 - acc: 0.0000e+00 - val_loss: 24.4598 - val_acc: 0.0000e+00\n",
      "Epoch 86/200\n",
      "367/367 [==============================] - 276s 751ms/step - loss: 18.8576 - acc: 0.0000e+00 - val_loss: 23.4582 - val_acc: 0.0000e+00\n",
      "Epoch 87/200\n",
      "367/367 [==============================] - 276s 751ms/step - loss: 18.9128 - acc: 0.0000e+00 - val_loss: 23.9428 - val_acc: 0.0000e+00\n",
      "Epoch 88/200\n",
      "367/367 [==============================] - 276s 752ms/step - loss: 18.9045 - acc: 0.0000e+00 - val_loss: 23.7118 - val_acc: 0.0000e+00\n",
      "Epoch 89/200\n",
      "367/367 [==============================] - 276s 752ms/step - loss: 18.6879 - acc: 0.0000e+00 - val_loss: 23.4703 - val_acc: 0.0000e+00\n",
      "Epoch 90/200\n",
      "367/367 [==============================] - 276s 752ms/step - loss: 18.8143 - acc: 0.0000e+00 - val_loss: 23.9357 - val_acc: 0.0000e+00\n",
      "Epoch 91/200\n",
      "367/367 [==============================] - 276s 751ms/step - loss: 18.6565 - acc: 0.0000e+00 - val_loss: 23.7249 - val_acc: 0.0000e+00\n",
      "Epoch 92/200\n",
      "367/367 [==============================] - 279s 761ms/step - loss: 18.6743 - acc: 0.0000e+00 - val_loss: 23.4790 - val_acc: 0.0000e+00\n",
      "Epoch 93/200\n",
      "367/367 [==============================] - 276s 752ms/step - loss: 18.5782 - acc: 0.0000e+00 - val_loss: 22.9920 - val_acc: 0.0000e+00\n",
      "Epoch 94/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 277s 755ms/step - loss: 18.5495 - acc: 0.0000e+00 - val_loss: 23.7646 - val_acc: 0.0000e+00\n",
      "Epoch 95/200\n",
      "367/367 [==============================] - 276s 751ms/step - loss: 18.5022 - acc: 0.0000e+00 - val_loss: 24.4391 - val_acc: 0.0000e+00\n",
      "Epoch 96/200\n",
      "367/367 [==============================] - 276s 753ms/step - loss: 18.2458 - acc: 0.0000e+00 - val_loss: 22.9456 - val_acc: 0.0000e+00\n",
      "Epoch 97/200\n",
      "367/367 [==============================] - 275s 749ms/step - loss: 18.2227 - acc: 0.0000e+00 - val_loss: 23.3956 - val_acc: 0.0000e+00\n",
      "Epoch 98/200\n",
      "367/367 [==============================] - 276s 753ms/step - loss: 18.1855 - acc: 0.0000e+00 - val_loss: 23.4236 - val_acc: 0.0000e+00\n",
      "Epoch 99/200\n",
      "367/367 [==============================] - 276s 753ms/step - loss: 18.1981 - acc: 0.0000e+00 - val_loss: 23.5554 - val_acc: 0.0000e+00\n",
      "Epoch 100/200\n",
      "352/367 [===========================>..] - ETA: 10s - loss: 18.2921 - acc: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-282eea5a5b3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m \u001b[0m_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#训练函数入口\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-282eea5a5b3b>\u001b[0m in \u001b[0;36m_main\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m#批大小\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0;31m#迭代次数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0minit_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         )\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#模型训练\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-282eea5a5b3b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(path, start_layer, lr, batch_size, epochs, init_epochs)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#epochs=50,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             callbacks=[logging, checkpoint])\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m#=================保存训练参数================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Retrain the YOLO model for your own dataset.\n",
    "\"\"\"\n",
    "import pdb\n",
    "#pdb.set_trace()\n",
    "import os\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
    "from yolo3.utils import get_random_data\n",
    "\n",
    "path='%s/work/data/yolo/mytrain_model_data'%(os.getenv('HOME')) #数据存放根目录\n",
    "\n",
    "def _main():\n",
    "    his1=train_model(\n",
    "        path,           #数据目录\n",
    "        start_layer=-1, #起始解冻层,-1不解冻\n",
    "        lr=1e-3,        #学习率\n",
    "        batch_size=14,  #批大小\n",
    "        epochs=50,      #迭代次数\n",
    "        init_epochs=0\n",
    "        )\n",
    "    \n",
    "    train_model(\n",
    "        path,           #数据目录\n",
    "        start_layer=0, #起始解冻层,-1不解冻\n",
    "        lr=1e-4,        #学习率\n",
    "        batch_size=14,  #批大小\n",
    "        epochs=200,     #迭代次数\n",
    "        init_epochs=50\n",
    "        )\n",
    "#模型训练\n",
    "def train_model(\n",
    "        path,           #数据目录\n",
    "        start_layer=-1, #起始解冻层,-1不解冻\n",
    "        lr=1e-3,        #学习率\n",
    "        batch_size=32,  #批大小\n",
    "        epochs=20,      #迭代次数\n",
    "        init_epochs=0   #初始迭代次数\n",
    "        ):\n",
    "    print('===============train_model================')\n",
    "    #===============训练参数配置==================\n",
    "    annotation_path = '%s/train.txt'%(path)      #训练样本，注释文件,格式：/img_file 6,1,314,262,19 40,97,121,411,4 137,36,169,109,14 180,36,216,104,14 96,39,123,103,14\n",
    "                                                 #由voc_annotation.py生成\n",
    "    log_dir = '%s/log'%(path)                    #日志目录\n",
    "    classes_path = '%s/voc_classes.txt'%(path)   #VOC数据集标签类别(20类)\n",
    "    anchors_path = '%s/yolo_anchors.txt'%(path)  #yolo anchor配置文件[10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326]\n",
    "    class_names = get_classes(classes_path)      #读取VOC数据集标签类别[aeroplane,bicycle,bird,boat,bottle,bus,car,cat,chair,cow,diningtable,dog,horse,motorbike,person,pottedplant,sheep,sofa,train,tvmonitor]\n",
    "    num_classes = len(class_names)               #标签类别数(20)\n",
    "    anchors = get_anchors(anchors_path)          #锚点wh,anchors [[10,13],  [16,30],  [33,23],  [30,61],  [62,45],  [59,119],  [116,90],  [156,198],  [373,326]]\n",
    "    input_shape = (416,416)                      # multiple of 32, hw #模型输入尺寸\n",
    "\n",
    "    #=================加载训练样本文件================\n",
    "    val_split = 0.1                     #留出百分之10的数据用于校验\n",
    "    with open(annotation_path) as f:\n",
    "        lines = f.readlines()           #每行形如以下格式：img_file 6,1,314,262,19 40,97,121,411,4 137,36,169,109,14 180,36,216,104,14 96,39,123,103,14\n",
    "    np.random.seed(10101)               #设置随机种子，固化每次的随机序列(伪随机)\n",
    "    np.random.shuffle(lines)            #打乱顺序\n",
    "    np.random.seed(None)                #恢复随机状态\n",
    "    num_val = int(len(lines)*val_split) #校验样本数\n",
    "    num_train = len(lines) - num_val    #训练样本数\n",
    "\n",
    "    is_tiny_version = len(anchors)==6 # default setting\n",
    "    if is_tiny_version:\n",
    "        model_file='%s/tiny_yolo_weights.h5'%path\n",
    "        cp_file='%s/tiny_cp_file.h5'%path\n",
    "    else:\n",
    "        model_file='%s/yolo_weights.h5'%path\n",
    "        cp_file='%s/cp_file.h5'%path\n",
    "        \n",
    "    print('--------params--------')\n",
    "    print('path:',path)\n",
    "    print('start_layer:',start_layer)\n",
    "    print('lr:',lr)\n",
    "    print('batch_size:',batch_size)\n",
    "    print('epochs:',epochs)\n",
    "    print('log_dir:',log_dir)\n",
    "    print('annotation_path:',annotation_path)\n",
    "    print('classes_path:',classes_path)\n",
    "    print('anchors_path:',anchors_path)\n",
    "    print('input_shape:',input_shape)\n",
    "    print('num_classes:',num_classes)\n",
    "    print('class_names:',class_names)\n",
    "    print('anchors:',anchors)\n",
    "    print('num_anchors:',len(anchors))\n",
    "    print('\\n')\n",
    "    \n",
    "    #===============创建训练模型=================\n",
    "    #freeze_body=2 => 冻结除y1,y2,y3的所有层\n",
    "    if is_tiny_version:\n",
    "        print('create_tiny_model!')\n",
    "        model = create_tiny_model(input_shape, anchors, num_classes,\n",
    "            freeze_body=2, weights_path=model_file)\n",
    "    else:\n",
    "        print('create_model!')\n",
    "        #freeze_body:1-解冻所有层，2-冻结darknet\n",
    "        model = create_model(input_shape, anchors, num_classes,\n",
    "            freeze_body=2, weights_path=model_file) # make sure you know what you freeze\n",
    "        print('mdoel.input_shape:',model.input_shape)   #mdoel.input_shape: [(None, None, None, 3), (None, 13, 13, 3, 25), (None, 26, 26, 3, 25), (None, 52, 52, 3, 25)]\n",
    "        print('mdoel.output_shape:',model.output_shape) #mdoel.output_shape: (None, 1) --- loss\n",
    "    \n",
    "    #================训练回调函数设置=================\n",
    "    #TensorBoard可视化日志\n",
    "    logging = TensorBoard(log_dir=log_dir)\n",
    "    #断点保存\n",
    "    checkpoint = ModelCheckpoint(cp_file,\n",
    "        monitor='val_loss', save_weights_only=True, save_best_only=True, period=1)\n",
    "    #学习率\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "    #退出条件\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "\n",
    "    #=================解冻层====================\n",
    "    if start_layer>=0:\n",
    "        print('unfreeze from start_layer:',start_layer)\n",
    "        for i in range(start_layer,len(model.layers)):\n",
    "            model.layers[i].trainable = True\n",
    "\n",
    "    #=================模型编译===================\n",
    "    model.compile(optimizer=Adam(lr=lr), loss={'yolo_loss': lambda y_true, y_pred: y_pred},metrics=['accuracy'])\n",
    "\n",
    "    #=================构造训练数据生成器==========\n",
    "    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "    #anchors=>[[10,13],  [16,30],  [33,23],  [30,61],  [62,45],  [59,119],  [116,90],  [156,198],  [373,326]]\n",
    "    data_gen=data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes)\n",
    "    print(type(data_gen))\n",
    "    #print('data_gen.shape:',data_gen.shape) #\n",
    "    #data_gen.shape=>([(32, 416, 416, 3), (32, 13, 13, 3, 25), (32, 26, 26, 3, 25), (32, 52, 52, 3, 25)],(32,))\n",
    "\n",
    "    #=================模型训练====================\n",
    "    history=model.fit_generator(data_gen,\n",
    "            steps_per_epoch=max(1, num_train//batch_size),\n",
    "            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "            validation_steps=max(1, num_val//batch_size),\n",
    "            epochs=epochs,#epochs=50,\n",
    "            initial_epoch=init_epochs,\n",
    "            callbacks=[logging, checkpoint])\n",
    "\n",
    "    #=================保存训练参数================\n",
    "    print('save model to file:',model_file)\n",
    "    model.save_weights(model_file)\n",
    "    print('\\n\\n')\n",
    "    return history\n",
    "    \n",
    "def get_classes(classes_path):\n",
    "    '''loads the classes'''\n",
    "    '''加载检测类别名称\n",
    "    @param classes_path 检测类别文件,文件内容每行表示一个类别名称，如：\n",
    "        dog\n",
    "        cat\n",
    "    @return class_names [list]检测类别名称\n",
    "    '''\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    '''加载锚点数组\n",
    "    @param anchors_path 锚点文件路径,文件内容如下所示：\n",
    "        10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\n",
    "        每两个组成一个锚点，标识边框的宽度与高度wh\n",
    "    @return np.array(anchors).reshape(-1, 2) \n",
    "    '''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "\n",
    "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/yolo_weights.h5'):\n",
    "    '''create the training model'''\n",
    "    '''构建模型\n",
    "    @param input_shape     [tuple]模型输入尺寸,val=>(416,416)\n",
    "    @param anchors         [array]锚点数组,shape=>(9,2)\n",
    "    @param num_classes     [int  ]检测类别数,val=>20\n",
    "    @param load_pretrained [bool ]是否预加载参数\n",
    "    @param freeze_body     [int  ]模型层的冻结方式，1-冻结darknet53,2-除y1y2y3的所有层，其他-不做冻结设置\n",
    "    @param weights_path    [str  ]预训练模型参数路径\n",
    "\n",
    "    @return model\n",
    "        模型输入:image_data,y1,y2,y3\n",
    "        模型输出:loss\n",
    "    '''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    #=============定义输出标签值:y_true=[y1,y2,y3]=============\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
    "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
    "    '''\n",
    "    h=>416\n",
    "    w=>416\n",
    "    num_anchors=>9\n",
    "    num_classes=>20\n",
    "    y_true=>[<tf.Tensor 'input_1:0' shape=(?, 13, 13, 3, 25) dtype=float32>,\n",
    "             <tf.Tensor 'input_2:0' shape=(?, 26, 26, 3, 25) dtype=float32>,\n",
    "             <tf.Tensor 'input_3:0' shape=(?, 52, 52, 3, 25) dtype=float32>]\n",
    "    '''\n",
    "    \n",
    "    #=============yolo主体模型================================\n",
    "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
    "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    #=============加载预训练模型参数==========================\n",
    "    if load_pretrained and os.path.exists(weights_path):\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
    "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    #=============定义网络loss===============================\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
    "        [*model_body.output, *y_true])\n",
    "\n",
    "    #=============重构模型===================================\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    #输出最终训练模型\n",
    "    return model\n",
    "\n",
    "def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/tiny_yolo_weights.h5'):\n",
    "    '''create the training model, for Tiny YOLOv3'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n",
    "        num_anchors//2, num_classes+5)) for l in range(2)]\n",
    "\n",
    "    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n",
    "    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained and os.path.exists(weights_path):\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze the darknet body or freeze all but 2 output layers.\n",
    "            num = (20, len(model_body.layers)-2)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator'''\n",
    "    '''数据生成器\n",
    "    @param annotations_lines 训练样本，每行形如以下格式：img_file 6,1,314,262,19 40,97,121,411,4 137,36,169,109,14 180,36,216,104,14 96,39,123,103,14 \n",
    "    @param batch_size 批大小,32\n",
    "    @param input_shape 模型输入尺寸(416,416)\n",
    "    @param anchors bounding box 锚点wh:[[10,13],  [16,30],  [33,23],  [30,61],  [62,45],  [59,119],  [116,90],  [156,198],  [373,326]]\n",
    "    @param num_classes 标签类别数,20\n",
    "    @return yield [image_data, *y_true], np.zeros(batch_size) => ([image_data,y1,y2,y3],loss)\n",
    "                                                              => ([(32,416,416,3),(32,13,13,3,25),(32,26,26,3,25),(32,52,52,3,25),(32,)])\n",
    "    '''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0: #一轮\n",
    "                np.random.shuffle(annotation_lines) #打乱排序\n",
    "            #生成一个样本数据,image.shape=>(416,416,3),box.shape=>(20,5)\n",
    "            #image做数据增强、归一化处理；box与image同步做变形、偏移处理，未归一化\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)  \n",
    "            image_data.append(image) #图像序列\n",
    "            box_data.append(box)     #bounding box序列\n",
    "            i = (i+1) % n\n",
    "        image_data = np.array(image_data)                                           #=>shape:(32,416,416,3)\n",
    "        box_data = np.array(box_data)                                               #=>shape:(32,20,5)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes) #=>把样本原始数据转换为训练需要的数据格式\n",
    "        '''\n",
    "        image_data:shape=>(32,416,416,3),模型输入图像数据\n",
    "        y_true:[y1,y2,y3],               模型输入Box标签数据\n",
    "            y1:shape=>(32,13,13,3,25)\n",
    "            y2:shape=>(32,26,26,3,25)\n",
    "            y3:shape=>(32,52,52,3,25)\n",
    "        np.zeros(batch_size):            模型输出loss\n",
    "\n",
    "        yield [image_data, *y_true], np.zeros(batch_size) => ([image_data,y1,y2,y3],loss)\n",
    "                                                          => ([(32,416,416,3),(32,13,13,3,25),(32,26,26,3,25),(32,52,52,3,25),(32,)])\n",
    "        '''        \n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n",
    "\n",
    "\n",
    "_main() #训练函数入口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-850795225b45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_file.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save_weights('model_file.h5')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
