{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOV3模型解读\n",
    "    更详尽的代码注释请看： \n",
    "    https://github.com/wilsonwong2014/MyDL/tree/master/Tensorflow/labs/keras-yolo3-master\n",
    "    关于目标检测的总数可以参考这篇博文：\n",
    "    https://blog.csdn.net/qq_35451572/article/details/80249259\n",
    "    关于公式的推导可以参考这篇博文：\n",
    "    https://blog.csdn.net/jesse_mx/article/details/53925356\n",
    "    关于损失函数可以参考这篇博文：\n",
    "    https://blog.csdn.net/yangchengtest/article/details/80664415\n",
    "    相关论文：\n",
    "    v1:\n",
    "    https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf\n",
    "    https://www.cnblogs.com/CZiFan/p/9516504.html\n",
    "    v2:\n",
    "    https://arxiv.org/pdf/1612.08242.pdf\n",
    "    https://blog.csdn.net/weixin_35654926/article/details/72473024\n",
    "    v3:\n",
    "    https://pjreddie.com/media/files/papers/YOLOv3.pdf\n",
    "    https://zhuanlan.zhihu.com/p/35023499    \n",
    "\n",
    "### 先一睹YOLO模型的芳蓉\n",
    "<img src=\"doc/fig_model2.png\" />\n",
    "\n",
    "    YOLO模型归类于边框回归的训练方法，通过标注数据的[x,y,w,h,class_id],我们预测[x',y',w',h',class_id']，通过训练模型获得参数使损失函数值最小.\n",
    "\n",
    "    箭头所指对应的函数或代码块.\n",
    "\n",
    "    左边1x,2x,8x,8x,4x为Darknet_body为官网提供的基础模型，用于特征提取,去掉最后的全链接层。添加全链接层，引入wordnet，联合训练Imagenet数据集，可以提升检测类别数，后面会有详细介绍。\n",
    "    y1,y2,y3是yolo_body网络输出。\n",
    "    scale1,scale2,scale3是三个不同的尺度值,不同尺度值对应不同分辨率，与anchors联合使用有一个分配策略问题，大尺度对应高分辨率，更容易检测到小目标，反之，小尺度对应小分辨率。\n",
    "    \n",
    "### YOLO是什么？\n",
    "    YOLO是当前最先进的目标检测模型，精度高，速度快，满足实时性要求。\n",
    "    YOLO是端对端(end-to-end)的，就是只要给模型输入一张图像，就可以检测到图像中的对象，不像传统的检测方案，需要进行复杂的特征计算。\n",
    "    \n",
    "### YOLO是如何工作的？\n",
    "    要使YOLO能检测对象，我们必须先对模型进行训练，训练达到我们要求的精度后，即可应用部署.\n",
    "\n",
    "### def yolo_body(inputs, num_anchors, num_classes)\n",
    "    生成 yolo_body模型\n",
    "    模型输入:\n",
    "        yolo_model.input --- inputs,shape=>(batch_size,416,416,3)\n",
    "    模型输出:\n",
    "        yolo_model.output => [y1,y2,y3]\n",
    "        y1 --- shape=>(batch_size,13,13,255)=>(batch_size,13,13,3,85)\n",
    "        y2 --- shape=>(batch_size,26,26,255)=>(batch_size,26,26,3,85)\n",
    "        y3 --- shape=>(batch_size,52,52,255)=>(batch_size,52,52,3,85)\n",
    "\n",
    "\n",
    "### anchors分配策略\n",
    "    anchors分配策略：一共有9个anchor,三个模型输出[y1,y2,y3]\n",
    "    anchor从小到大排序为0,1,2,3,4,5,6,7,8\n",
    "    y1的分辨率最小(13x13),其次为y2的分别率为(26x26),y3的分辨率最高(52x52)\n",
    "    高分辨率更容易检测小物体，因此，小的anchor分配给高分辨率的输出，大的anchor分配给小分辨率的输出\n",
    "    anchors(0,1,2)=>y3,(0,1,2)再分配给不同的滤波层[0:3]\n",
    "    anchors(3,4,5)=>y2,同上\n",
    "    anchors(6,7,8)=>y1,同上\n",
    "    \n",
    "    9个anchor分配给[y1,y2,y3]，每个yx得3个anchor，三个滤波层每个按序号得1个anchor\n",
    "    \n",
    "### 边框回归公式推导\n",
    "    Faster-RCNN anchor的预测公式\n",
    "$t_{x}=(x-x_{a}/w_{a})$   $\\qquad$  $t_{y}=(y-y_{a}/h_{a})$\n",
    "\n",
    "$t_{w}=log(w/w_{a})$      $\\qquad$  $t_{h}=log(h/h_{a})$\n",
    "\n",
    "$t_{x}^*=(x^*-x_{a}/w_{a})$   $\\qquad$  $t_{y}^*=(y^*-y_{a}/h_{a})$\n",
    "\n",
    "$t_{w}^*=log(w^*/w_{a})$      $\\qquad$  $t_{h}^*=log(h^*/h_{a})$\n",
    "\n",
    "公式中，符号的含义解释一下：x 是坐标预测值，$x_{a}$ 是anchor坐标（预设固定值），$x^∗$ 是坐标真实值（标注信息），其他变量 y，w，h 以此类推，t 变量是偏移量。\n",
    "\n",
    "    预测相对于grid cell的坐标位置的办法\n",
    "    \n",
    "<img src=\"doc/fig_model3.png\">    \n",
    "\n",
    "$t_{x},t_{y},t_{w},t_{h}$通过sigmoid限制在0-1之间;$p_{w},p_{h}$是anchor的宽度和高度,$c_{x},c_{y}$是grid cell左上角距离\n",
    "\n",
    "$b_{x},b_{y},b_{w},b_{h}$为预测值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练\n",
    "### 模型训练执行流程线索\n",
    "\n",
    "    构建模型 create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/yolo_weights.h5')\n",
    "      构建模型 model = Model([model_body.input, *y_true], model_loss)\n",
    "          模型输入\n",
    "              输入数据 image_input = Input(shape=(None, None, 3))\n",
    "                  1. 标准化模型输入尺寸 input_shape=>(416,416).\n",
    "                  2. 数据增强处理:缩放，偏移，仿射变换,HSV变换等.\n",
    "                  3. 归一化处理，限值在0-1之间.\n",
    "              标注数据 y_true => [y1,y2,y3]=> [(?,13,13,3,25),(?,26,26,3,25),(?,52,52,3,25)]\n",
    "                  1. box与输入图像做同步几何变换处理：缩放、偏移、仿射.\n",
    "                  2. x,y,w,h归一化处理，由绝对坐标转换为相对于input_shape的相对坐标，限值在0-1之间.\n",
    "          模型输出 model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "                    arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
    "                    [*model_body.output, *y_true])\n",
    "                  1. 添加Lambda层，设置自定义损失函数，损失函数值直接作为模型输出.\n",
    "    编译模型\n",
    "    训练模型\n",
    "        数据生成器 data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n",
    "            数据增强/提取boxs (image,box)=get_random_data(annotation_lines[i], input_shape, random=True)\n",
    "                image --- 图像增强处理，归一化处理\n",
    "                box   --- 与image同步变形，未归一化处理，shape=>(max_boxs,5)\n",
    "            标注数据处理 y_true=preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "                    box_data.shape=>(batch_size,max_boxs,5)\n",
    "                    提取图像有效框，匹配最佳anchor，在对应y_true位置填充box,obj,cls\n",
    "                    1.遍历批数据的每个图像=>m\n",
    "                    2.提取图像有效框=>wh\n",
    "                    3.计算每个框匹配的最佳anchor(IoU计算)=>n=>k\n",
    "                       根据n找到所属层(y1,y2 or y3)和filter_index\n",
    "                    4.查找最佳anchor属于那个层(anchor_mask)=>l\n",
    "                    5.换算外框中心所属grid cell=>(j,i)\n",
    "                    6.提取类别ID=>c\n",
    "                    7.填充 y_true\n",
    "                        y_true[l][b, j, i, k, 0:4] = true_boxes[b,t, 0:4]  #x,y,w,h\n",
    "                        y_true[l][b, j, i, k, 4] = 1                       #所有检测类别统一视为Object\n",
    "                        y_true[l][b, j, i, k, 5+c] = 1                     #对应类别序号上设置标记\n",
    "                        x,y,w,h是归一化值，相对值0-1之间\n",
    "        损失函数 yolo_loss(args, anchors, num_classes, ignore_thresh=.5, print_loss=False)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型测试\n",
    "\n",
    "### 模型测试执行流程线索\n",
    "    设置执行参数 => params\n",
    "    创建YOLO对象=> yolo=YOLO(**params)\n",
    "     |- 读取分类列表 => self.class_names=self._get_classes()\n",
    "     |- 读取锚框数组 => self.anchors=self._get_anchors()\n",
    "     |- 构造测试模型 => self.boxes, self.scores, self.classes = self.generate()\n",
    "     |   |- 构造YOLO模型 => self.yolo_model=yolo_body(Input(shape=(None,None,3)),                                              \n",
    "     |   |   |                                       num_anchors//3, num_classes)\n",
    "     |   |   |-构造darknet => darknet=Model(inputs, darknet_body(inputs))\n",
    "     |   |   |  |-  x = DarknetConv2D_BN_Leaky(32, (3,3))(x)\n",
    "     |   |   |  |       return compose(\n",
    "     |   |   |  |           DarknetConv2D(*args, **no_bias_kwargs),\n",
    "     |   |   |  |           BatchNormalization(), \n",
    "     |   |   |  |           LeakyReLU(alpha=0.1))                    \n",
    "     |   |   |  |-  x = resblock_body(x, 64, 1)\n",
    "     |   |   |  |       x = ZeroPadding2D(((1,0),(1,0)))(x)\n",
    "     |   |   |  |       x = DarknetConv2D_BN_Leaky(num_filters, (3,3), strides=(2,2))(x)\n",
    "     |   |   |  |       for i in range(num_blocks):\n",
    "     |   |   |  |           y = compose(\n",
    "     |   |   |  |                   DarknetConv2D_BN_Leaky(num_filters//2, (1,1)),       #降低1半过滤器\n",
    "     |   |   |  |                   DarknetConv2D_BN_Leaky(num_filters, (3,3)))(x)       #恢复过滤器数\n",
    "     |   |   |  |           x = Add()([x,y])                                             #残差\n",
    "     |   |   |  |       #x.shape=>(batch_size,height/2,width/2,num_filters)\n",
    "     |   |   |  |       #y.shape=>(batch_size,height/2,width/2,num_filters)\n",
    "     |   |   |  |       return x                    \n",
    "     |   |   |  |-  x = resblock_body(x, 128, 2)\n",
    "     |   |   |  |-  x = resblock_body(x, 256, 8)\n",
    "     |   |   |  |-  x = resblock_body(x, 512, 8)\n",
    "     |   |   |  |-  x = resblock_body(x, 1024, 4)\n",
    "     |   |   |-生成输出y1 => x, y1 = make_last_layers(darknet.output, 512, num_anchors*(num_classes+5))\n",
    "     |   |   |-生成输出y2 => x, y2 = make_last_layers(darknet.output, 256, num_anchors*(num_classes+5))\n",
    "     |   |   |-生成输出y2 => x, y2 = make_last_layers(darknet.output, 128, num_anchors*(num_classes+5))\n",
    "     |   |   |-输出YOLO模型 => return Model(inputs, [y1,y2,y3])\n",
    "     |   |- 加载参数 => self.yolo_model.load_weights(self.model_path)\n",
    "     |   |- yolo估计器 => boxes, scores, classes = yolo_eval(\n",
    "     |   |   |                  self.yolo_model.output       #模型输出:[y1,y2,y3]\n",
    "     |   |   |                  , self.anchors               #锚点数组:[9 x 2]\n",
    "     |   |   |                  , len(self.class_names)      #分类数目：80\n",
    "     |   |   |                  , self.input_image_shape     #原始图像大小:张量,placeholder,模型输入\n",
    "     |   |   |                  , score_threshold=self.score #得分阈值\n",
    "     |   |   |                  , iou_threshold=self.iou     #交并比阈值\n",
    "     |   |   |                  )\n",
    "     |   |   |- 提取预测结果 => _boxes, _box_scores = yolo_boxes_and_scores(yolo_outputs[l],\n",
    "     |   |   |   |             anchors[anchor_mask[l]], num_classes, input_shape, image_shape)\n",
    "     |   |   |   |- 提取预测边框 => box_xy, box_wh, box_confidence, box_class_probs = yolo_head(feats,\n",
    "     |   |   |   |                                                  anchors, num_classes, input_shape)\n",
    "     |   |   |   |- 修正预测边框为真实值 => boxes = yolo_correct_boxes(box_xy, box_wh, input_shape, \n",
    "     |   |   |                                                      image_shape)                                \n",
    "     |   |   |                          boxes=> (ymin,xmin,ymax,xmax)=>(top,left,bottom,right)\n",
    "     |   |   |- 条件条件过滤：得分 && 非极大值抑制\n",
    "     |   |- 返回yolo估计器 => return boxes,scores,classes\n",
    "    读取图像 => image=Image.open(img_file)    \n",
    "    对象检测 => r_image=yolo.detect_image(image)\n",
    "     |- 图像数据预处理：修正为标准尺寸(self.model_image_size)，归一化处理，扩展维度\n",
    "     |- 执行评估模型(yolo_eval)=> out_boxes, out_scores, out_classes = self.sess.run(\n",
    "     |          [self.boxes, self.scores, self.classes],\n",
    "     |          feed_dict={\n",
    "     |              self.yolo_model.input: image_data,\n",
    "     |              self.input_image_shape: [image.size[1], image.size[0]],\n",
    "     |              K.learning_phase(): 0\n",
    "     |          })\n",
    "     |- 返回结果图 => 原始图与检测框的合成图\n",
    "    显示结果 => plt.imshow(r_image)\n",
    "##### def yolo_eval(yolo_outputs, anchors,  num_classes, image_shape, max_boxes=40, score_threshold=.6,iou_threshold=.5)\n",
    "    模型测试\n",
    "    模型输入:\n",
    "        yolo_model.input --- inputs,shape=>(batch_size,416,416,3)\n",
    "        image_shape -------- 图像真实尺寸，如(533,400)\n",
    "    模型输出:boxes, scores, classes\n",
    "        boxes --- 预测外框,[n x 4],=>()\n",
    "        scores--- 预测分数,[n x 1]\n",
    "        classes-- 预测类别,[n x 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
